## v22.2.0-alpha.2

Release Date: September 6, 2022

{% include releases/release-downloads-docker-image.md release=include.release %}

<h3 id="v22-2-0-alpha-2-backward-incompatible-changes">Backward-incompatible changes</h3>

- Using `SESSION USER` in a projection or where clause now actually returns the SESSION USER instead of the CURRENT USER. If you require this to be backwards compatible, use `session_user()` for SESSION USER and `current_user()` or `CURRENT USER` if you need the CURRENT USER. [#70444][#70444]
- Placeholder values (e.g. `$1`) can no longer be used for role names in ALTER ROLE statements. [#71498][#71498]
- Placeholders (e.g. `$1`) can no longer be used for role names in CREATE/DROP ROLE statements. [#71498][#71498]
- Non-standard cron expressions that specify seconds or year fields are no longer supported. [#74881][#74881]
- Changefeeds will now filter out virtual computed columns from events by default. [#74916][#74916]
- The environment variable that controls the max amount of CPU that can be taken by password hash computations during authentication was renamed from `COCKROACH_MAX_BCRYPT_CONCURRENCY` to `COCKROACH_MAX_PW_HASH_COMPUTE_CONCURRENCY`. Its semantics remain unchanged. [#74301][#74301]
- The volatilities of cast operations between strings and interval/timestamp types has changed from immutable to stable. This means that these cast operations can no longer be used in computed columns or partial index definitions. Instead, the builtin functions parse_interval, parse_date, parse_time, parse_timetz, parse_timestamp, or to_char can be used. When finalizing the upgrade to v22.1, CockroachDB will automatically rewrite any computed columns or partial indexes that use the affected casts to use the new builtin functions. [#78357][#78357]
- This patch introduces a few UX guardrails, including one breaking change:  [breaking]: After further discussion, we realized explicit subdirectories were useful for running incremental backups, but not for full backups. To that end, this pr throws an error if: a) a user passes a subdirectory; b) there does not already exist a full backup in that subdirectory. The user can enable this deprecated syntax by switching the new bulkio.backup.deprecated_full_backup_with_subdir cluster setting to true.  Discussion in #79447 also lead to a discovery of two bugs for backups with AS OF SYSTEM TIME:  Previously, a user could run an AS OF SYSTEM TIME incremental backup with an end time earlier than the previous backup's end time , which could lead to an out of order incremental backup chain. This PR causes the incremental backup to fail if the AS OF SYSTEM TIME is less than the previous backup's end time.  Previously, if a user ran `BACKUP INTO dest AS OF SYSTEM TIME t` and a full backup subdirectory already existed at t, the backup would mistakingly increment on that full backup instead of failing. Without the IN keyword, the user expects a full backup, not an incremental backup. In this patch, the full backup fails when it detects a full backup already exists at the resolved subdirectory. [#79799][#79799]
- CockroachDB does not perform env var expansion in the parameter `--certs-dir` anymore. This was an undocumented feature.  Uses like `--certs-dir='$HOME/path'` (expansion by CockroachDB) can be replaced by `--certs-dir="$HOME/path"` (expansion by the unix shell). [#81298][#81298]
- In the cockroach CLI, BOOLEAN values are now formatted as `t` or `f` instead of `True` or `False`. [#81943][#81943]
- The `cockroach quit` command was removed. It had been deprecated since v20.1. To shut down a node gracefully, send a SIGTERM signal to it. [#82988][#82988]
- A cluster version is added to allow Pebble to recombine certain SSTables (specifically, user keys that are split across multiple files in a level of the LSM). Recombining the split user keys is required for supporting the range keys feature.  The migration to recombine the SSTables is expected to be short (split user keys are rare in practice), but will block subsequent migrations until all tables have been recombined. The `storage.marked-for-compaction-files` time series metric can show the progress of the migration. [#84887][#84887]
- Using a single TCP port listener for both RPC (node-node) and SQL client connections is now deprecated. This capability will be removed in the next version of CockroachDB. Deployments are invited to perform either one of the following changes:  - (preferred:) keep port 26257 for SQL, and allocate a new port,   e.g. 36257, for node-node RPC connections. For example:         --listen-addr=:36257 --sql-addr=:26257 \        --join=othernode:36257,othernode:26257    This will become the default configuration in the next version   of CockroachDB.    When using this mode of operation, care should be taken to   use a `--join` flag that include both the old and new   port numbers for other nodes, so that no network partition   occurs during the upgrade.  - (optional:) keep port 26257 for RPC, and allocate a new port,   e.g. 36257, for SQL connections. For example:        --listen-addr=:26257 --sql-addr=:36257    When using this mode of operation, the `--join` flags do not   need to be modified. However, SQL client apps or the SQL   load balancer configuration (when in use) should be updated   to use the new SQL port number. [#85671][#85671]
- If no `nullif` option is specified while using IMPORT CSV, then a zero-length string in the input is now treated as NULL. The quoted empty string in the input is treated as an empty string. Similarly, if `nullif` is specified, then an unquoted value is treated as NULL, and a quoted value is treated as that string. These changes were made to make IMPORT CSV behave more similarly to COPY CSV.  If the previous behavior (i.e. treating either quoted or unquoted values that match the `nullif` setting as NULL) is desired, then use the new `allow_quoted_null` option in the IMPORT statement. [#84487][#84487]
- COPY FROM operations are now atomic by default instead of being segmented into 100 row transactions. Set the copy_from_atomic_enabled session setting to false to get the old behavior.  Release justification: low risk high benefit correctness fix to existing functionality [#85986][#85986]

<h3 id="v22-2-0-alpha-2-security-updates">Security updates</h3>

- Sql tenant servers will now use a TLS certificate for their HTTP server when it's present. Previously this server never used TLS. [#69723][#69723]
- It is not possible any more to use a node TLS certificate to establish a SQL connection with another username than `node`. This facility had existed as an "escape hatch" so that an operator could use the node cert to perform operations on behalf of another SQL user. However, this facility is not necessary: an operator with access to a node cert can log in as `node` directly and create new credentials for another user anyway. By removing this facility, we tighten the guarantee that the principal in the TLS client cert always matches the SQL identity. [#71134][#71134]
- Multitenant SQL servers now reuse the tenant client certificate (`client-tenant.NN.crt`) for SQL-to-SQL communication. Existing deployments must regenerate the certificates with dual purpose (client and server authentication). [#71248][#71248]
- Authenticated HTTP requests to nodes can now contain additional cookies with the same name as the one we use ("session"). Duplicates like this are permitted by the HTTP spec and our code will now attempt to parse all cookies with a matching name before giving up. This can resolve issues with customers who run other services on the same domain as their CRDB nodes. [#70792][#70792]
- Add a new flag --external-io-enable-non-admin-implicit-access that can remove the admin-only restriction on interacting with arbitrary network endpoint and using 'implicit' auth in operations such as BACKUP, IMPORT or EXPORT. [#71594][#71594]
- The server.identity_map.configuration cluster setting allows a pg_ident.conf file to be uploaded to support dynamically remapping system identities (e.g.: Kerberos or X.509 principals) to database usernames. This supports use-cases where X.509 certificates must conform to organizational standards that mandate the use of Common Names that are not valid SQL usernames (e.g.: CN=carl@example.com => carl). Mapping rules that result in the root, node, or other reserved usernames will result in an error when the client attempts to connect. [#70269][#70269]
- The client_authentication_info structured log message provides a new "SystemIdentity" field with the client-provided system identity. The existing "User" field will be populated after any Host-Based Authentication rules have been selected and applied, which may include a system-identity to database-username mapping. [#70269][#70269]
- GSSAPI-based authentication can now use either the HBA "map" option or "include_realm=0" to map the incoming princpal to a database username. Existing configurations will operate unchanged, however operators are encouraged to migrate from "include_realm=0" to "map" to avoid ambiguity in deployments where multiple realms are present. [#70269][#70269]
- Incoming system identities are normalized to lower-case before they are evaluated against any active identity-mapping HBA configuration. For example, an incoming GSSAPI principal "carl@EXAMPLE.COM" would only be matched by rules such as "example carl@example.com carl" or "example /^(.*)@example.com$ \1". [#70269][#70269]
- It is now possible to pre-compute the hash of the password credentials of a SQL user client-side, and set the SQL user's password using the hash, so that the CockroachDB never sees the password string in clear in the SQL session.  This auto-detection is subject to the new cluster setting `server.user_login.store_client_pre_hashed_passwords.enabled`. This setting defaults to `true` (i.e. feature enabled).  This feature is meant for use in automation/orchestration, when the control plane constructs passwords for users outside of CockroachDB, and there is an architectural desire to ensure that cleartext passwords are not transmitted/stored in-clear.  Note: **when the client provides the password hash, CockroachDB cannot carry any checks on the internal structure of the password,** such as minimum length, special characters, etc.  Should a deployment require such checks to be performed database-side, the operator would need to disable the mechanism via the cluster setting named above. When upgrading a cluster from a previous version, to ensure that the feature remains disabled throughout the upgrade, use the following statement prior to the upgrade: ```sql INSERT INTO system.settings(name, value, "valueType") VALUES('server.user_login.store_client_pre_hashed_passwords.enabled', 'false', 'b'); ```  (We do not recommend relying on the database to perform password checks. Our recommended deployment best practice is to implement credential definitions in a control plane / identity provider that is separate from the database.) [#72579][#72579]
- For context, when configuring passwords for SQL users, if the client presents the password in cleartext via ALTER/CREATE USER/ROLE WITH PASSWORD, CockroachDB is responsible for hashing this password before storing it. By default, this hashing uses CockroachDB's bespoke `crdb-bcrypt` algorithm, itself based off the standard Bcrypt algorithm.  The cost of this hashing function is now configurable via the new cluster setting `server.user_login.password_hashes.default_cost.crdb_bcrypt`. Its default value is 10, which corresponds to an approximate password check latency of 50-100ms on modern hardware.  This value should be increased over time to reflect improvements to CPU performance: the latency should not become so small that it becomes feasible to bruteforce passwords via repeated login attempts.  Future versions of CockroachDB will likely update the default accordingly. [#74582][#74582]
- CockroachDB is now able to authenticate users via the web UI and through SQL sessions when the client provides a cleartext password and the stored credentials are encoded using the SCRAM-SHA-256 algorithm.  (Note: support for a SCRAM authentication flow is a separate feature and is not the target of this release note.)  In particular, for SQL client sessions it makes it possible to use the authentication methods `password` (cleartext passwords), and `cert-password` (TLS client cert or cleartext password) with either CRDB-BCRYPT or SCRAM-SHA-256 stored credentials. Previously, only CRDB-BCRYPT stored credentials were supported for cleartext password authentication. [#74301][#74301]
- CockroachDB now supports the SCRAM-SHA-256 authentication method for SQL clients in a way compatible with PostgreSQL servers and most PostgreSQL-compatible client drivers.  SCRAM is a standard authentication protocol defined by IETF RFCs [5802](https://datatracker.ietf.org/doc/html/rfc5802) and [7677](https://datatracker.ietf.org/doc/html/rfc7677). In contrast to the cleartext-based mechanism that CockroachDB was previously using, SCRAM offers:  - computational burden moved to the client: the computational   cost to compute the authentication hash is borne by the   client, and thus prevents DoS attacks enabled by forcing the   server to compute many hashes simultaneously by malicious clients. - non-replayability: a malicious intermediary cannot reuse   a password observed in one session to re-gain access later. - protection against credential stuffing: a malicious   intermediary cannot reuse a password to gain access to other services. - credential secrecy: the server never learns the cleartext   password and cannot impersonate the client to other servers.  As before, the SCRAM credentials are stored on the server in hashed form, and prevent a malicious attacker from gaining knowledge about passwords even if they gain access to a copy of the hashes.  To use SCRAM, an operator must take care of the following:  1. the stored credentials for the SQL accounts that want to use SCRAM    must use the SCRAM password hash format.     To store SCRAM hashes in CockroachDB, at this time it is necessary    to pre-compute the SCRAM hash in a SQL client and store it    pre-hashed using a CREATE/ALTER USER/ROLE WITH PASSWORD statement.     This was documented in a previous release note already.     A mechanism to compute the SCRAM hash server-side from a cleartext    password might be provided at a later date. Note however that such    a mechanism is generally undesirable: one of the main benefits of    SCRAM is to remove the need for the server to know the client's    cleartext password at any time; a SCRAM hash generation server-side    would defeat this benefit.     A plan also exists to auto-migrate existing passwords to the new    format (refer to a later release note).  2. the SCRAM authentication method must be enabled.     This can be done e.g. explicitly to require SCRAM specifically    via a HBA configuration via the cluster setting    `server.host_based_authentication.configuration`.     For this, two new authentication methods are available:    `scram-sha-256` `certs-scram-sha-256`. The first one is akin to    PostgreSQL and requires a SCRAM authentication flow with the    client. The second one is CockroachDB-specific and allows SQL    client to authenticate *either* using a TLS client certificate *or*    a valid SCRAM authentication flow.     For example, the configuration line `host all all all    scram-sha-256` will require a SCRAM authentication flow for all    clients besides the `root` user.     A plan also exists to automatically opt existing clusters    into SCRAM (refer to a later release note).  Known limitations:  - HTTP authentication (web UI, HTTP APIs) still uses cleartext   passwords.    Security there can be enhanced in two ways:   - enable and use OIDC authentication for the web UI.   - use separate user accounts for access to HTTP than those     used for access to SQL.  - the CockroachDB implementation of SCRAM differs from PostgreSQL in   two ways:    - the extended protocol SCRAM-SHA-256-PLUS is not yet supported.     SCRAM-SHA-256-PLUS adds *channel binding* over TLS, a mechanism that     offers MITM protection from malicious intermediaries even when these     have access to well-signed TLS certificates. Without this extension,     proper MITM protection requires the client to verify the server     certificate against a known CA and server fingerprint.      CockroachDB does not yet support SCRAM-SHA-256-PLUS because we     have observed that support for channel binding is not yet common     in SQL client drivers besides PostgreSQL's own `libpq` driver.    - CockroachDB does not yet implement zero-knowledge authentication     failures like PostgreSQL.  In PostgreSQL, the implementation ensures     that a SQL client cannot distinguish the causes of an authentication     failure: whether a password is missing, expired, invalid, or the     user account does not exist, the SQL client is forced to pay the     price of the SCRAM handshake and does not learn the exact cause of     the failure. This ensures that a malicious attacker cannot use the     type of authentication failure as a mechanism to learn properties of     a target SQL account.      This mechanism may be implemented in CockroachDB at a later time. [#74301][#74301]
- The hash method used to encode cleartext passwords before storing them is now configurable, via the new cluster setting `server.user_login.password_encryption`. Its supported values are `crdb-bcrypt` and `scram-sha-256`.  The cluster setting only becomes effective and its default value is `scram-sha-256` after all cluster nodes have been upgraded. Prior to completion of the upgrade, the cluster behaves as if the cluster setting is fixed to `crdb-bcrypt` (for backward compatibility)  Note that the preferred way to populate password credentials for SQL user accounts is to pre-compute the hash client-side, and pass the precomputed hash via CREATE/ALTER USER/ROLE WITH PASSWORD. This ensures that the server never sees the cleartext password. [#74301][#74301]
- The cost of the hashing function for `scram-sha-256` is now configurable via the new cluster setting `server.user_login.password_hashes.default_cost.scram_sha_256`.  Its default value is 119680, which corresponds to an approximate password check latency of 50-100ms on modern hardware.  This value should be increased over time to reflect improvements to CPU performance: the latency should not become so small that it becomes feasible to bruteforce passwords via repeated login attempts.  Future versions of CockroachDB will likely update the default accordingly. [#74301][#74301]
- When using the HBA authentication method `cert-password` (the default) for SQL client connections, and the SQL client does not present a TLS client certificate to the server, CockroachDB now automatically upgrades the password handshake protocol to use SCRAM-SHA-256 if the user's stored password uses the SCRAM encoding.  The previous behavior of requesting a cleartext password is still used if the stored password is encoded using the CRDB-BCRYPT format.  An operator can force to _always_ request SCRAM-SHA-256 when a TLS client cert is not provided (so as to guarantee the various security benefits of SCRAM) using the authentication methods `cert-scram-sha-256` (either TLS client cert _or_ SCRAM-SHA-256); and `scram-sha-256` (only SCRAM-SHA-256).  (As previously, mandatory cleartext password authentication can be requested, e.g. for debugging purposes, by using the HBA method `password`.)  This automatic protocol upgrade can be manually disabled using the new cluster setting `server.user_login.cert_password_method.auto_scram_promotion.enable` (by setting it to `false`), for example if certain client drivers are found to not support SCRAM-SHA-256 authentication properly. [#74301][#74301]
- In order to promote a transition to SCRAM-SHA-256 for password authentication, CockroachDB now automatically attempts to convert stored password hashes after a cleartext password authentication succeeds to SCRAM-SHA-256, if the target hash method configured via `server.user_login.password_encryption` is `scram-sha-256`.  This auto-conversion can happen either during SQL logins or HTTP logins that use passwords, whichever happens first.  When it happens, a structured event of type `password_hash_converted` is logged to the SESSIONS channel.  The PKBDF2 iteration count on the hash is chosen in order to preserve the latency of client logins, to remain similar to the latency incurred from the starting bcrypt cost. (For example, the default configuration of bcrypt cost 10 is converted to a SCRAM iteration count of 119680.)  This choice, however, lowers the cost of bruteforcing passwords for an attacker with access to the encoded password hashes, if they have access to ASICs or GPUs, by a factor of ~10. For example, if it would previously cost them $1M to bruteforce a `crdb-bcrypt` hash, it would now cost them "just" $100k to bruteforce the `scram-sha-256` hash that results from this conversion.  If an operator wishes to compensate for this, three options are available:  1. they can set up their infrastructure such that only passwords with    a high entropy can be used. This can be achieved by e.g. disabling    the ability of end-users to select their own passwords and    auto-generating passwords for them, or enforce some entropy checks    during password selection. This way, the entropy of the password    itself compensates for the lower hash complexity.  2. they can manually select a higher SCRAM iteration count.  This can    be done either by pre-computing SCRAM hashes client-side and providing    the precomputed hash using ALTER USER WITH PASSWORD; or adjusting the    cluster setting    `server.user_login.password_hashes.default_cost.scram_sha_256` and    asking CockroachDB to recompute the hash.  3. they can disable the auto-conversion of `crdb-bcrypt` hashes to    `scram-sha-256` altogether, using the new cluster setting    `server.user_login.upgrade_bcrypt_stored_passwords_to_scram.enabled`.    This approach is discouraged however, as it removes the other    security protections offered by SCRAM authentication.  NB: the conversion also only happens if the target configured method via `server.user_login.password_encryption` is `scram-sha-256`, because the goal of the conversion is to move clusters towards that configuration. This acknowledges cases when the operator had a legitimate reason to select another value and future versions of of CockroachDB that may use a new authentication method. [#74301][#74301]
- Added support for query cancellation via the pgwire protocol. Since this protocol is unauthenticated, there are a few precautions included.  (1) The protocol requires that a 64-bit key is used to uniquely identify a session. Some of these bits are used to identify the CockroachDB node that owns the session. The rest of the bits are all random. If the node ID is small enough, then only 12 bits are used for the ID, and the remaining 52 bits are random. Otherwise, 32 bits are used for both the ID and the random secret.  (2) A fixed per-node rate limit is used. There can only be at most 256 failed cancellation attempts per second. Any other cancel requests that exceed this rate are ignored. This makes it harder for an attacker to guess random cancellation keys. Specifically, if we assume a 32-bit secret and 256 concurrent sessions on a node, it would take 2^16 seconds (about 18 hours) for an attacker to be certain they have cancelled a query.  (3) No response is returned for a cancel request. This makes it impossible for an attacker to know if their guesses are working. There are internal  warning logs for unsuccessful attempts. Large numbers of these messages could indicate malicious activity. [#67501][#67501]
- The cluster setting server.user_login.session_revival_token.enabled has been added. It is false by default. If it is set to true, then a new token-based authentication mechanism is enabled. A token can be generated using the crdb_internal.create_session_revival_token builtin function. The token has a lifetime of 10 minutes and is cryptographically signed to prevent spoofing and brute-forcing attempts. When initializing a session later, the token can be presented in a pgwire StartupMessage with a parameter name of `crdb:session_revival_token_base64`, with the value encoded in base64. If this parameter is present, all other authentication checks are disabled, and if the token is valid and has a valid signature, the user who originally generated the token authenticates into a new SQL session. If the token is not valid, then authentication fails.  The token does not have "use-once" semantics, so the same token can be used any number of times to create multiple new SQL sessions within the 10 minute lifetime of the token. As such, the token should be treated as highly sensitive cryptographic information.  This feature is meant to be used by multitenant deployments to move a SQL session from one node to another. It requires the presence of a valid Ed25519 keypair in tenant-signing.<tenant_id>.crt and tenant-signing.<tenant_id>.key. [#75660][#75660]
- When the `sql.telemetry.query_sampling.enabled` cluster setting is enabled, SQL names and client IPs are no longer redacted in telemetry logs. [#76676][#76676]
- Users can enable HSTS headers to be set on all HTTP requests which force browsers to upgrade to HTTPS without a redirect. This is controlled by setting the `server.hsts.enabled` cluster setting to true which is false by default. [#77244][#77244]
- HBA configuration can now be used to restrict admin logins to originating from localhost. This allows security conscious users to better restrict acces to their instance. To restrict admins from logging in to localhost insert the following as the first line of your HBA configuration:     host  all root 127.0.0.1/32 cert-password [#77955][#77955]
- Crdb_internal.reset_sql_stats() and crdb_internal.reset_index_usage_stats() builtins now check if user has admin role. [#79810][#79810]
- This PR introduces tenant scoping for a client certificate. This allows for client certificates to be used to authenticate a client on a specific tenant only. It contains the username within the CN of the certificate. The tenant ID and username is embedded in the URIs section of Subject Alternate Name (SAN) values. The format of the URI SAN is crdb://tenant/<tenant_id>/user/<username> [#79064][#79064]
- Certain less-secure TLS 1.2 cipher suites are no longer supported. Very old clients (more than five years old) may fail to connect. CRDB now matches the IETF's "recommended" cipher list defined in RFC 8447. [#82362][#82362]
- We introduce a new tenant scoped client certificate to authenticate a client on a specific tenant. A tenant scoped client certificate contains the client name within the CN and the tenant ID, to which the certificate is being scoped to, as the SAN. The tenant ID is embedded within the URI section with the format "crdb://tenant/<tenant_id>/user/<username>". For example, a root client certificate scoped to a tenant with ID 123 will contain "root" in the CN field and the URI "crdb://tenant/123/user/root" in the URI section of the certificate. This certificate will authorize the root client on the tenant with the ID 123. It will result in an authorization error if used to authenticate the root client on any other tenant. [#79065][#79065]
- Multi-region related builtin functions now have access control checks. [#83918][#83918]
- The HTTP endpoints under the `/api/v2` prefix will now accept cookie-based authentication similar to other HTTP endpoints used by the DB Console. The encoded session *must* be in a cookie named `"session"`, and the `"X-Cockroach-API-Session"` header is required to be set to `"cookie"` for the session to be read from the cookie header. A cookie provided without the custom header present will be ignored. [#84617][#84617]
- Change requirements to access some observability features. Databases/tables/schema endpoints for admin ui require admin or VIEWACTIVITY. EXPERIMENTAL_AUDIT requires admin or MODIFYCLUSTERSETTING. SQL login requires not having NOSQLLOGIN or the equivalent role option. [#85769][#85769]
- HTTP API endpoints under the `/api/v2/` prefix, will allow requests through when the cluster is running in "insecure" mode. When the cluster is running in "insecure" mode requests to these endpoints will have the username set to "root".  Release justification: low-risk high-benefit change to existing functionality. [#86417][#86417]

<h3 id="v22-2-0-alpha-2-general-changes">General changes</h3>

- Non-cancelable jobs, such as schema-change GC jobs, now do not fail unless they fail with a permanent error. They retry with exponential-backoff if they fail due to a transient error. Furthermore, Jobs that perform reverting tasks do not fail. Instead, they are retried with exponential-backoff if an error is encountered while reverting. As a result, transient errors do not impact jobs that are reverting.  Fixes: #66685 [#69300][#69300]
- CRDB now supports exporting operation traces to OpenTelemetry-compatible tools using the OTLP protocol through the trace.opentelemetry.collector cluster setting.  CRDB now support exporting traces to a Jaeger agent through the new trace.jaeger.agent cluster setting. Exporting to Jaeger was previously possibly by configuring the Jaeger agent to accept Zipkin traces and using the trace.zipkin.collector cluster setting; this configuration is no longer required.  Support for exporting to DataDog and Lightstep through other interfaces has been retired; these tools can use OpenTelemetry data.  The cluster settings trace.lightstep.token, trace.datadog.agent, and trace.datadog.project have been deprecated; they no longer have any effect. [#65599][#65599]
- Tracing transaction commits now includes details about replication. [#72738][#72738]
- The following metrics were added for observability of cancellation requests made using the Postgres wire protocol: - sql.pgwire_cancel.total - sql.pgwire_cancel.ignored - sql.pgwire_cancel.successful  The metrics are all counters. The "ignored" counter is incremented if a cancel request was ignored due to exceeding the per-node rate limit of cancel requests. [#76457][#76457]
- Explainer documentation has been added describing how jobs and scheduled jobs functions and are used in CRDB [#73995][#73995]
- Use Bazel to build release binaries  Release justification: update release process [#76897][#76897]
- When using Azure Cloud Storage for data operations, cockroach now calculates the Storage Account URL from the provided AZURE_ENVIRONMENT query parameter. This defaults to AzurePublicCloud if not specified to maintain backwards compatibility. [#80511][#80511]
- Update new minimum supported kernel and glibc versions on Linux to 3.10.108 and 2.25 respectively. [#84283][#84283]
- CRDB will now collect schema info if phoning home is enabled. This schema info is added to the telemetry log by a built-in scheduled job which runs on a weekly basis by default. This recurrence can be changed via the sql.schema.telemetry.recurrence cluster setting.  The schedule can also be paused via PAUSE SCHEDULE followed by its ID, which can be retrieved by querying SELECT * FROM [SHOW SCHEDULES] WHERE label = 'sql-schema-telemetry'. [#84761][#84761]
- Changefeeds without a specified sink will not longer terminate when schema changes occur. [#85458][#85458]
- This change updates core/experimental changefeeds to be more resilient to transient errors (ex. network blips) by adding checkpointing.  Previously, transient errors would result in a core changefeed stopping and terminating the underlying SQL statement. This would require the SQL statement to be restarted by a user. Furtheremore, if the core changefeed were restarted during an inital scan, the initial scan would start from the beginning. For large initial scans, transient errors are more likely, so restarting from the beginning would likely see more transient errors and restarts which would not progress the changefeed.  Now, an experimental changefeed will automatically take frequent checkpoints and retry from the last checkpoint when a transient errors occurs.  Release justification: This change updates an experimental feature. [#86253][#86253]

<h3 id="v22-2-0-alpha-2-enterprise-edition-changes">Enterprise edition changes</h3>

- Updated retyable error warning message to begin with "WARNING" [#70226][#70226]
- Fixes a bug that could have led to duplicate instances of a single changefeed job running for prolonged periods of time. [#70612][#70612]
- Fixed a limitation of IMPORT for tables using user-defined types whereby any change to the set of tables or views which reference the type or any changes to privileges on the type during the IMPORT would lead to failure. Now new references to the type or GRANT or REVOKE operations performed while the IMPORT is ongoing will not cause failure. [#71016][#71016]
- Temporary tables are now restored to their original database instead of defaultdb during a full cluster restore. Furthermore, defaultdb and postgres are dropped before a full cluster restore and will only be restored if they're present in the backup being restored. [#71890][#71890]
- Changefeeds can be created with a new option called `metrics_label` which lets operators configure changefeeds to use dedicated set of metrics for those changefeed(s) so that they can be monitored independently of other changefeed(s) in the system. [#72111][#72111]
- Fix a bug where restore can sometimes map OIDs to invalid types in certain circumstances containing UDTs. [#73095][#73095]
- Changefeeds now support gcp pubsub as a sink. [#72056][#72056]
- Client certificates may now be provided for the webhook changefeed sink. [#74645][#74645]
- Redacted more potentially-sensitive URI elements from changefeed job descriptions. This is a breaking change for workflows involving copying URIs. As an alternative, the unredacted URI may be accessed from the jobs table directly. [#75174][#75174]
- Changefeeds will now output the topic name(s) created by the Kafka sink. Furthermore, these topic name(s) will be displayed in the SHOW CHANGEFEED JOBS query. [#75223][#75223]
- Backup and Restore now allows for encryption/decryption with GCS KMS [#75750][#75750]
- Kafka sink supports larger messages, up to 2GB in size. [#76265][#76265]
- Added support for a new SQL statement called ALTER CHANGEFEED, which allows users to add/drop targets for an existing changefeed. The syntax of the statement is as follows:  ALTER CHANGEFEED <job_id> {{ADD|DROP} <targets>}...  Where there can be an abritrary number of ADD/DROP commands in any order. The following is an example of this statement:  ALTER CHANGEFEED 123 ADD foo,bar DROP baz;  With this statement, users can avoid going through the process of altering a changefeed on their own, and rely on CRDB to carry out this task. [#75737][#75737]
- Changefeeds running on tables with a low gcttl will function more reliably due to protected timestamps being maintained for the changefeed targets at the resolved timestamp of the changefeed.  The frequency at which the protected timestamp is updated to the resolved timestamp can be configured through the `changefeed.protect_timestamp_interval` cluster setting. If the changefeed lags too far behind such that storage of old data becomes an issue, cancelling the changefeed will release the protected timestamps and allow garbage collection to resume. If `protect_data_from_gc_on_pause` is unset, pausing the changefeed will release the existing protected timestamp record. [#76605][#76605]
- Added support to the ALTER CHANGEFEED statement so that users can edit and unset the options of an existing changefeed. The syntax of this addition is the following:  ALTER CHANGEFEED <job_id> SET <options> UNSET <opt_list> [#76583][#76583]
- Users may now alter the sink URI of an existing changefeed. This can be achieved by executing the following statement:  ALTER CHANGEFEED <job_id> SET sink = '<sink_uri>'  Where the sink type of the new sink must match the sink type of the old sink that was chosen at the creation of the changefeed. [#77043][#77043]
- Altering the sink type of a changefeed is disallowed. In this PR we offer solutions for those who would like to use a new sink type in the error message.  Release justification: This is a safe, low-risk code change as we are only changing the content of the error message to make it more prescriptive for users. [#77152][#77152]
- Currently executing schedules are cancelled immediately when jobs scheduler disabled.  Release Justification: stability improvement. [#77306][#77306]
- The "changefeed.backfill_pending_ranges" prometheus metric was added to track ongoing backfill progress of a changefeed.  Release justification: Low risk metrics changes [#76995][#76995]
- Changefeeds can now be created on tables with more than one column family. Previously, this would error. Now, we create a feed that will emit individual messages per column family. Primary key columns will appear in the key for all column families, but in the value only in the families they are in. For example, if a table foo has families "primary" containing the primary key and a string column, and "secondary" containing a different string column, you'll see two messages for an insert that will look like 0 -> {id: 0, s1: "val1"}, 0 -> {s2: "val2"}. If an update then only affects one family, you'll see only one message (e.g. 0 -> {s2: "newval"}). This behavior reflects CockroachDB's internal treatment of column families: writes are processed and stored separately, with only the ordering and atomicity guarantees that would apply to updates to two different tables within a single transaction. Avro schema names will include the family name concatenated to the table name. Note that if family names are not specified in the CREATE or ALTER TABLE statement, the default family names will either be "primary" or of the form "fam_<zero-indexed family id>_<underscore-delimited list of columns>. [#77084][#77084]
- Add created time column to `crdb_internal.active_range_feeds` virtual table to improve observability and debugability of rangefeed system.  Release Justification: Low impact observability/debugability improvement. [#77597][#77597]
- Incremental backups created by BACKUP TO LATEST IN or BACKUP TO are now stored by default under the path 'incrementals' within the backup destination, rather than under each backup's path. This enables easier management of cloud-storage provider policies specifically applied to incremental backups.  Release justification: This feature is very well-tested, and the code refactoring makes it more verifiably correct. [#75970][#75970]
- Changefeed records message size histogram.  Release Justification: Low impact change. [#77711][#77711]
- Users can now perform initial scans on newly added targets by executing the following statement:  ALTER CHANGEFEED <job_id> ADD <targets> WITH initial_scan  The default behavior is to perform no initial scans on newly added targets, but users can explicitly request this by replacing the 'initial_scan' with 'no_initial_scan'.  Release justification: low danger enhancement to newly implemented functionality. [#77263][#77263]
- The public column of setting server.child_metrics.enabled will be set to true.  Release justification: This change is very small and low risk [#77561][#77561]
- Limit the number of concurent catchup scan requests issued by rangefeed client.  Release Justfication: Important stability and scalability improvement to prevent a single rangefeed client from consuming entirety of catchup scan iterator budget on a KV server. [#77725][#77725]
- Changefeeds can now specify column families to target, using the syntax `[TABLE] foo FAMILY bar`. For example,`CREATE CHANGEFEED FOR TABLE foo FAMILY bar, TABLE foo FAMILY baz, TABLE users` will create a feed that watches the bar and baz column families of foo, as well as the whole table users. A family must exist with that name when the feed is created. If all columns in a watched family are dropped in an ALTER TABLE statement, the feed will fail with an error, similarly to dropping a table. Behavior is otherwise similar to feeds created using split_column_families. [#77640][#77640]
- Do not block schema changes when executing core style change feeds.  Release Justification: low danger stability fix. [#78142][#78142]
- Allow users to provide an end time for changefeeds through the 'end_time' option. When this option is provided, the changefeed will run until it has reached the end time, and then the changefeed job will end with a successful status code. Furthermore, we now provide an 'initial_scan_only' option. When this option is set, the changefeed job will end with a successful status code immediately after the initial scan completed.  Release Justification: This feature is low danger, yet highly desired from users. [#78199][#78199]
- Tenant GC job will now wait for protected timestamp records targetting the tenant, and with a protect time less than the tenant's drop time.  Release justification: high-priority changes in existing functionality [#77726][#77726]
- Changefeeds can now protect targets from gc on user tenants [#78410][#78410]
- Remove expensive, unnecessary, and never used `schedules.round.schedules-ready-to-run` and `schedules.round.num-jobs-running` metrics from job schedulers.  Release Justification: Stability fix for scheduled job system. [#78467][#78467]
- Job scheduler is more efficient and should no longer lock-up jobs and scheduled jobs tables.  Release Justification: Stability improvement for scheduled jobs system.  s [#78564][#78564]
- Checkpoint files are no longer overwritten and now versioned and written side by side in the /progress directory. Temporary checkpoint files are no longer written. [#76869][#76869]
- Changefeeds can now be distributed across pods in tenant environments [#78965][#78965]
- Remove the default values from the SHOW CHANGEFEED JOB output [#79325][#79325]
- Changefeed messages for tables with multiple column families will append the family name to the table name in the default topic. For example, `CREATE CHANGEFEED FOR TABLE foo, TABLE bar FAMILY primary` will emit to the topics "foo" and "bar.primary". A changefeed created with the `split_column_families` option will create new topics if new families are added to a watched table that already had multiple column families. In cloud storage sinks such as s3, the filename will include the family separated by a + (e.g. "bar+primary"). The full_table_name option is now supported for all sinks. [#79186][#79186]
- Unify the syntax that allows users to define the behaviour they would like for initial scans on changefeeds by extending the `initial_scan` option to take on three possible values: `'yes|no|only'`.  Release justification: Small, safe refactor that will improve the user experience when creating changefeeds. [#79324][#79324]
- LATEST files are no longer overwritten and now versioned and written in the /metadata/latest directory for non mixed clusters. [#77284][#77284]
- Fix the issue of not being able to resolve existing targets when performing validation checks by adding the fully qualified name to the changefeed statement. As a result, every altered changefeed will display the fully qualified name of every target in the SHOW CHANGEFEED JOB query.  Release justification: Low risk bug fix. [#79542][#79542]
- Block incremental backups with mismatched localities. [#79135][#79135]
- Fix bug where backups in the base directory of a Google Storage bucket would not be discovered by SHOW BACKUPS. These backups will now appear correctly. [#80182][#80182]
- Changefeeds to gcp no longer require topic creation permission if all topics being written to already exist. [#80430][#80430]
- Support a CSV format for changefeeds. Only works with initial_scan='only', and does not work with diff/resolved options. [#79853][#79853]
- Backups run by secondary tenants now write protected timestamp records to protect their target schema objects from garbage collection during backup execution. [#80587][#80587]
- Users can now authenticate to AWS by passing in the argument AUTH=assume and specifiying a AWS_ROLE_ARN=<role-ARN>. A user to AssumeRole with can optionally be specified with AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY or can be left blank to use the default credentials chain. [#79968][#79968]
- `primary_key_filter` option can be used to restrict the span watched by changefeed only to the portion that satisfies the filtering predicate. [#80499][#80499]
- Changefeed restarts, and changefeeds started with cursor are now more efficient since they can use checkpoint of catchup scan progress.  Release Justification: important performance and scalability improvements for large scale changefeeds. [#77763][#77763]
- Storage and KMS URIs for GCP in Backup and restore now accept an "ASSUME_ROLE" parameter, which informs the current service account authenticated by either implicit or specified credentials to obtain temporary credentials for the service account specified by the ASSUME_ROLE parameter in order to access the resource specified by the URI. Below are examples of URIs with "ASSUME_ROLE" parameter:  ``` GCS: gs://<bucket>/<key>?AUTH=specified&ASSUME_ROLE=<service_account>@<project>.iam.gserviceaccount.com&CREDENTIALS=<credentials> KMS GCP: gs:///<key_resource_name>?AUTH=implicit&ASSUME_ROLE=<service_account>@<project>.iam.gserviceaccount.com ``` [#80417][#80417]
- Adds the ability to provide short-lived OAuth 2.0 tokens as a form of short-lived credentials to Google Cloud Storage and KMS. The token can be passed to the GCS or KMS URI via the new BEARER_TOKEN parameter for "specified" authentication mode.  Example GCS URI: gs://<bucket>/<key>?AUTH=specified&BEARER_TOKEN=<token> Example KMS URI: gs:///<key_resource>?AUTH=specified&BEARER_TOKEN=<token>  There is no refresh mechanism associated with this token, so it is up to the user to ensure that its TTL is longer than the duration of the job or query that is using the token. The job or query may irrecoverably fail if one of its tokens expire before completion. [#82861][#82861]
- CHANGEFEED statement now supports general expressions: predicates and projections. Projections allow customers to emit only the data that they care about, including computed columns, while predicates (i.e. filters) allow them to restrict the data that's emitted only to those events that match the filter.  ``` CREATE CHANGEFEED INTO 'kafka://' AS SELECT * FROM t WHERE NOT cdc_is_delete() ``` [#82562][#82562]
- Added replanning functionality for changefeeds when topology changes with a replanning counter metric. this functionality only works properly for serverless currently. [#83143][#83143]
- Allow the ASSUME_ROLE parameter in AWS and GCP storage and KMS URIs to specify a list of roles with a comma-separated string. The roles in the list can then be chain assumed in order to access the resource specified by the URI.  For example, if a destination in S3 can only be accessed by RoleB, and the identity corresponding to implicit auth can only assume RoleB through an intermediate role RoleA, then this chain assumption can be specified in the S3 URI: s3://bucket/key?AUTH=implicit&ASSUME_ROLE=RoleA,RoleB  In addition, remove the "assume" auth mode from AWS URIs, and instead use the ASSUME_ROLE parameter to indicate that a role should be assumed for authentication. Below are some examples:  S3: s3://<bucket>/<key>?AUTH=specified&ASSUME_ROLE=<role_arn>&AWS_ACCESS_KEY_ID=<access_key>&AWS_SECRET_ACCESS_KEY=<secret_key> AWS KMS: aws:///<key_arn>?AUTH=implicit&REGION=<region>&ASSUME_ROLE=<role_arn> [#83712][#83712]
- The URI for GCP pubsub now accept an "ASSUME_ROLE" parameter, which specifies a comma-separated list of service accounts to be chain assumed by the service account authenticated by the implicit or specified credentials. [#84619][#84619]
- Previously, if you dropped a column with the schema_change_policy 'stop', the changefeed would stop. Dropping a column with a different policy would result in previous rows being retransmitted with the dropped column omitted.  In some cases, a changefeed may target specific columns (a column family) of a table. In these cases, if a non-target column is dropped, it does not make sense to stop the changefeed or retransmit values because the column was not visible to a consumer sink to begin with.  With this change, dropping an non-target column from a table will not stop the changefeed when the schema_change_policy is 'stop'. With any other policy, dropping a non-target column will not trigger a backfill. [#84674][#84674]
- Implemented functionality to determine the number of column families that are referenced by a SELECT statement in changefeed expressions and handle appropriately [#84764][#84764]
- Backup, restore, and backup schedule creation now have corresponding events that are emitted to the telemetry channel. [#82463][#82463]
- Add ALTER BACKUP SCHEDULE command to modify existing backup schedules. [#85489][#85489]
- When creating a changefeed with 'AS SELECT ...', the option schema_change_policy='stop' will be required. This means that the changefeed will stop if schema changes occur. This restriction will be reverted in future releases, allowing schema changes again. [#85896][#85896]
- Introduce a new Rangefeed RPC called `MuxRangeFeed`.  Rangefeeds now use a common HTTP/2 stream per client for all range replicas on a node, instead of one per replica. This significantly reduces the amount of network buffer memory usage, which could cause nodes to run out of memory if a client was slow to consume events. The caller may opt in to use new mechanism by specifying `WithMuxRangefeed` option when starting the rangefeed.  However, a cluster wide `COCKROACH_ENABLE_MULTIPLEXING_RANGEFEED` environment variable may be set to `false` to inhibit the use of this new RPC.  Release justification: Rangefeed scalability and stability improvement. Safe to merge since the functionality disabled by default. [#75581][#75581]
- ALTER BACKUP now supports additional commands like SET WITH, SET SCHEDULE OPTION, SET LABEL, and SET INTO  Release justification: low risk, medium benefit [#86190][#86190]
- Changefeeds may opt in via `changefeed.mux_rangefeed.enabled` setting to use `MuxRangeFeed` RPC which multiplexes multipe range feed streams onto a single RPC stream per node.  Release justification: add option to enable functionality that's disabled by default. [#86448][#86448]
- Alter Backup Schedule will fail if the new backup statement does not pass planning.  Release justification: Improving reliability on feature launching for 22.2. [#86819][#86819]

<h3 id="v22-2-0-alpha-2-sql-language-changes">SQL language changes</h3>

- There are now new job control statements allowing an operator to manipulate all jobs of specific type: `<Command> ALL <JobType> JOBS`. Supports CHANGEFEED, BACKUP, IMPORT and RESTORE jobs. For example: `PAUSE ALL CHANGEFEED JOBS`. [#69314][#69314]
- IMPORT INTO now supports UDT for default and computed columns.  Release justification: fixes for high-priority or high-severity bugs in existing functionality [#69779][#69779]
- EXPLAIN ANALYZE now contains more information about the MVCC behavior of operators that scan data from disk. See commit message for more details. [#64503][#64503]
- Add support for SQL arrays containing JSON for in-memory processing. This does not add support for storing SQL arrays of JSON in tables. [#70041][#70041]
- Placeholder values can now be used as the right-hand operand of the JSONFetchVal (->) and JSONFetchText (->>) operators without ambiguity. This argument will be given the text type and the "object field lookup" variant of the operator will be used.  Release justification: None [#70066][#70066]
- Fixed createdb and settings columns for tables: pg_user, pg_roles and pg_authid [#69609][#69609]
- The `information_schema._pg_truetypid` and `information_schema._pg_truetypmod` builtin functions are now supported, which improve compatibility with PostgreSQL. [#69913][#69913]
- The `information_schema._pg_char_max_length` builtin function is now supported, which improves compatibility with PostgreSQL. [#69913][#69913]
- The pg_my_temp_schema builtin function now properly returns the OID of the active session's temporary schema, if one exists.  Release justification: None, waiting for v22.1. [#69909][#69909]
- The pg_is_other_temp_schema builtin function is now supported, which returns whether the given OID is the OID of another session's temporary schema.  Release justification: None, waiting for v22.1. [#69909][#69909]
- The `information_schema._pg_index_position` builtin function is now supported, which improves compatibility with PostgreSQL.  Release justification: None, waiting for v22.1. [#69911][#69911]
- Extend index scan hint to allow zigzag joins to be forced. [#67737][#67737]
- Pg_authid.rolesuper, pg_roles.rolesuper and pg_user.usesuper now are true for users/roles that have admin role  Fixes: #69943 [#69981][#69981]
- Warn users that sequences are slower than using UUID. [#68964][#68964]
- SQL queries with ORDER BY x LIMIT k clauses may now be transformed to use TopK in the query plan if the limit is a constant. Although this affects the output of EXPLAIN, using TopK in the query plan does not necessarily mean that it is used during execution.  Release justification: [#68140][#68140]
- The error message when creating the wrong type of index was not clear and it now suggests creating an inverted index. [#69824][#69824]
- IMPORT INTO regional by row tables is supported.  Release justification: fixes for high-priority or high-severity bugs in existing functionality [#69903][#69903]
- The has_tablespace_privilege, has_server_privilege, and has_foreign_data_wrapper_privilege builtin functions now return NULL instead of true when provided with a non-existed OID reference, which matches the behavior of newer versions of PostgreSQL. [#69939][#69939]
- The pg_has_role builtin function is now supported, which returns whether a given user has privileges for a specified role or not.  Release justification: None, waiting for v22.1. [#69939][#69939]
- The query logging enabled by `sql.telemetry.query_sampling.enabled` now avoids considering SQL statements issued internally by CockroachDB itself. [#70346][#70346]
- Change the pgerror code XC instead of CD for CockroachDB specific errors. This is because the "C" class is reserved for the SQL standard. The pgcode `CDB00` used for unsatisfiable bounded staleness is now `XCUBS`. [#70347][#70347]
- Add the json_populate_record, jsonb_populate_record functions, json_populate_recordset, and jsonb_populate_recordset functions, which transform JSON into row tuples based on the labels in a record type. [#70115][#70115]
- The enable_drop_enum_value session variable has been removed, along with the corresponding cluter setting. The functionality of being able to drop enum values is now enabled automatically. Queries that refer to the session/cluster setting will still work but will have no effect. [#70369][#70369]
- The array builtins (array_agg, array_cat, array_position, etc) now operate on record types. [#70332][#70332]
- Return a pgerror with code 22P02 when an invalid cast to OID is made. This previously threw an assertion error. [#70454][#70454]
- CREATE TABLE ... LIKE ... now copies ON UPDATE definitions for INCLUDING DEFAULTS. [#70472][#70472]
- "visible" is now usable as a table or column name without extra quoting. [#70533][#70533]
- Added the optional new_db_name clause to RESTORE DATABASE statment, allowing the user to rename the database they intend to restore. [#70222][#70222]
- Small fix to error messaging for builtin functions for sequences.  Example: SELECT nextval('@#%@!324234') correctly returns relation "@#%@!324234" does not exist (if the relation doesn't exist) instead of a syntax error.  SELECT currval('') returns currval\(\): invalid table name: instead of pq: currval(): syntax error at or near "to" DETAIL: source SQL: ALTER TABLE  RENAME TO x                     ^ HINT: try \h ALTER TABLE [#70590][#70590]
- It is now possible to cast JSON booleans to the BOOL type, and to cast JSON numerics with fractions to rounded INT types. Error messages are now more clear when a cast from a JSON value to another type fails. [#70522][#70522]
- Added a new sql builtin 'unordered_unique_rowid' which generates a globally unique 64-bit integer that does not have ordering. [#70338][#70338]
- Added a new serial_normalization case 'unordered_rowid' which generates a globally unique 64-bit integer that does not have ordering. [#70338][#70338]
- A hint is now provided when using a SERIAL4 type which gets upgraded to a SERIAL8 due to the serial_normalization session variable requiring an INT8 to succeed. [#70656][#70656]
- Fixed a bug where LINESTRINGZ, LINESTRINGZM and LINESTRINGM could not be used as a column type. [#70654][#70654]
- Improve error message when trying to select a named field from an anonymous record that has no labels. [#70726][#70726]
- Implemented pg_statistic_ext on pg_catalog [#70591][#70591]
- `SHOW JOBS` will now include the newly added columns from `crdb_internal.jobs` (`last_run`, `next_run`, `num_runs`, and `execution_errors`). The columns capture state related to retries, failures, and exponential backoff. [#70766][#70766]
- Implemented pg_shadow at pg_catalog  Solves #68133  Release justification: low risk, high benefit changes to existing functionality [#68255][#68255]
- Disallow cross DB references for sequences by default. This can be enabled with the cluster setting sql.cross_db_sequence_references.enabled. [#70581][#70581]
- This change adds ability to comment on SQL table constraints using PostgreSQL's COMMENT ON CONSTRAINT syntax. [#69783][#69783]
- Added a `WITH COMMENT` clause to the `SHOW CONSTRAINT` statement that causes constraint comments to be displayed. [#69783][#69783]
- Show indpred on the pg_index table for partial indexes. This was previously NULL for partial indexes. [#70808][#70808]
- EXPLAIN ANALYZE (DEBUG) now returns an error for non-system tenants, since we cannot yet support it correctly. [#70932][#70932]
- The cluster setting `sql.telemetry.query_sampling.qps_threshold`, and `sql.telemetry.query_sampling.sample_rate` have been removed. A new setting, `sql.telemetry.query_sampling.max_event_frequency` has been introduced, with default value of 10 events per second. [#70786][#70786]
- Adding empty stubs for tables and columns: tables: - pg_statistic - pg_statistic_ext_data - pg_stats - pg_stats_ext columns: - pg_attribute.attmissingval  Resolves #70780 [#70865][#70865]
- Earlier the behavior of casting an int to "char" was similar to bpchar where we returned only the first digit of the integer. Now, we are interpreting int cast to "char" as an ASCII byte to align the overall behavior more with PostgreSQL. [#70942][#70942]
- A parameter of type "char" can now be used as a parameter in a prepared statement. [#70942][#70942]
- The `information_schema._pg_numeric_precision`, `information_schema._pg_numeric_precision_radix` and `information_schema._pg_numeric_scale` builtin functions are now supported, which improves compatability with PostgreSQL. [#70881][#70881]
- If the time zone is set in a GMT offset, for example +7 or -11, the timezone will be formatted as <+07>-07 and <-11>+11 respectively instead of +7, -11.  This most notably shows up when doing SHOW TIME ZONE. [#70716][#70716]
- SQL tenants will now spill to disk by default when processing large queries, instead of memory. [#71040][#71040]
- NULLS FIRST and NULLS LAST specifiers now supported for ORDER BY. [#71083][#71083]
- SHOW CREATE ALL SCHEMAS is a command that allows the user to get the statements to recreate the schemas of the current database. The command returns a flat log of the create statements for schemas. [#71138][#71138]
- The session variable `inject_retry_errors_enabled` has been added. When this is true, any statement that is a not a SET statement will return a transaction retry error if it is run inside of an explicit transaction. If the client retries the transaction using the special cockroach_restart SAVEPOINT, then after the 3rd error, the transaction will proceed as normal. Otherwise, the errors will continue until `inject_retry_errors_enabled` is set to false. The purpose of this setting is to allow developers to test their transaction retry logic. [#71357][#71357]
- Fixed an oversight in which a full scan of a partial index could be rejected due to the disallow_full_table_scans setting. Full scans of partial indexes will no longer be rejected if disallow_full_table_scans is true, since a full scan of a partial index must be a constrained scan of the table. [#71317][#71317]
- The optimizer has been updated so that if disallow_full_table_scans is true, it will never plan a full table scan with an estimated row count greater than large_full_scan_rows. If no alternative plan is possible, an error will be returned, just as it was before. However, cases where an alternative plan is possible will no longer produce an error, since the alternative plan will be chosen. As a result, users should see fewer errors due to disallow_full_table_scans.  A side effect of this change is that if disallow_full_table_scans is set along with statement-level hints such as an index hint, the optimizer will try to avoid a full scan while also respecting the index hint. If this is not possible, the optimizer will return an error and might not log the attempted full table scan or update the sql.guardrails.full_scan_rejected.count metric. If no index hint is used, the full scan will be logged and the metric updated. [#71317][#71317]
- Added support for a new index hint, NO_FULL_SCAN, which will prevent the optimizer from planning a full scan for the specified table. The hint can be used in the same way as other existing index hints. For example, SELECT * FROM table_name@{NO_FULL_SCAN};. Note that a full scan of a partial index may still be planned, unless NO_FULL_SCAN is forced in combination with a specific partial index via FORCE_INDEX=index_name. [#71317][#71317]
- Fix bug where previously CURRENT_USER and SESSION_USER were parsed incorrectly. [#70439][#70439]
- Arrays of enums can now be compared. [#71427][#71427]
- NULLS can be ordered NULLS LAST by default if the `null_ordered_last` session variable be set to true. [#71429][#71429]
- Previously, comparing against `bytea[]` without a cast (e.g. `SELECT * FROM t WHERE byteaarrcol = '{}'`) would result in an ambiguous error. This has now been resolved. [#71501][#71501]
- Previously, placeholders in ARRAY would resolve in an ambiguous error (e.g. `SELECT ARRAY[$1]::int[]`). This is now fixed. [#71432][#71432]
- RESTORE TABLE for a regional by row table into a multiregion database with the same regions as the backed up database, is now allowed. The user has to ensure that the regions in the backed up database, and the database being restored into match, and are added in the same order, for the RESTORE to work. [#71178][#71178]
- EXPLAIN output now displays limit hint when limit hint is nonzero as part of the 'estimated row count' field. [#71299][#71299]
- Implicit casts performed during INSERT statements now more closely follow Postgres's behavior. Several minor bugs related to these types of casts have been fixed. [#70722][#70722]
- Newly created tables now have `<table_name>_pkey` by default as their index/constraint name. [#70604][#70604]
- Newly created FOREIGN KEYs now have the same constraint name as postgres - `<table>_<cols>_fkey`. Previously, this was `fk_<cols>_ref_<target>`. [#70658][#70658]
- CURRENT_USER and SESSION_USER can now be used as the role identifier in ALTER ROLE statements. [#71498][#71498]
- Array builtin functions can now be used with arrays of enums. [#71482][#71482]
- Statements containing multiple INSERT ON CONFLICT, UPSERT, UPDATE, or DELETE subqueries can cause data corruption if they modify the same row multiple times. For example, the following SELECT 1 statement will cause corruption of table t:  ```sql CREATE TABLE t (i INT, j INT, PRIMARY KEY (i), INDEX (j)); INSERT INTO t VALUES (0, 0); WITH   cte1 AS (UPDATE t SET j = 1 WHERE i = 0 RETURNING *),   cte2 AS (UPDATE t SET j = 2 WHERE i = 0 RETURNING *) SELECT 1; ```  Until this is fixed, this change disallows statements with multiple subqueries which modify the same table. Applications can work around this by rewriting problematic statements. For example, the query above can be rewritten as an explicit multi-statement transaction:  ```sql BEGIN; UPDATE t SET j = 1 WHERE i = 0; UPDATE t SET j = 2 WHERE i = 0; SELECT 1; COMMIT; ```  or, if it doesn't matter which update "wins", as multiple non-mutating CTEs on an UPDATE statement:  ```sql WITH   cte1 AS (SELECT 1),   cte2 AS (SELECT 2) UPDATE t SET j = x.j FROM (SELECT * FROM cte1 UNION ALL SELECT * FROM cte2) AS x (j) WHERE i = 0 RETURNING 1; ```  which in this case could be written more simply as:  ```sql UPDATE t SET j = x.j FROM (VALUES (1), (2)) AS x (j) WHERE i = 0 RETURNING 1; ```  (Note that in these last two rewrites the first update will win, rather than the last.) None of these rewrites suffer from the corruption problem.  To override this change and allow these statements in spite of the risk of corruption, applications can:  ```sql SET CLUSTER SETTING sql.multiple_modifications_of_table.enabled = true ```  But be warned that with this enabled there is nothing to prevent this type of corruption from occuring if the same row is modified multiple times by a single statment.  To check for corruption, use the EXPERIMENTAL SCRUB command:  ```sql EXPERIMENTAL SCRUB TABLE t WITH OPTIONS INDEX ALL; ``` [#70976][#70976]
- Introduce an implicitly-defined type for every table, which resolves to a tuple type that contains all of the columns in the table. [#70100][#70100]
- Add new formatting functions to create summarized queries for SELECT, INSERT, and UPDATE statements. Also add new metadata fields, which will later be used to pass this information to the front-end Statements page. [#71012][#71012]
- `aggregation_interval` column has been added to crdb_internal.{statement,transaction}_statistics tables, representing the aggregation duration. [#71538][#71538]
- The WITH RECURSIVE variant that uses UNION (as opposed to UNION ALL) is now supported. [#71685][#71685]
- Infinite decimal values can now be encoded when sending data to/from the client. The encoding matches the PostgreSQL encoding. [#71772][#71772]
- EXPLAIN ANALYZE (DEBUG) can now be used by tenants. [#71680][#71680]
- Previously, certain enum builtins or operators required an explicit enum cast. This has been reduced in some cases. [#71653][#71653]
- Remove the cluster setting sql.defaults.interleaved_tables.enabled, since interleaved support is fully removed now. [#71537][#71537]
- Record compressed plan gist for all queries. For example, a query like this:  SELECT * FROM abc UNION SELECT * FROM abc ORDER BY b,a  Produces the following plan according to EXPLAIN (SHAPE)  • distinct │ distinct on: a │ └── • union all     │     ├── • sort     │   │ order: +b,+a     │   │     │   └── • scan     │         missing stats     │         table: abc@primary     │         spans: FULL SCAN     │     └── • sort         │ order: +b,+a         │         └── • scan               missing stats               table: abc@primary               spans: FULL SCAN  produces the following "gist":  AgFuAgAHAAAAEQFuAgAHAAAAERANAAYGAA==  The "gist" can be turned back into the following plan:  • distinct │ distinct on │ └── • union all     │     ├── • sort     │   │ order     │   │     │   └── • scan     │         table: abc@primary     │         spans: FULL SCAN     │     └── • sort         │ order         │         └── • scan               table: abc@primary               spans: FULL SCAN [#69293][#69293]
- T_unknown ParamaterTypeOIDs in the PostgreSQL Frontend/Backend protocol are now correctly handled. [#71971][#71971]
- String literals can now be parsed as tuples, either in a cast expression, or in other contexts like function arguments. [#71916][#71916]
- The session variables LC_COLLATE, LC_CTYPE, LC_MESSAGES, LC_MONETARY, LC_NUMERIC, and LC_TIME were added for compatibility with PostgreSQL. They only support the C.UTF-8 locale. [#72109][#72109]
- Add function crdb_internal.reset_index_usage_stats() to clear index usage stats. This can be invoked from the SQL shell. [#71896][#71896]
- Custom session options can now be used, i.e. any session variable that has `.` in the name. [#71915][#71915]
- Adds logic to process an EXPORT PARQUET command [#71868][#71868]
- Adds ability to EXPORT PARQUET for relations with float, int, string column types. [#71868][#71868]
- This change removes support for: - `IMPORT TABLE ... CREATE USING` - `IMPORT TABLE ... <non-bundle-format> DATA`  <non-bundle-format> refers to CSV, Delimited, PGCOPY, AVRO. These formats do not define the table schema in the same file as the data.  The workaround following this feature removal is to use `CREATE TABLE` with the same schema that was previously being passed into the IMPORT statement, followed by an `IMPORT INTO` the newly created table. [#71058][#71058]
- Previously if you did comment on constraint on a table in a schema the command would succeed but the comment would not actually created. Now the comment is successfully created. [#71985][#71985]
- Table backups of regional-by-row, regional-by-table, and global table are no longer disallowed. [#71186][#71186]
- Removed INTERLEAVE IN PARENT. [#70618][#70618]
- Explain analyze now shows maximum allocated memory and maximum sql temp disk usage for a statement. [#72113][#72113]
- SHOW CREATE ALL TYPES is a command that allows the user to get the statements to recreate user-defined types of the current database. The command returns a flat log of the create statements for types. [#71326][#71326]
- It's now possible to swap names (for tables, etc.) in the same transaction. For example:    CREATE TABLE foo();   BEGIN;   ALTER TABLE foo RENAME TO bar;   CREATE TABLE foo();   COMMIT;  Previously, we'd be getting a "relation ... already exists" error. [#70334][#70334]
- To align with PostgreSQL, casting an OID type with a value of `0` to a regtype, regproc, regclass, or regnamespace now will convert the value to the string `-`. The reverse behavior is implemented too, so a `-` will become `0` if casted to a `reg` OID type. [#71873][#71873]
- Implement the date_part builtin. [#72502][#72502]
- PRIMARY KEYs have been renamed to conform to postgres (e.g. `@tbl_col1_col2_pkey`) in this release. To protect certain use cases of backwards compatibility, we also allow `@primary` index hints to alias to the PRIMARY KEY, but only if no other index is named `primary`. [#72534][#72534]
- Previously, in-memory SQL Stats was reset periodically. This behavior is now removed since persisted SQL Stats is introduced in 21.2. As the result, diagnostics.sql_stats_reset.interval cluster setting is removed. diagnostics.forced_sql_stats_reset.interval now only controls the reset of the reported SQL Stats if it is not collected by the telemetry reporter. [#71597][#71597]
- Some filesystem-level properties are now exposed in `crdb_internal.kv_store_status`. Note that the particular fields and layout are not stabilized yet. [#72435][#72435]
- Introduce a builtin function "crdb_internal.init_stream" and a cluster setting "stream_replication.job_liveness_timeout". [#72330][#72330]
- A notice is now issued when creating a foreign key referencing a column of a different width [#72545][#72545]
- Newly created databases will now have the CONNECT privilege granted by default to the PUBLIC role. [#72595][#72595]
- SQL Stats metrics with *_internal suffix in their labels are now removed. [#72667][#72667]
- `system.table_statistics` has an additional field, `avgSize`, that is the average size in bytes of the column(s) with `columnIDs`. The new field is visible with the command `SHOW STATISTICS FOR TABLE` and can be modified with the command `INJECT STATISTICS`, as with other table statistics. This field is not yet used by the optimizer as part of cost modeling. [#72365][#72365]
- Added ALTER TABLE ... ADD CONSTRAINT IF NOT EXISTS. [#71257][#71257]
- Fix the asyncpg tests to hit cockroach [#72161][#72161]
- Fix `gateway_region` for `--multitenant` demo clusters. [#72734][#72734]
- Prior to this change it was possible to alter a columns type in a way that was not compatible with the DEFAULT or ON UPDATE clause. This would cause parsing errors within tables. Now the DEFAULT/ON UPDATE clause is checked. [#71423][#71423]
- The experimental `ALTER COLUMN TYPE` statement is no longer permitted when the column is stored in a secondary index. Prior to this change, that was the only sort of secondary index membership which was allowed, but the result of the operation was a subtly corrupted table. [#72777][#72777]
- Added CREATE SEQUENCE AS <typename> option. [#57339][#57339]
- Introduce new SQL syntax ALTER RANGE RELOCATE to move a lease or replica between stores. This is helpful in an emergency situation to relocate data in the cluster. [#72305][#72305]
- Fixes a bug which allowed computed columns to also have DEFAULT expressions. [#73090][#73090]
- Users can now export relations with null values to parquet files.  Informs: #67710 [#72530][#72530]
- Previously, ALTER TABLE ... RENAME TO ... would allow the user to move the table from a database to another if the table is being moved within one database's public schema to another. This is now disallowed.  sql: explicitly disallow dropping public schema and reassigning public schema owner  from one database's public schema to another was previously possible using ALTER TABLE RENAME due to the public schema being a special case, now that the public schema is a regular user defined schema with a descriptor, this is no longer the case. [#72000][#72000]
- Previously, ALTER TABLE ... RENAME TO ... would allow the user to move the table from a database to another if the table is being moved within one database's public schema to another. This is now disallowed.  sql: explicitly disallow dropping public schema and reassigning public schema owner  This maintains behaviour from 21.2 and prior. We can revisit this in 22.1 and remove these restrictions  Release justification: None  sql: update tests resulting from public schema being an explicit schema  Test updates include: rttanalysis updates fixing sql tests and logic tests that previously used hardcoded 53 as an id TestDoctorZipDir and TestDoctorCluster  Release justification: None, waiting for 22.1.  sql: disallow alter database convert to schema on versions with explicit public schemas [#72000][#72000]
- ALTER DATABASE CONVERT TO SCHEMA is now disabled on versions 22.1+.  sql: rebase logic test changes [#72000][#72000]
- The structured payloads used for telemetry logs now include two new fields: CostEstimate and Distribution. CostEstimate is the cost of the query as estimated by the optimizer, and Distribution is the distribution of the DistSQL query plan (local, full, or partial). [#73278][#73278]
- User can now specify a different path for their incremental backups. [#72713][#72713]
- The `CREATE ROLE` and `ALTER ROLE` statements now accept password hashes computed by the client app. For example: `CREATE USER foo WITH PASSWORD 'CRDB-BCRYPT$2a$10$.....'`.  Note: this feature is not meant for use by human users / in interactive sessions; it is meant for use in programs, using the computation algorithm described below.  This auto-detection can be disabled by changing the cluster setting `server.user_login.store_client_pre_hashed_passwords.enabled` to `false`.  Note: this design mimics the behavior of PostgreSQL, which recognizes pre-computed password hashes when presented to the regular PASSWORD option (https://www.postgresql.org/docs/14/sql-createrole.html).  The password hashes are auto-detected based on their lexical structure. For example, any password that starts with the prefix `CRDB-BCRYPT$`, followed by a valid encoding of a bcrypt hash (as detailed below), is considered a candidate password hash.  To ascertain whether a password hash will be recognized as such, orchestration code can use the new built-in function `crdb_internal.check_password_hash_format()`.  Currently, CockroachDB only recognizes password hashes computed using Bcrypt, as follows (we detail this algorithm so that orchestration software can implement their own password hash computation, separate from the database):  1. take the cleartext password string. 2. append the following byte array to the password:    e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855    (these are 32 hex-encoded bytes)     (What are these bytes? it's the SHA-256 hash of an empty string. Why    is it appended? This is a historical oddity in the CockroachDB with    no particular reason. It adds no security.)  3. choose a Bcrypt cost. (CockroachDB servers use cost 10 by default.) 4. generate a bcrypt hash of the string generated at step 2 with the    cost chosen at step 3, as per     https://en.wikipedia.org/wiki/Bcrypt     or     https://bcrypt.online/     Note: at this point, CockroachDB only supports hashes computed using    Bcrypt version 2a.  5. Encode the hash into the format recognized by CockroachDB: the    string `CRDB-BCRYPT`, followed by the standard bcrypt hash    encoding (`$2a$...`).  Summary:  | Hash method     | Recognized by `check_password_hash_format()` | ALTER/CREATE USER WITH PASSWORD           | |-----------------|----------------------------------------------|-------------------------------------------| | `crdb-bcrypt`   | yes (`CRDB-BCRYPT$2a$...`)                   | recognized if enabled via cluster setting | | `scram-sha-256` | yes (`SCRAM-SHA-256$4096:...`)               | not implemented yet (issue #42519)        | | `md5`           | yes (`md5...`)                               | obsolete, will likely not be implemented  | [#72579][#72579]
- If the WITH GRANT OPTION flag is present when granting privileges to a user, then that user is able to grant those same privileges to subsequent users; otherwise, they cannot. If the GRANT OPTION FOR flag is present when revoking privileges from a user, then only the ability the grant those privileges is revoked from that user, not the privileges themselves (otherwise both the privileges and the ability to grant those privileges are revoked). This behavior is consistent with Postgres.  For example, let's say we have a user named Alice who is the admin of a database that contains a table named t. If she wanted to give read access to Bob on t but did not want him to be able to give that privilege to anyone else, she could do this with the command 'GRANT SELECT ON TABLE t TO bob'. However, if she wanted Bob to be able to give the SELECT privilege on table t to other users, she would grant him the ability to do so with the command 'GRANT SELECT ON TABLE t TO bob WITH GRANT OPTION'.  If Alice changed her mind and decided she did not want Bob to have the ability to grant read access on table t to other users (but she still wanted Bob himself to have read access on table t), she could revoke his ability to do so with the command 'REVOKE GRANT OPTION FOR SELECT ON TABLE t FROM bob'. Alternatively, she could omit the flag and do 'REVOKE SELECT ON TABLE t FROM bob' to remove Bob's read access on table t in addition to his ability to grant read access to other users. [#72123][#72123]
- Disallow ST_MakePolygon from making empty polygons from empty linestrings. This is not allowed in PostGIS. [#73489][#73489]
- Introduce a replication builtin crdb_internal.replication_stream_progress(stream_id, frontier_ts). [#73321][#73321]
- New column `stmt` has been added to `crdb_internal.(cluster|node)_distsql_flows` virtual table. It is populated on a best effort basis. [#73522][#73522]
- The `create_type_statements` table now has an index on `descriptor_id`. [#73635][#73635]
- EXPORT PARQUET now preserves column names and nullability. [#73382][#73382]
- SHOW CREATE VIEW returns prettier SQL. [#73642][#73642]
- The output of the EXPLAIN SQL statement has changed. Below the plan, we now output index recommendations for the SQL statement being "EXPLAIN-ed", if there are any. These index recommendations are indexes the user could add or indexes they could replace to make the given query faster. [#73302][#73302]
- The void type is now recognized in CockroachDB. [#73488][#73488]
- In the experimental RELOCATE syntax forms, the positional keyword that indicates that the statement should move non-voter replicas is now spelled `NONVOTERS`, instead of `NON_VOTERS` previously. [#73803][#73803]
- The inline help for the ALTER statements now mentions the RELOCATE syntax. [#73803][#73803]
- In the experimental RELOCATE syntax forms, the positional keyword that indicates that the statement should move non-voter replicas is now spelled `NONVOTERS`, instead of `NON_VOTERS` previously. [#73802][#73802]
- The inline help for the ALTER statements now mentions the RELOCATE syntax. [#73802][#73802]
- The experimental ALTER RANGE...RELOCATE syntax now accepts arbitrary scalar expressions as the source and target store IDs. [#73807][#73807]
- The output of `EXPLAIN ALTER RANGE ... RELOCATE` now includes the source and target store IDs. [#73807][#73807]
- The experimental ALTER RANGE...RELOCATE syntax now accepts arbitrary scalar expressions as the range ID when the FOR clause is not used. [#73807][#73807]
- The output of `EXPLAIN ALTER RANGE ... RELOCATE` now includes which replicas are subject to the relocation. [#73807][#73807]
- Support ALTER DEFAULT PRIVILEGES IN SCHEMA <schemas...> Users can now in addition to specifying default privileges globally (within a database), specify default privileges in a specific schema.  When creating an object that has default privileges specified at the database (global) and at the schema level, the union of the default privileges are taken. [#73576][#73576]
- Index recommendations can be omitted from the EXPLAIN plan if the `index_recommendations_enabled` session variable is set to false. [#73346][#73346]
- The cluster setting that controls the default for the session setting reorder_joins_limit, called sql.defaults.reorder_joins_limit, is now public and included in the docs. [#73877][#73877]
- The output of `EXPLAIN ALTER INDEX/TABLE ... RELOCATE/SPLIT` now includes the target table/index name and, for the SPLIT AT variants, the expiry timestamp. [#73832][#73832]
- The digest and hmac builtin functions were added. They match the PostgreSQL (pgcrypto) implementation. Supported hash algorithms are md5, sha1, sha224, sha256, sha384, and sha512. [#73935][#73935]
- Users can now RESTORE [locality aware] incremental backups created with the 'incremental_storage' parameter. [#73744][#73744]
- The RULE privilege was added for compatbility with Postgres. It is impossible to grant it, but it is supported as a parameter of the has_table_privilege function. [#73960][#73960]
- Improves cost model for TopK expressions if the input to TopK can be partially ordered by its sort columns. [#73459][#73459]
- User can now observe incremental backups created using the 'incremental_storage' option. [#73357][#73357]
- Escape character processing was missing from constraint span generation which resulted in incorrect results when doing escaped like lookups. [#73978][#73978]
- Shard column of hash sharded index is now a virtual column instead of stored. [#74138][#74138]
- Clients waiting for a schema change job will now receive an error if the job they are waiting for is paused. [#74157][#74157]
- Exposed ByteSize method for a catalog.Descriptor for memory monitoring purposes. [#73344][#73344]
- We will be deprecating the GRANT privilege in 22.1 before eventually removing it in 22.2 in favor of grant options. To promote backwards compatibility for users with code still using GRANT, we will give grant options on every privilege a user has when they are granted GRANT and remove all their grant options when GRANT is revoked, in addition to the existing grant option behavior. [#74210][#74210]
- `system.protected_timestamp_records` table now has an additional `target` column that will store an encoded protobuf that represents the target a record protects. This target can either be the entire cluster, tenants, or schema objects (databases/tables). [#74281][#74281]
- The KV tracing of SQL queries (that could be obtained with `\set auto_trace=on,kv`) has been adjusted slightly. Previously, we would fully decode the key part of each key-value pair even if some part of the key would not be decoded when tracing is enabled. Now, we won't perform any extra decoding, and parts of the key that aren't decoded are replaced with `?`. [#74236][#74236]
- We now support `default_with_oids` which only accepts being false. [#74499][#74499]
- EXPORT PARQUET can export columns of type array [#73735][#73735]
- System-only cluster settings are no longer visible for non-system tenants. [#74253][#74253]
- Statements are now formatted prior to being send to the UI, this is done using a new builtin function that formats statements. [#73853][#73853]
- Before this change, the check constraint on shard column used by hash sharded index was printed in the corresponding `SHOW CREATE TABLE`. The constraint had been shown because cockroach lacked logic to ensure that shard columns which are part of hash sharded indexs always have the check constraint which the optimizer relies on to achieve properly optimized plans on hash sharded indexes. We no longer display this constraint in `SHOW CREATE TABLE` as it is now implied by the `USING HASH` clause on the relevant index. [#74179][#74179]
- The experimental SCRUB PHYSICAL is no longer implemented. [#74761][#74761]
- The `xmloption` session variable is now accepted, only taking in `content`. Note this does not do anything. [#74664][#74664]
- `CREATE MATERIALIZED VIEW` syntax now supported `WITH DATA`. [#74821][#74821]
- Introduce builtin function for stream replication: crdb_internal.replication_stream_spec. [#73886][#73886]
- Creation of the new role `VIEWACTIVITYREDACTED` that works similar as VIEWACTIVITY but restricts the usage of Statements Diagnostics Bundle. It is possible for a user to have both roles (VIEWACTIVITY and VIEWACTIVITYREDACTED), but the role VIEWACTIVITYREDACTED takes precedent on restrictions. [#74715][#74715]
- Add support for the ON CONFLICT ON CONSTRAINT form of INSERT ON CONFLICT. This form is added for compatibility with PostgreSQL. It permits explicitly selecting an arbiter index for INSERT ON CONFLICT, rather than inferring one using a column list, which is the default behavior. [#73460][#73460]
- Support setting `check_function_bodies`. Note this doesn't variable doesn't do anything. [#74828][#74828]
- Import now checks readability earlier for multiple files, to fail sooner if e.g. permissions are invalid. [#74863][#74863]
- A new role option is now available, `NOSQLLOGIN` (and its inverse `SQLLOGIN`), which restricts SQL CLI login ability for a user while retaining their ability to login to the DB Console (as opposed to `NOLOGIN` which restricts both SQL and DB Console). Without any role options all login behavior remains permitted as it does today. OIDC logins to the DB Console continue to be permitted with `NOSQLLOGIN` set. [#74706][#74706]
- Support the `default_table_access_method` session variable, which only takes in `heap` (same as PG). [#74774][#74774]
- The distributed plan diagram now lists scanned column names for TableReaders. [#75114][#75114]
- Allow users to specify the owner when creating a database. 			   Similar to postgresql: CREATE DATABASE name     							[ [ WITH ] [ OWNER [=] user_name ] [#74867][#74867]
- The `CREATE ROLE` and `ALTER ROLE` statements now accept password hashes computed using the SCRAM-SHA-256 method, for example: `CREATE USER foo WITH PASSWORD 'SCRAM-SHA-256$4096:B5VaT...'`.  As for other types of pre-hashed passwords, this auto-detection can be disabled by changing the cluster setting `server.user_login.store_client_pre_hashed_passwords.enabled` to `false`.  To ascertain whether a SCRAM-SHA-256 password hash will be recognized as such, orchestration code can use the built-in function `crdb_internal.check_password_hash_format()` that had been previously introduced.  The encoding of the SCRAM-SHA-256 password should be performed as follows:  1. take the cleartext password string. 2. generate a salt, iteration count, stored key and server key as per    [RFC 5802](https://datatracker.ietf.org/doc/html/rfc5802). 3. encode the hash into the format recognized by CockroachDB: the    string `SCRAM-SHA-256$`, followed by the iteration count,    followed by `:`, followed by the base64-encoded salt, followed    by `$`, followed by the base-64 stored key, followed by `:`,    followed by the base-64 server key. [#74301][#74301]
- The session variable `password_encryption` is now exposed to SQL clients. Note that SQL clients cannot modify its value directly; it is configurable via a cluster setting. [#74301][#74301]
- When possible, CockroachDB will now automatically require the PostgreSQL-compatible SCRAM-SHA-256 protocol when performing password validation when SQL client log in. (Reminder: this mechanism is not used when SQL clients use TLS client certs, which is the recommended approach.)  This assumes support for SCRAM-SHA-256 in client drivers. As of 2020, we have found this to be prevalent in the pg driver ecosystem. However, users should be mindful of the following possible behavior changes:  - an application that tries to detect whether password verification   has failed by checking server error messages, might observe   different error messages with SCRAM-SHA-256. Those checks, if   present, need to be updated.  - if a client driver simply does not support SCRAM-SHA-256 at all,   the operator retains the option to set the cluster setting   `server.user_login.cert_password_method.auto_scram_promotion.enable`   to `false` to force the previous password verification method instead. [#74301][#74301]
- After a cluster upgrade, the first time a SQL client logs in using password authentication, the password will be converted to a new format (`scram-sha-256`) if it was encoded with `crdb-bcrypt` previously.  This conversion will increase the latency of that initial login by a factor of ~2x, but it will be reduced again after the conversion completes.  When login latency is a concern, operators are invited to perform the password conversion ahead of time, by computing new SCRAM hashes for the clients via ALTER USER/ROLE WITH PASSWORD.  This conversion can also be disabled via the new cluster setting `server.user_login.upgrade_bcrypt_stored_passwords_to_scram.enabled`. [#74301][#74301]
- Statements are no longer formatted prior to being sent to the UI, but the new builtin function remains. [#75443][#75443]
- The default sql stats flush interval is now 10 minutes. A new cluster setting `sql.stats.aggregatinon.interval` controls the aggregation interval of sql stats, with a default value of 1 hour. [#74831][#74831]
- SELECT, INSERT, DELETE, UPDATE can no longer be granted/revoked on databases. Previously SELECT, INSERT, DELETE, UPDATE would be converted to ALTER DEFAULT PRIVILEGES on GRANTs and were revokable but now they are no longer revokable either. [#72665][#72665]
- Added pgcodes to errors when an invalid storage parameter is passed. [#75262][#75262]
- Implemented the `ALTER TABLE ... SET (...)` syntax. This mostly no-ops as we do not support any storage parameters (yet). [#75262][#75262]
- SHOW GRANTS ON TABLE includes is_grantable column [#75226][#75226]
- Implemented the `ALTER TABLE ... RESET (...)` syntax. This is currently a no-op operation. [#75429][#75429]
- S3 URIs used for BACKUPs, EXPORTs or CHANGEFEEDs can now include the query paramter S3_STORAGE_CLASS to configure the storage class used when that job creates objects in the designated S3 bucket. [#75588][#75588]
- Modifies query cost based on the `avg_size` table statistic, which may change query plans. This is gated by the session setting `cost_scans_with_default_col_size`, and can be disabled by setting it to true via `SET cost_scans_with_default_col_size=true`. [#74551][#74551]
- The crdb_internal.jobs table now has a new column `execution_events` which is a structured json form of `execution_errors`. [#75556][#75556]
- The privileges reported in information_schema.schema_privileges for non-user-defined schemas no longer are inferred from the privileges on the parent database. Instead, virtual schemas (like pg_catalog and information_schema) always report the USAGE privilege for the public role. The pg_temp schema always reports USAGE and CREATE privileges for the public role. [#75628][#75628]
- Transaction ID to Transaction Fingerprint ID mapping is now stored in the new Transaction ID Cache, a FIFO unordered in-memory buffer. The size of the buffer is 64 MB by default and configurable via sql.contention.txn_id_cache.max_size cluster setting. Consequentially, two additioanl metrics are introduced: * sql.contention.txn_id_cache.size: tracks the current memory usage   of transaction ID Cache * sql.contention.txn_id_cache.discarded_count: number of resolved   transaction IDs that are dropped due to memory constraints. [#74115][#74115]
- Added new builtin functions called crdb_internal.revalidate_unique_constraint, crdb_internal.revalidate_unique_constraints_in_table, and crdb_internal.revalidate_unique_constraints_in_all_tables, which can be used to revalidate existing unique constraints. The different variations support validation of a single constraint, validation of all unique constraints in a table, and validation of all unique constraints in all tables in the current database, respectively. If any constraint fails validation, the functions will return an error with a hint about which data caused the constraint violation. These violations can then be resolved manually by updating or deleting the rows in violation. This will be useful to users who think they may have been affected by #73024. [#75548][#75548]
- SHOW GRANTS ON SCHEMA includes is_grantable column [#75722][#75722]
- Disallow type cast from ENUM to BYTES [#75816][#75816]
- EXPORT PARQUET has a new 'compression' option whose value can be 'gzip' or 'snappy'. An example query:  `EXPORT INTO PARQUET 'nodelocal://0/compress_snappy' WITH compression = snappy    FROM SELECT * FROM foo `  By default, the parquet file will be uncompressed. With compression, the file name will be '[filename].parquet.gz' or '[filename].parquet.snappy'. [#74661][#74661]
- Previously, users would be able to set a UTC timezone offset of greater than 167 or less than -167. This now returns an error.  Example:  SET TIME ZONE '168' Gives error: invalid value for parameter "timezone": "'168'": cannot find time zone "168": UTC timezone offset is out of range.  SET TIME ZONE '-168' Gives error: invalid value for parameter "timezone": "'-168'": cannot find time zone "-168": UTC timezone offset is out of range. [#75822][#75822]
- Support for the RESET ALL statement was added. This statement resets the values of all session variables to their default values. [#75804][#75804]
- SHOW GRANTS ON DATABASE includes is_grantable column [#75854][#75854]
- Reordered unimplemented tables in pg_catalog and information_schema to match postgresql [#75461][#75461]
- CockroachDB no longer supports incompatible database privileges to be consistent with Postgres.  SELECT, INSERT, UPDATE, DELETE can no longer be granted/revoked on databases.  Note that these privileges were already deprecated and could not be granted in the previous version but were automatically converted to default privileges.  Existing SELECT, INSERT, UPDATE, DELETE privileges on databases will be converted to the equivalent default privileges.  I.e., If GRANT SELECT ON DATABASE test TO ... was run before 22.1, the SELECT is converted to the equivalent default privilege that is granted by running USE test; ALTER DEFAULT PRIVILEGES FOR ALL ROLES GRANT SELECT ON TABLES TO ...; [#75562][#75562]
- Allow users who are not admin to SHOW RANGES if ZONECONFIG is granted [#75551][#75551]
- Previously, `WITH (param=value)` syntax is not allowed for primary key. However, that does not align with postgresql. Also, to support `WITH (bucket_count=...)` syntax for hash sharded index, we need to enable it as well. This pr also adds extra validation to prevent existing storage params from being applied to primary keys. Which means, even the syntax is accepted by the parser, none of existing storage param for inverted index is allowed on primary key. We don't actually set those params on top of PKs internally, but we need to tell user which param is supprted or not. Eventually, when we add support for `bucket_count` param, a param white list will be maintained for PKs. [#75971][#75971]
- Alias the `idle_session_timeout` session variable with the `idle_in_session_timeout` variable - the former of which aligns with the PG14 name and the latter introduced by us beforehand. Setting or getting either session variable will alter or return the same thing. [#76002][#76002]
- SHOW GRANTS ON TYPE includes is_grantable column [#75957][#75957]
- `bucket_count` storage parameter is added. To create hash sharded index, now we may use the new syntax: `USING HASH WITH (bucket_count=xxx)`. `bucket_count` storage param can only be use together with `USING HASH`. The old `WITH BUCKET_COUNT=xxx` syntax is still supported for backward compatibility. However, only either the old or new syntax can be used, but not both. Err is returned for clause like `USING HASH WITH BUCKET_COUNT=5 WITH (bucket_count=5). [#76068][#76068]
- `bulkio.backup.merge_file_buffer_size` default value has been changed from 16MiB to 128MiB. This value determines the maximum byte size of SSTs that we buffer before forcing a flush during a backup. [#75988][#75988]
- We have add support for the new `bucket_count` storage param syntax. We prefer it over the old `WITH BUCKET_COUNT=xxx` syntax. With this change, crdb outputs the new syntax for `SHOW CREATE`. Though for the AST tree formatting, we still respect the old syntax if user used it. [#76112][#76112]
- Saving plan hash/gist to the Statements persisted stats inside Statistics column. [#75762][#75762]
- Added PG error codes to the majority of spatial related functions. [#76129][#76129]
- BACKUPs of ranges containing extremely large numbers of revisions to a single row no longer fail with errors related to exceeding size limit. [#76254][#76254]
- 16 is used as the default bucket count for hash sharded index. [#76115][#76115]
- Filter out internal statements and transactions from UI timeseries metrics. [#75815][#75815]
- EXPORT PARQUET now supports all data types that avro change feeds supports. Below I list the data type converstion from CRDB to Parquet. To maintain backward compatibality with older parquet readers, parquet converted types were also annotated.  To learn about more about parquet data representation,  see https://github.com/apache/parquet-format  CRDB Type Family ->  Parquet Type | Parquet Logical Type | Parquet Converted Type Bool -> boolean | nil | nil String -> byte array | string | string Collated String -> byte array | string| string INet -> byte array | string | string JSON -> byte array | json | json Int (oid.T_int8) -> int64 | int64 | int64 Int (oid.T_int4 or oid.T_int2) -> int32 | int32 | int32 Float -> float64 | nil | nil Decimal -> byte array | decimal (note: scale and precision data are preserved in the parquet file) | decimal Uuid -> fixed length byte array (16 bytes) | uuid | no converted type Bytes -> byte array | nil | nil Bit -> byte array | nil | nil Enum -> byte array | Enum | Enum Box2d -> byte array | string | string Geography -> byte array | nil | nil Geometry -> byte array | nil | nil Date -> byte array | string | string Time -> int64 | time (note: microseconds since midnight) | time TimeTz -> byte array | string | string Interval -> byte array | string (specifically represented as ISO8601) | string Timestamp -> byte array | string | string TimestampTz -> byte array | string | string Array -> encoded as a repeated field and each array value gets encoded by pattern described above. Logical type and converted type are both 'List' [#75890][#75890]
- SHOW CREATE TABLE no longer shows the FAMILY clause if there is only the PRIMARY family clause. [#76285][#76285]
- The database now records the approximate time when an index was created it. This information is exposed via a new NULL-able TIMESTAMP column, `created_at`, on `crdb_internal.table_indexes`. [#75753][#75753]
- Added support for query cancellation via the pgwire protocol. CockroachDB will now respond to a pgwire cancellation by forwarding the request to the node that is running a particular query. That node will then cancel the query that is currently running in the session identified by the cancel request. The cancel request is made through the pgwire protocol when initializing a new connection. The client must first send 32 bits containing the integer 80877102, followed immediately by the 64-bit BackendKeyData message that the server sent to the client when the session was started. Most Postgres drivers handle this protocol already, so there's nothing for the end-user to do apart from calling the "cancel" function that their driver offers.  See https://www.postgresql.org/docs/13/protocol-flow.html#id-1.10.5.7.9 [#67501][#67501]
- Refactored BACKUP, SHOW BACKUP, and RESTORE incremental_storage option to incremental_location. [#76416][#76416]
- Restored data now appears to have been written at the time it was restored, rather than the time at which it was backed up, when reading the lower-level write timestamps from the rows themselves. This affects various internal operations and the result of crdb_internal_mvcc_timestamp. [#76271][#76271]
- The buil-in functions `crdb_internal.force_panic`, `crdb_internal.force_log_fatal`, `crdb_internal.set_vmodule`, `crdb_internal.get_vmodule` are now available to all `admin` users, not just `root`. [#76518][#76518]
- BACKUP of a table marked with `exclude_data_from_backup` via `ALTER TABLE ... SET (exclude_data_from_backup = true)` will no longer backup that table's row data. The backup will continue to backup the table's descriptor and related metadata, and so on restore we will end up with an empty version of the backed up table. [#75451][#75451]
- Failed DROP INDEX schema changes are no longer rolled back. Rolling back a failed DROP INDEX requires the index to be rebuilt -- a potentially long-running, expensive operation. Further, in previous versions, such rollbacks were already incomplete as the failed to roll back cascaded drops for dependent views and foreign key constraints. [#75727][#75727]
- When `sql.contention.txn_id_cache.max_size` is set to 0, it would effectively turn off transaction ID cache. [#76523][#76523]
- Allow users to add NEW_KMS encryption keys to existing backups using: ALTER BACKUP <backup_location> ADD NEW_KMS = <kms_uris> WITH OLD_KMS = <kms_uris> ALTER BACKUP <subdir> IN <backup_collection> ADD NEW_KMS = <kms_uris> WITH OLD_KMS = <kms_uris>  The OLD_KMS must refer to at least one KMS URI that was previously used to encrypt the backup. Following successful completion of the ALTER BACKUP, subsequent backups, restore and show commands can use any of old or new KMS URIs to decrypt the backup. [#75900][#75900]
- Primary key columns which are not part of a unique secondary index (but are "implicitly" included because all indexes include all primary key columns) are now marked as `storing` in the information_schema.statistics table and in `SHOW INDEX`. This is technically more correct; the column is in the value in KV and not in the indexed key. [#72670][#72670]
- A special flavor of RESTORE, RESTORE SYSTEM USERS FROM ..., is added to support restoring system users from a backup. When executed, the statement recreates those users which are in a backup of system.users but do not currently exist (ignoring those who do) and re-grant roles for users if the backup contains system.role_members. [#71542][#71542]
- Add support for DECLARE, FETCH and CLOSE commands for creating, using and deleting SQL cursors. [#74006][#74006]
- SQL cursors now appear in pg_catalog.pg_cursors. [#74006][#74006]
- Previously, crdb blocked users from creating hash sharded index in all kinds of partitioned tables including implict partitioned tables using `PARTITION ALL BY` or `REGIONAL BY ROW`. Now we turn on the support of hash sharded index in implicit partitioned tables. Which means primary key cannot be hash sharded if a table is explicitly partitioned with `PARTITION BY` or an index cannot be hash sharded if the index is explicitly partitioned with `PARTITION BY`. Paritioning columns cannot be placed explicitly as key columns of a hash sharded index as well, including regional-by-row table's `crdb_region` column. [#76358][#76358]
- When a hash sharded index is partitioned, ranges are pre-split within every single possible partition on shard boundaries. Each partition is split up to 16 ranges, otherwise split into the number bucket count ranges. Note that, only list partition is being presplit, we don't presplit for range partition. [#76358][#76358]
- New user privileges are added: `VIEWCLUSTERSETTING` and `NOVIEWCLUSTERSETTING` that allows users to view cluster settings only. [#76012][#76012]
- Several error cases in geospatial and other builtins returned "internal error" pg error codes. They now return more appropriate error codes. This is a minor change and clients should not notice. [#76458][#76458]
- Expression indexes can now longer have duplicate expressions. [#76863][#76863]
- The crdb_internal.serialize_session and crdb_internal.deserialize_session now can handle prepared statements. When deserializing, any prepared statements that existed when the session was serialized are re-prepared. It is an error to re-prepare a statement if the current session already has a statement with that name. [#76399][#76399]
- The experimental_enable_hash_sharded_indexes session variable has been removed, along with the corresponding cluster setting. The functionality of being able to create hash sharded index is enabled automatically. SQL statements refer to the setting will still work but will have no effects. [#76937][#76937]
- Adds session setting `default_transaction_quality_of_service` which controls the priority of work submitted to the different admission control queues on behalf of SQL requests submitted in a session. Admission control must be enabled for this setting to have an effect, see: https://www.cockroachlabs.com/docs/v21.2/architecture/admission-control.html To increase admission control priority of subsequent SQL requests:    `SET default_transaction_quality_of_service=critical;` To decrease admission control priority of subsequent SQL requests:    `SET default_transaction_quality_of_service=background;` To reset admission control priority to the default session setting (in between background and critical):    `SET default_transaction_quality_of_service=regular;` [#76512][#76512]
- Previously we only require the bucket count a positive Int32 integer (greater than 1). Now it's limited to inclusive range of [2, 2048]. [#77004][#77004]
- Adds support for distributed import queries in multi-tenant environments, which allows import queries to have improved parallelism by utilizing all available SQL pods in the tenant. [#76566][#76566]
- ST_Box2DFromGeoHash now accepts NULL arguments, the precision being NULL is the same as no precision being passed in at all.  Upper case characters are now parsed as lower case characters for geohash, this matches Postgis behaviour. [#76990][#76990]
- Support SHOW COMPLETIONS AT OFFSET <offset> FOR <stmt> syntax that returns a set of SQL keywords that can complete the keyword at <offset> in the given <stmt>.  If the offset is in the middle of a word, then it returns the full word. For example SHOW COMPLETIONS AT OFFSET 1 FOR "SELECT" returns select. [#72925][#72925]
- We introduce a new row level TTL feature to CockroachDB, which is available as a beta feature. This allows users to use a special syntax to automatically mark rows for deletion. Rows are deleted using a SCHEDULED JOB.  A user can create a table with TTL using: ``` CREATE TABLE t (id INT PRIMARY KEY) WITH (ttl_expire_after = '10 mins') ```  Where `ttl_expire_after` is a duration expression. A user can also add TTL to an existing table using ``` ALTER TABLE t SET (ttl_expire_after = '10 mins') ```  This creates a new column, `crdb_internal_expiration`, which automatically is set to `now() + ttl_expire_after` when inserted by default or on update. The scheduled job will delete any rows which exceed this timestamp as of the beginning of the job run.  The TTL job is configurable in a few ways using the WITH/SET syntax: * ttl_select_batch_size: how many rows to select at once (by default   it is cluster setting sql.ttl.default_select_batch_size) * ttl_delete_batch_size: how many rows to delete at once (default   cluster setting sql.ttl.default_select_batch_size) * ttl_delete_rate_limit: maximum rows to delete per second for   the given table (default cluster setting   sql.default.default_delete_rate_limit) * ttl_pause: pauses the TTL job (also globally pausable with   `sql.ttl.job.enabled`).  Using `ALTER TABLE table_name RESET (<parameter>)` will reset the parameter to re-use the default, or `RESET(ttl)` will disable the TTL job for the table and remove the `crdb_internal_expiration` column. [#76918][#76918]
- A new cluster setting `sql.contention.event_store.capacity` is added . This cluster setting can be used to control the in-memory capacity of contention event store. When this setting is set to zero, the contention event store is disabled. [#76719][#76719]
- When dropping a user that has default privileges, the error message now includes which database and schema the default privileges are defined in.  Additionally a hint is given to show exactly how to remove the default privileges. Example: pq: role testuser4 cannot be dropped because some objects depend on it owner of default privileges on new sequences belonging to role testuser4 in database testdb2 in schema s privileges for default privileges on new sequences belonging to role testuser3 in database testdb2 in schema s privileges for default privileges on new sequences for all roles in database testdb2 in schema public privileges for default privileges on new sequences for all roles in database testdb2 in schema s HINT: USE testdb2; ALTER DEFAULT PRIVILEGES FOR ROLE testuser4 IN SCHEMA S REVOKE ALL ON SEQUENCES FROM testuser3; USE testdb2; ALTER DEFAULT PRIVILEGES FOR ROLE testuser3 IN SCHEMA S REVOKE ALL ON SEQUENCES FROM testuser4; USE testdb2; ALTER DEFAULT PRIVILEGES FOR ALL ROLES IN SCHEMA PUBLIC REVOKE ALL ON SEQUENCES FROM testuser4; USE testdb2; ALTER DEFAULT PRIVILEGES FOR ALL ROLES IN SCHEMA S REVOKE ALL ON SEQUENCES FROM testuser4; [#77016][#77016]
- Adds support for distributed backup in a multitenant environment that uses all available SQL pods in the tenant. [#77023][#77023]
- Introducing `crdb_internal.transaction_contention_events` virtual table, that exposes historical transaction contention events. The events exposed in the new virtual table also include transaction fingerprint IDs for both blocking and waiting transactions. This allows the new virtual table to be joined into statement statistics and transaction statistics tables. The new virtual table require either VIEWACTIVITYREDACTED OR VIEWACTIVITY role option to access. However, if user has VIEWACTIVTYREDACTED role, the contending key will be redacted. The contention events are stored in memory. The amount of contention events stored is controlled via 'sql.contention.event_store.capacity' cluster setting. [#76917][#76917]
- Initial implementation of a scheduled logger used to capture index usage statistics to the telemetry logging channel.  Release justification: Category 4: Low risk, high benefit changes to existing functionality. [#76886][#76886]
- This commit adds the ability for the TTL job to generate statistics on number of rows and number of expired rows on the table. This is off by default, controllable by the `ttl_row_stats_poll_interval` storage parameter syntax.  Release justification: high benefit changes to new functionality [#76837][#76837]
- Return ambiguous unary operator error for ambiguous input like ~'1' which can be interpreted as an integer (resulting in -2) or a bit string (resulting in 0).  Release justification: Improves a confusing error message saying that an operator is invalid instead of ambiguous. [#76943][#76943]
- Added syntax for modifying cluster settings at the tenant level.  Release justification: Completion of feature for 22.1. [#76929][#76929]
- Previously crdb_internal.default_privileges would incorrectly show default privileges for databases where the default privilege was not actually defined in. [#77255][#77255]
- Core changefeeds can now be created on tables with more than one column family. Previously, this would error. Now, we create a feed that will emit individual messages per column family. Primary key columns will appear in the key for all column families, but in the value only in the families they are in. For example, if a table foo has families "primary" containing the primary key and a string column, and "secondary" containing a different string column, you'll see two messages for an insert that will look like 0 -> {id: 0, s1: "val1"}, 0 -> {s2: "val2"}. If an update then only affects one family, you'll see only one message (e.g. 0 -> {s2: "newval"}). This behavior reflects CockroachDB's inte rnal treatment of column families: writes are processed and stored separately, with only the ordering and atomicity guarantees that would apply to  updates to two different tables within a single transaction. [#77084][#77084]
- The new built-in scalar function `crdb_internal.active_version()` can now be used alongside `crdb_internal.is_at_least_version()` to determine which cluster version is currently active and choose client-side feature levels accordingly. [#77233][#77233]
- IMPORT INTO with AVRO now supports avro files with the following avro types: long.time-micros, int.time-millis, long.timestamp-micros,long.timestamp-millis, and int.date. This feature only works if the user has created a crdb table with column types with match certain avro types. Specifically:  AVRO | CRDB time-* | TIME timestamp_* | TIMESTAMP date | DATE  Release justification: [#76989][#76989]
- Added a `sql.auth.resolve_membership_single_scan.enabled` cluster setting, which changes the query for an internal role membership cache. Previously the code would recursively look up each role in the membership hierarchy, leading to multiple queries. With the setting on, it uses a single query. The setting is true by default. [#77359][#77359]
- The type of shard columns created for hash-sharded indexes have changed from `INT4` to `INT8`. This should have no effect on behavior or performance. [#76930][#76930]
- Introduce sql.contention.resolver.queue_size metric. This is a gauge metric reflecting the current size of the queued contention events waiting to have its transaction ID to be translated into transaction fingerprint ID. [#77514][#77514]
- Introduce sql.contention.resolver.retries metric. This is a counter metric reflecting the number of retries performed by the contention event store attempting to translate the transaction ID of the contention event into transaction fingerprint ID. [#77514][#77514]
- Introduce sql.contention.resolver.failed_resolution metric. This is a counter metric number of failed attempt to translate transaciton ID in the contention events into transaction fingerprint ID. [#77514][#77514]
- Add support for date_trunc(string, interval). [#77508][#77508]
- Introduce sql.contention.event_store.duration_threshold cluster setting. This cluster setting specifies the minimum contention duration to cause the contention events to be collected into crdb_internal.transaction_contention_events virtual table. [#77623][#77623]
- Add support for super region functionality. Super regions allow the user to define a set of regions on the database such that any regional by table based in the super region or any regional by row partition in the super region will have all their replicas in regions within the super region. The primary use is for data domiciling.  Super regions are an experimental feature and are gated behind the session variable: enable_super_regions. There is also a cluster setting sql.defaults.super_regions.enabled.  Syntax examples: ``` show regions;      region      |  zones  | database_names | primary_region_of -----------------+---------+----------------+--------------------   ca-central-1   | {b,c,d} | {}             | {}   us-east-1      | {b,c,d} | {}             | {}   us-west-1      | {a,b,c} | {}             | {}   ap-southeast-  | {a,b,c} | {}             | {}   us-central-1   | {a,b,c} | {}             | {}  ``` `ALTER DATABASE mr3 ADD SUPER REGION "r2" VALUES "ca-central-1", "us-west-1", "us-central-1"` -> This creates super region "r2" with regions "ca-central-1", "us-west-1" and "us-central-1" Any regional by row table located in any of those regions will have their replicas constrained to those regions.  The zone config for a table or partition within the super region will look like under zone survivability ``` PARTITION "ca-central-1" OF TABLE mr3.public.rt  ALTER PARTITION "ca-central-1" OF TABLE mr3.public.rt CONFIGURE ZONE USING                                                  range_min_bytes = 134217728,                                                  range_max_bytes = 536870912,                                                  gc.ttlseconds = 90000,                                                  num_replicas = 5,                                                  num_voters = 3,                                                  constraints = '{+region=ca-central-1: 1, +region=us-central-1: 1, +region=us-west-1: 1}',                                                  voter_constraints = '[+region=ca-central-1]',                                                  lease_preferences = '[[+region=ca-central-1]]'  ```  The zone config for a table or partition within the super region will look like under region survivability. Note that the primary region has 2 voting replicas, the other replicas are constrained evenly across the other regions. ``` PARTITION "ca-central-1" OF TABLE mr3.public.rt  ALTER PARTITION "ca-central-1" OF TABLE mr3.public.rt CONFIGURE ZONE USING                                                  range_min_bytes = 134217728,                                                  range_max_bytes = 536870912,                                                  gc.ttlseconds = 90000,                                                  num_replicas = 5,                                                  num_voters = 5,                                                  constraints = '{+region=ca-central-1: 2, +region=us-central-1: 2, +region=us-west-1: 1}',                                                  voter_constraints = '[+region=ca-central-1: 2]',                                                  lease_preferences = '[[+region=ca-central-1]]'  ```  The above is only an example of what the zone config will look like. It depends on the number of regions and the survival goal. In the above, the voter_constraints are defined such that all 3 voting replicas are in ca-central-1, the other 2 non voting replcias are constrained to us-central-1 and us-west-1.  If region survival goal is set, the number of voters will be at least 5, one replica will be constrained to each region and the excess voting replicas will be constrained to the primary region.  To drop a super region, simply do: ALTER DATABASE mr3 DROP SUPER REGION "r2"  Release justification: Low risk, high benefit change. Also being added experimentally behind a session variable. [#76620][#76620]
- TTL metrics are labelled by relation name if `SET CLUSTER SETTING server.child_metrics.enabled=true;` is set and the `ttl_label_metrics` storage parameter is set to true. This is to prevent a potentially unbounded cardinality on TTL related metrics. [#77567][#77567]
- Add support for the MOVE command, which moves a SQL cursor without fetching any rows from it. MOVE is identical to FETCH, including in its arguments and syntax, except it doesn't return any rows. [#74877][#74877]
- The enable_implicit_transaction_for_batch_statements session variable was added. It defaults to true. When it is true, multiple statements in a single query (a.k.a. a "batch statement") will all be run in the same implicit transaction, which matches the Postgres wire protocol. This setting is provided for users who want to preserve the behavior of CockroachDB versions v21.2 and earlier. [#76834][#76834]
- Core users that schedule a backup without the Full BACKUP ALWAYS clause will receive a warning. [#77506][#77506]
- Changefeeds can now specify column families to target, using the syntax `[TABLE] foo FAMILY bar`. For example,`EXPERIMENTAL CHANGEFEED FOR TABLE foo FAM ILY bar, TABLE foo FAMILY baz, TABLE users` will create a feed that watches the bar and baz column families of foo, as well as the whole table users. A family must exist with that name when the feed is created. If all columns in a watched family are dropped in an ALTER TABLE statement, the feed will fail with an error, similarly to dropping a table. Behavior  is otherwise similar to feeds created using split_column_families.  Release justification: Additive change that mainly takes advantage of existing plumbing already merged. [#77640][#77640]
- Implemented the pg_options_to_table builtin. [#77883][#77883]
- Experimental_enable_hash_sharded_indexes used to be set to enable the hash sharded index feature. since we now enable the feature by default, user don't need to set this var anymore. But still keeping it as noop for backward compatibility. [#77968][#77968]
- New builtin to group statement statistics metadata. [#77837][#77837]
- When the user runs SHOW BACKUP on an encrypted incremental backup, they must set the encyrption_info_dir dir to the full backup directory in order for SHOW BACKUP to work. [#78032][#78032]
- Casts that are affected by the DateStyle or IntervalStyle sesion variables that are used in computed columns or partial index definitions will be rewritten to use immutable functions when the upgrade to v22.1 is finalized. This is in preparation for allowing DateStyle and IntervalStyle to be used by default. (Currently they are gated behind the datestyle_enabled and intervalstyle_enabled settings.) [#76510][#76510]
- The `BACKUP TO` syntax to take backups is deprecated, and will be removed in a future release. Users are recommended to create a backup collection using the `BACKUP INTO` syntax in our docs. [#78165][#78165]
- The `RESTORE FROM` syntax without an explicit subdirectory pointing to a backup in a collection is deprecated, and will be removed in a future release. Users are recommended to use `RESTORE FROM <backup> IN <collection>` to restore a particular backup in a collection. [#78165][#78165]
- Added a `crdb_internal.validate_ttl_scheduled_jobs` builtin which verifies each table points to a valid scheduled job which will action the deletion of expired rows. [#77741][#77741]
- Adds a `crdb_internal.repair_ttl_table_scheduled_job` builtin, which repairs the given TTL table's scheduled job by supplanting it with a valid schedule. [#77741][#77741]
- Implemented the `COPY FROM ... ESCAPE ...` syntax. [#78303][#78303]
- Change the equality assertion on the redacted error message string returned by sql.WithAnonymizedStatement to target only the prefix containing the error message with the redacted SQL query. Previously equality was required against the entire stack trace which can refer to architecture-specific assembly files. [#78317][#78317]
- The session variables datestyle_enabled and intervalstyle_enabled, and the cluster settings sql.defaults.datestyle.enabled and sql.defaults.intervalstyle.enabled no longer have any effect. When the upgrade to v22.1 is finalized, all of these settings are effectively always interpreted as "true." [#78357][#78357]
- Add support for ALTER DATABASE ... ALTER SUPER REGION.  This command allows the user to change the regions of an existing super region.  Example: ALTER DATABASE db3 ALTER SUPER REGION "test1" VALUES "ca-central-1", "us-west-1", "us-east-1";  Super region "test1" now consists of the 3 regions "ca-central-1", "us-west-1", "us-east-1".  Alter super region follows the same rules as add or drop super region. [#78367][#78367]
- 'RESTORE TENANT tenant_id FROM REPLICATION STREAM FROM addr' (as of time not specified) will enable initial scan.  Release justification: Cat 4. [#78398][#78398]
- Stats compaction scheduled job no longer cause intent buildup. Release Justification: important stability fix to ensure jobs and scheduled jobs do not lock up when running stats compaction job. [#78467][#78467]
- Allow users to run SHOW BACKUP on collections with the FROM keyword: `SHOW BACKUP FROM {subdir} IN {DEST}`. Users can still run SHOW BACKUP without the FROM keyword; however, for 22.1 docs, we should only document SHOW BACKUP with the FROM keyword, once the backport merges. One gotcha: `SHOW BACKUP SCHEMAS` must be run with FROM, though this shouldn't affect our documentation strategy for this commit. [#78427][#78427]
- Bucket count of hash sharded index is now being shown from the crdb_internal.table_indexes table. [#78459][#78459]
- Disabled index recommendations in EXPLAIN output for REGIONAL BY ROW tables, as the previous recommendations were not valid. [#78616][#78616]
- The `SHOW BACKUP` cmd  without the `IN` keyword to specify a subdirectory is deprecated and will be removed from a future release. Users are recommended to only create collection based backups and view them with `SHOW BACKUP FROM <backup> IN <collection>` [#78626][#78626]
- `ALTER TABLE ... INJECT STATISTICS ...` will now issue notices when the given statistics JSON includes non-existent columns, rather than resulting in an error. Any statistics in the JSON for existing columns will be injected successfully. [#78997][#78997]
- Help text for creating indexes or primary key constraints no longer mentions BUCKET_COUNT because it can now be omitted and a default is used. [#79045][#79045]
- `COMMENT ON SCHEMA` now can use qualified schema name. So can do both `COMMENT ON SCHEMA sc_name ...` and `COMMENT ON SCHEMA db_name.sc_name ...`. [#79055][#79055]
- Changes the default value of `sql.zone_configs.allow_for_secondary_tenant.enabled` to be false.  Moreover, this setting is no longer settable by secondary tenants. Instead, it's now a tenant read-only cluster setting. [#79097][#79097]
- Add support for show default privileges in schema.  The SHOW DEFAULT PRIVILEGES clause now supports optionally passing a schema name.  SHOW DEFAULT PRIVILEGES [opt_for_role] [opt_schema_name]  Example:  SHOW DEFAULT PRIVILEGES IN SCHEMA s2 ---- role      for_all_roles  object_type  grantee    privilege_type testuser  false          tables       testuser2  DROP testuser  false          tables       testuser2  SELECT testuser  false          tables       testuser2  UPDATE  SHOW DEFAULT PRIVILEGES FOR ROLE testuser IN SCHEMA s2 ---- role      for_all_roles  object_type  grantee    privilege_type testuser  false          tables       testuser2  DROP testuser  false          tables       testuser2  SELECT testuser  false          tables       testuser2  UPDATE [#78959][#78959]
- Introduced a `expect_and_ignore_not_visible_columns_in_copy` session variable. If this is set, COPY with no column specifiers will assume hidden columns are in the copy data, but will ignore them when applying the COPY. [#79016][#79016]
- Add support for SHOW SUPER REGIONS FROM DATABASE. Example:  SHOW SUPER REGIONS FROM DATABASE mr2 ---- mr2  ca-central-sr  {ca-central-1} mr2  test           {ap-southeast-2,us-east-1} [#78985][#78985]
- Support OVERLAPS syntax and overlaps builtin function. The sementics is the same as the [OVERLAPS syntax in PostgreSQL](https://www.postgresql.org/docs/14/functions-datetime.html). This expression yields true when two time periods (defined by their endpoints) overlap, false when they do not overlap. The endpoints can be specified as pairs of dates, times, or time stamps; or as a date, time, or time stamp followed by an interval. When a pair of values is provided, either the start or the end can be written first; OVERLAPS automatically takes the earlier value of the pair as the start. Each time period is considered to represent the half-open interval `start <= time < end`, unless `start` and `end` are equal in which case it represents that single time instant. This means for instance that two time periods with only an endpoint in common do not overlap. [#77015][#77015]
- SHOW BACKUP now reports accurate row and byte size counts on backups created by a tenant. [#77952][#77952]
- Add extra logging for copy to the SQL_EXEC channel if the `sql.trace.log_statement_execute` cluster setting is set. [#79011][#79011]
- An error message is now logged to the SQL_EXEC channel when parsing fails. [#79011][#79011]
- Make direction explicit for inverted indices in SHOW CREATE TABLE output. [#78549][#78549]
- Memory and disk usage are now reported for the lookup joins in EXPLAIN ANALYZE. [#79250][#79250]
- `ALTER PRIMARY KEY` will not create a seconday index on the old PK columns if they're a strict prefix of an existing secondary index. [#78046][#78046]
- Previously, any privileges on a database that would be inherited (copied down) to tables/schemas if a table/schema is created in that database.  For example, `GRANT ALL ON DATABASE TEST TO foo` `CREATE TABLE test.t()` would result in foo having ALL on the table.  This is no longer the case as users should rely on default privileges instead. They can achieve the same behaviour by doing USE test; ALTER DEFAULT PRIVILEGES GRANT ALL ON TABLES TO foo; [#79049][#79049]
- The `to_regclass`, `to_regnamespace`, `to_regproc`, `to_regprocedure`, `to_regrole`, and `to_regtype` builtin functions are now supported, improving compatibility with PostgreSQL. [#78652][#78652]
- Extend stream replication statement to be RESTORE TENANT $1 FROM REPLICATION STREAM FROM $2 AS TENANT $3.  Release justification: Category 4. [#77521][#77521]
- Use the InvalidPassword error code when authenticating if the password is invalid or the user does not exist. [#79257][#79257]
- This patch ensures the user passes the same number of locality aware URIs for the full backup destination as the incremental_location parameter. I.e.  Good: `BACKUP INTO LATEST IN ($1, $2, $3) WITH incremental_location = ($4, $5, $6)`  Bad: `BACKUP INTO LATEST IN $4 WITH incremental_location = ($1, $2, $3)`  Note that the non locality uris for the full backup don't really affect incremental backup planning -- the patch just adds guardrails to the UX. Further work will ensure users cannot create incremental backup chains with mixed localities (#79135) [#79523][#79523]
- Changefeed statements now detect duplicate targets and throw an error. [#79465][#79465]
- Previously, Backup commmands allowed the user to specify a custom subdirectory name for their backups via `BACKUP .. INTO <subdir> IN <collectionURI>`. After this change, this will no longer be supported. Users can only create a full backup via `Backup ... INTO <collectionURI>` or an incremental backup on the latest full backup in their collection via `BACKUP ... INTO LATEST IN <collectionURI>`. This deprecation also removes the need to address a bug in `SHOW BACKUPS IN` which cannot display user defined subdirectories. [#79447][#79447]
- EXPLAIN (DDL), when invoked on statements supported by the declarative schema changer, prints a plan of what the schema changer will do. This can be useful for the user to anticipate the complexity of a schema change (anything involving Backfill or Validation operations might be slow to run). This can be useful for troubleshooting. EXPLAIN (DDL, VERBOSE) produces a more detailed plan. [#79673][#79673]
- The new sql.conn.failures counter metric shows number of failed SQL connections. [#79606][#79606]
- Add a new session variable, enable_multiple_modifications_of_table, which can be used instead of cluster variable sql.multiple_modifications_of_table.enabled to allow statements containing multiple INSERT ON CONFLICT, UPSERT, UPDATE, or DELETE subqueries modifying the same table. Note that underlying issue 70731 is not fixed. As with sql.multiple_modifications_of_table.enabled, be warned that with this session variable enabled there is nothing to prevent the table corruption seen in issue 70731 from occuring if the same row is modified multiple times by different subqueries of a single statment. It's best to rewrite these statements, but the session variable is provided as an aid if this is not possible. [#79677][#79677]
- Introduces new cluster setting which allows the operator to control if a secondary tenant can make use of MR abstractions. The setting is called `sql.multi_region.allow_abstractions_for_secondary_tenants.enabled`. [#79536][#79536]
- Previously, if a column in a table has a comment, `SHOW CREATE TABLE` would fail after the column type is changed. Now this is fixed. [#79998][#79998]
- Added the builtin functions: uuid_nil, uuid_ns_dns, uuid_ns_url, uuid_ns_oid, and uuid_ns_x500. [#80204][#80204]
- The builtin functions uuid_generate_v1, uuid_generate_v1mc, uuid_generate_v3, and uuid_generate_v5 were added. [#80204][#80204]
- The command CREATE EXTENSION "uuid-ossp" no longer fails, since CockroachDB now includes all the builtin functions from this extension. [#80204][#80204]
- The new settings cloudstorage.<provider>.write.node_rate_limit and cloudstorage.<provider>.write.node_burst_limit allow limiting the rate at which bulk operations write to the designated cloud storage provider. [#80200][#80200]
- The cluster settings cloudstorage.<provider>.read.node_rate_limit and cloudstorage.<provider>.read.node_burst_limit can now be used to limit throughput when reading from cloud storage during a RESTORE or IMPORT. [#80261][#80261]
- Users can pass locality aware backup URIs to SHOW BACKUP. This change only affects SHOW BACKUP with the new syntax: e.g.:  SHOW BACKUP FROM LATEST IN (<collectionURI>, <localityURI1>, <localityURI2>)  Users can not yet run SHOW BACKUP for locality aware backups created using the incremental_location parameter. [#79121][#79121]
- Ttl_job_cron is now displayed on SHOW CREATE TABLE and `reloptions` by default. [#80221][#80221]
- Introducing the `crdb_internal.cluster_locks` virtual table, which exposes the current state of locks on keys tracked by concurrency control. The virtual table displays metadata on locks currently held by transactions, as well as operations waiting to obtain the locks, and as such can be used to visualize active contention. The `VIEWACTIVITY` or `VIEWACTIVITYREDACTED` role option, or the `admin` role, is required to access the virtual table; however, if the user only has the `VIEWACTIVITYREDACTED` role option, the key on which a lock is held will be redacted. [#77876][#77876]
- BACKUP, IMPORT and RESTORE jobs will be paused instead of entering a failed state if they continue to encounter transient errors once they have retried a maximum number of times. The user is responsible for cancelling or resuming the job from this state. [#80403][#80403]
- Table scans performed as a part of index joins, lookup joins, and inverted joins now respect the row-level locking strength and wait policy specified by the optional FOR SHARE/UPDATE [NOWAIT] clause on SELECT statements. [#60719][#60719]
- Table scans performed as a part of zigzag joins now respect the row-level locking strength and wait policy specified by the optional FOR SHARE/UPDATE [NOWAIT] clause on SELECT statements. [#60719][#60719]
- The pg_cast table was populated in order to match PostgreSQL behavior [#79537][#79537]
- Constraints that only include hidden columns are no longer excluded in SHOW CONSTRAINTS. This behavior can be changed using the show_primary_key_constraint_on_hidden_columns session variable. [#80154][#80154]
- Table scans performed as a part of index joins, lookup joins, and inverted joins now respect the row-level locking strength and wait policy specified by the optional FOR SHARE/UPDATE [NOWAIT] clause on SELECT statements. [#78961][#78961]
- Table scans performed as a part of zigzag joins now respect the row-level locking strength and wait policy specified by the optional FOR SHARE/UPDATE [NOWAIT] clause on SELECT statements. [#78961][#78961]
- The pg_cast table was populated in order to match PostgreSQL behavior [#78961][#78961]
- Introduce ST_XMin/XMax/YMin/YMax builtins. [#80363][#80363]
- Added builtin st_makeenvelope  Signed-off-by: Frédéric BIDON <frederic@oneconcern.com> [#80408][#80408]
- Add the pgcrypto gen_salt builtin with support for the des, xdes, md5, bf algos. [#80318][#80318]
- Automatic statistics collection can now be enabled or disabled for individual tables, taking precedence over the cluster setting, for example: ``` ALTER TABLE t1 SET (sql_stats_automatic_collection_enabled = true); ALTER TABLE t1 SET (sql_stats_automatic_collection_enabled = false); ALTER TABLE t1 RESET (sql_stats_automatic_collection_enabled); ``` RESET removes the setting value entirely, in which case the similarly-name cluster setting, `sql.stats.automatic_collection.enabled`, is in effect for the table.  Cluster settings `sql.stats.automatic_collection.fraction_stale_rows` and `sql.stats.automatic_collection.min_stale_rows` now also have table setting counterparts: ``` sql_stats_automatic_collection_fraction_stale_rows sql_stats_automatic_collection_min_stale_rows ``` The table settings may be set at table creation time, or later via ALTER TABLE ... SET, independent of whether auto stats is enabled: ``` ALTER TABLE t1       SET (sql_stats_automatic_collection_fraction_stale_rows = 0.1,            sql_stats_automatic_collection_min_stale_rows = 2000); CREATE TABLE t1 (a INT, b INT)        WITH (sql_stats_automatic_collection_enabled = true,              sql_stats_automatic_collection_min_stale_rows = 1000000,              sql_stats_automatic_collection_fraction_stale_rows= 0.05              ); ``` The current table settings (storage parameters) are shown in the `WITH` clause output of `SHOW CREATE TABLE`. Note, any row mutations which have occurred a minute or two before disabling auto stats collection via `ALTER TABLE ... SET` may trigger stats collection, though DML submitted after the setting change will not. [#78110][#78110]
- New sql.txn.contended.count metric exposes total number of transactions that experienced contentions. [#79176][#79176]
- Previously, the user did not have an easy way to check that all SSTs and metadata belonging to a backup were in the expected place in external storage. This patch adds the 'check_files' option to SHOW BACKUP which checks that all SSTs and metadata in a backup chain are in their expected location in external storage. If SHOW BACKUP cant read from a file, an error message with the problematic file path gets returned to the user.  A successful SHOW BACKUP with check_files will also return the additional `file_bytes` column which indicates the estimated bytes on external storage storing a table object in the backup, analogous to the return pattern of the 'rows' and 'size_bytes' columns. Note that 'size_bytes' indicates the logical size of the table, the sum of the size of each key value pair, while 'file_bytes' resprents the physical size of a whole (or fraction) of a potentially compressed SST storing the table's data. For small tables, 'file_bytes' may be larger than 'size_bytes' because of the overhead required to create an SST. [#80491][#80491]
- Previously, when we drop a hash-sharded index, we will also drop the accompanying shard column, if no other index uses this shard column.  For hash-sharded index created in 21.2 and prior, this shard column is a physical, `STORED` column. Dropping such a physical column can be very expensive since it requires a full table rewrite. For hash-sharded index craeted in 22.1 and later, this shard column is a virtual, computed column and dropping a virtual column is no problem.  This PR introduces the sql change that, if the to-be-dropped sharded index has a physical shard column (and no other index uses that column), we will drop only the index if not CASCADE; we will drop both the index and the column if CASCADE. [#80806][#80806]
- New crdb_internal.request_statement_bundle builtin allows statement bundle being requested from SQL CLI. The new builtin takes three parameters: * statement fingerprint text * minimum execution latency for the statement * length of duration the statement bundle request will stay valid for. VIEWACTIVITY or ADMIN role option is required to use this builtin. If user has VIEWACTIVITYREDACTED role option, user is not allowed to use this builtin. [#79693][#79693]
- Allow the use wildcard to show grants for all schemas in a database. [#80861][#80861]
- The error messages returned when encountering a malformed or unparseable argument for a query in the wire protocol are now more consistent. [#78108][#78108]
- Improved query performance for `crdb_internal.cluster_locks` when issued with constraints in the WHERE clause on `table_id`, `database_name`, or `table_name` columns. [#79623][#79623]
- Add the pgcrypto crypt builtin with support for the md5, bf algo. [#80809][#80809]
- The `ALTER ROLE` syntax` allows users to set default values for session variables making `SET CLUSTER SETTINGS sql.defaults...` redundant. This PR adds a notice to `SET CLUSTER SETTINGS sql.defaults...` that directs the user to use the `ALTER ROLE` syntax instead. [#80548][#80548]
- The json ? string operator is now index accelerated if there is an inverted index over the json column referred to on the left hand side of the expression, and a constant on the right. [#81253][#81253]
- The ?& and ?| operators are now index accelerated if the left hand side is an inverted indexed JSON column, and the right hand side is a constant. [#81253][#81253]
- Add a new RESTART option to ALTER and CREATE SEQUENCE which sets the nextval to the given number, or back to the original START value.  This implements the Postgres behavior described here: https://www.postgresql.org/docs/current/sql-altersequence.html  """ This is similar to calling the setval function with is_called = false: the specified value will be returned by the next call of nextval. Writing RESTART with no restart value is equivalent to supplying the start value that was recorded by CREATE SEQUENCE or last set by ALTER SEQUENCE START WITH.  In contrast to a setval call, a RESTART operation on a sequence is transactional and blocks concurrent transactions from obtaining numbers from the same sequence. If that's not the desired mode of operation, setval should be used. """ [#81377][#81377]
- Add syntax support for `{GRANT|REVOKE} ... ON {SEQUENCE | ALL SEQUENCES IN SCHEMA}` [#79862][#79862]
- Add logic for `{GRANT|REVOKE} ... ON {SEQUENCE | ALL SEQUENCES IN SCHEMA}` [#79862][#79862]
- SHOW EXPERIMENTAL_FINGERPRINTS now supports table with expression indexes. [#81042][#81042]
- Fixed a small typo when using DateStyle and IntervalStyle. [#81523][#81523]
- Removing the ability to cast int, int2 and int8 to a 0 length bit or varbit. [#81266][#81266]
- Add is_grantable column to SHOW GRANTS FOR role to be consistent with other SHOW GRANTS commands. [#81582][#81582]
- The cluster setting bulkio.ingest.sender_concurrency_limit can be used to adjust the concurrency at which any one SQL node, across all operations that it is running such as RESTORES, IMPORTs, and schema changes, will send bulk ingest requests to the KV storage layer. [#80494][#80494]
- This PR expands the capabilities of the experimental SCRUB tool to include checking unique constraints for primary keys, unique indexes, and unique columns without indexes. The usage and output of SCRUB is unchanged, but if there is a unique constraint violation, users will see the error message `unique_constraint_violation` for all rows that violate the constraint, along with information about the row. [#78297][#78297]
- Add the pg_trgm.similarity_threshold session setting which controls the threshold at which the trigram similarity operator % returns true vs false. [#81418][#81418]
- The pg_trgm builtins show_trgm, for showing the trigrams in a string, and similarity, for showing a measure of how similar two strings are based on their trigrams, are now supported. [#81418][#81418]
- Add the string % string trigram similarity overload. [#81418][#81418]
- The extra_float_digits session variable now defaults to 1. The meaning of the variable has also changed. Now, any value greater than zero causes floats to be formatted in their shortest precise decimal representation. That is, the string representation produced is closer to the actual binary value than to any other value. (Previously, this was only the behavior when extra_float_digits was set to 3.) This change was made in accordance with an equivalent change that was part of the PostgreSQL 12.0 release.  The behavior of a non-positive extra_float_digits value is unchanged. That will still reduce the number of float digits shown in the output string. The formula for number of digits shown is `max(1, (DIGITS + extra_float_digits))`, where DIGITS=6 for FLOAT4 values, and DIGITS=15 for FLOAT8 values. [#82022][#82022]
- Information has been added describing whether a query contains a full table or index scan. Note that this information is only valid when the query is in the `executing` phase.  The `ListSessions` api includes this info under the field `is_full_scan` in the active query for a session.  The `crdb_internal.{cluster,node}_queries` has a new column `full_scan`. This column is included in the `SHOW QUERIES` command. [#81531][#81531]
- String columns now support inverted indexes using trigrams. These indexes can be searched using the =, LIKE, ILIKE and % (similarity) predicates. [#79705][#79705]
- Permit usage of jsonb_ops, array_ops, gin_trgm_ops, and gist_trgm_ops as an opclass in inverted index creation. [#79705][#79705]
- Remove deprecated GRANT privilege. [#81310][#81310]
- Support crdb_internal.stream_ingestion_stats (ingestion_job_id) to running progress for a stream ingestion job. [#79748][#79748]
- Casting from an integer to OID, or calling the `oid` builtin function, using an integer that is larger than 32 bits now results in an error. Specifically, the range for valid inputs is [MinInt32, MaxUint32]. [#82430][#82430]
- An error is now returned if an OID is compared to an integer that is out of the allowable range of OID input values, which is [MinInt32, MaxUint32]. [#82430][#82430]
- SHOW BACKUP WITH check_files will display up to 10 missing SSTs. [#82274][#82274]
- Index recommendations are now supported for spatial indexes [#82293][#82293]
- Add new function to_timestamp which converts Unix epoch of FLOAT, INT, DECIMAL and text to Timestamp with time zone. [#82523][#82523]
- A column's DEFAULT/ON UPDATE clause can now have a type that differs from the column type,as long as that type can be assignment-cast into the column's type. This increases our PostgreSQL compatibility. [#81071][#81071]
- Previously, `SHOW BACKUP with privileges` displayed grant statments with incorrect syntax; specifically, without the object type. This patch fixes this.  As an example, previously displayed: GRANT ALL ON status TO j4;  Now displayed: GRANT ALL ON TYPE status TO j4; [#82626][#82626]
- The cluster setting `sql.ttl.range_batch_size` is deprecated. [#82390][#82390]
- Row-level TTL now works for multi-tenant clusters. [#82390][#82390]
- Permit use of the pgwire DESCRIBE command against a cursor created with the DECLARE command in SQL. This improves compatibility with Postgres and is needed for compatibility with psycopg3 server-side cursors. [#82567][#82567]
- COPY ... FROM CSV HEADER is now supported. [#82457][#82457]
- We now send the Severity_Nonlocalized field in the pgwire Notice Response. [#82677][#82677]
- `spanconfig.kvsubscriber.update_behind_nanos` metric has been added to track the latency between realtime and the last update handled by the KVSubscriber. This metric can be used to monitor the staleness of a nodes' view of reconciled spanconfig state. [#82846][#82846]
- Add rowCount to ttl job progress. [#81917][#81917]
- Updated the pg_backend_pid() builtin function so it matches with the data in the query cancellation key created during session initialization. The function is just for compatibility, and it does not return a real process ID. [#82952][#82952]
- Add logic for GRANT ... ON seq_names [#82458][#82458]
- Fix `has_sequence_privilege()` on `USAGE` privilege [#82458][#82458]
- Unredact fields for captured index usage stats telemetry logs. [#83136][#83136]
- The byte string parameter in the crdb_internal.schedule_sql_stats_compaction function has been removed. [#82560][#82560]
- Introduce GLOBAL privileges. These are privileges that live above the database level.  Example: `GRANT SYSTEM MODIFYCLUSTERSETTING TO foo`  Currently `MODIFYCLUSTERSETTING` is the only global privilege, it allows users to query the `crdb_internal.cluster_settings` table. [#82166][#82166]
- Add cluster.preserve_downgrade_option to prometheus as a unix timestamp and to alert banners in order to provide some observability in upgrade finalization. [#82633][#82633]
- Support `DROP OWNED BY`. [#82936][#82936]
- Create two invariants for stream_ingestion_stats builtin for protobuf and json respectively, and extend them to return more details. [#83066][#83066]
- Added support for JSONB subscripting in SELECT-style cases, e.g. SELECT json_field['a'] ... WHERE json_field['b'] = ... [#82877][#82877]
- A new execution statistic that tracks the number of gRPC calls issued to perform the read operations has been added to EXPLAIN ANALYZE output. It exposes low-level details that might aid with debugging the performance of queries for power users. [#83365][#83365]
- The sampled query telemetry log now includes a plan gist field. The plan gist field provides a compact representation of a logical plan for the sampled query, the field is written as a base64 encoded string. [#83027][#83027]
- Allow `CREATE TABLE ... WITH (ttl_expiration_expression='...')`. Allow `ALTER TABLE ... SET (ttl_expiration_expression='...')` and `ALTER TABLE ... RESET (ttl_expiration_expression)`. ttl_expiration_expression accepts an expression that returns a timestamp to support custom TTL calculation. [#82686][#82686]
- The error code reported when trying to use a system or virtual column in the STORING clause of an INDEX has been changed from XXUUU (internal error) to 0A000 (feature not supported). [#83491][#83491]
- Attempts to use a system column in an index as a key column now uses error code 0A000 (feature not supported) instead of XXUUU (internal error). [#83491][#83491]
- `oldest_query_start` in the `crdb_internal.cluster_sessions` and `crdb_internal.node_sessions` has been renamed to `active_query_start`, as this column contains the time at which the currently active query was started, not the time at which the session's first query was started. [#83451][#83451]
- Table `system.sql_instances` has a new column, `locality`, that stores the locality of a SQL instance if it was provided when the instance was started. This exposes a SQL instance's locality to other instances in the cluster for query planning. [#82915][#82915]
- This PR implements DROP INDEX under the new schema changer framework. Previously, DROP INDEX is supported only under the old schema changer. This is necessary since the team has decided to gradually move to the new schema changer and hence we need to implement all DDL statement under the new schema changer. Such a change should be transparent for end-user though. [#80133][#80133]
- Foreign keys can now reference the crdb_region column in REGIONAL BY ROW tables even if crdb_region is not explicitly part of a UNIQUE constraint. This is possible since crdb_region is implicitly included in every index on REGIONAL BY ROW tables as the partitioning key. (This applies to whichever column is used as the partitioning column, in case a different name is used via REGIONAL BY ROW AS.) [#83375][#83375]
- CREATE CHANGEFEED AS statements no longer need to include WITH DIFF when using cdc_prev(). [#83717][#83717]
- Remove ttl_automatic_column storage param. The crdb_internal_expiration column is created when ttl_expire_after is set and removed when ttl_expire_after is reset. [#83134][#83134]
- `txn_fingerprin_id` has been added to `crdb_internal.node_statement_statistics`. The type of the column is NULL or STRING. [#83616][#83616]
- Crdb_internal.validate_ttl_scheduled_jobs and crdb_internal.repair_ttl_table_scheduled_job can now only be run by admins. [#83952][#83952]
- Sampled query telemetry log now includes session/transaction/statement IDs, and database name of the query. [#83938][#83938]
- Crdb_internal.compact_engine_spans can now only be run by admins. [#84036][#84036]
- `CREATE FUNCTION` statement now can be parsed by crdb, but an unimplemented error would be thrown since the statement processing is not done yet. [#83891][#83891]
- DROP statements performed by the declarative schema changer (which is the case by default) now transition the descriptor states to OFFLINE in the initial schema change transaction, before subsequently transitioning them to DROP in a subsequent transaction executed by the schema change job. The behaviour of changefeeds on dropped tables will be correspondingly affected. Previously they'd throw an error about the table being dropped. They may now do either that or throw an error about the table being taken offline. Furthermore, it's possible for a concurrent backup to see the table as OFFLINE before it reaches DROP and this may cause the offline table to be included in the data. We don't expect the impact of these changes to be significant, but they may nonetheless be noticeable. [#83915][#83915]
- Sampled query telemetry log includes new database ID field. [#84195][#84195]
- The CREATE MATERIALIZED VIEW statement has been extended to support the WITH NO DATA clause. This allows the creation of materialized views with no data. Such views require to be refreshed atleast once prior to access. [#83347][#83347]
- Creation of cluster setting `sql.metrics.statement_details.index_recommendation_collection.enabled` that can be disabled if index recommendation generation is causing performance issues. [#84282][#84282]
- Sampled query telemetry log now includes the statement's fingerprint ID. [#84182][#84182]
- Add sequence option info for identity columns under information_schema [#84034][#84034]
- `AS OF SYSTEM TIME` now takes the time zone into account when converting to UTC. For example: '2022-01-01 08:00:00-04:00' is treated the same as '2022-01-01 12:00:00' instead of '2022-01-01 08:00:00' [#84613][#84613]
- The inet function has been added to support the conversion of a supplied type to that of the inet type family. If the conversion fails a SQL error will be output. [#83668][#83668]
- The last column of an INVERTED INDEX can no longer have the `DESC` option. If `DESC` was used in prior versions, it could cause internal errors. [#84516][#84516]
- Introduce new `troubleshooting_mode_enabled` session variable, to avoid doing additional work on queries when possible (i.e. collection telemetry data). By default, this session variable is disabled. [#84452][#84452]
- Introduce `CREATE EXTERNAL CONNECTION` syntax that can be used to create an External Connection representing a resource that resides outside of CockroachDB. The only supported resource at the moment is a `nodelocal` URI that can be represented as an External Connection object using:  `CREATE EXTERNAL CONNECTION foo AS 'nodelocal://1/foo'`;  Fixes: #84225 [#84310][#84310]
- `DROP EXTERNAL CONNECTION` can be used to drop a previously created External Connection object. [#84751][#84751]
- Cluster BACKUP and RESTORE no longer includes job records, which previously were usually only restored in a cancelling state with the exception of schema changes which were restored to their initial running state. Instead any schema change jobs required for restored tables are recreated after restoring the tables. [#84886][#84886]
- Adding new column index_recommendations to crdb_internal.node_statement_statistics, crdb_internal.cluster_statement_statistics, system.statement_statistics and crdb_internal.statement_statistics [#84618][#84618]
- Introduce an `EXTERNALCONNECTION` system privilege that is required to create an External Connection object to represent an underlying resource. [#85007][#85007]
- A new column `is_visible` has been added to the table `crdb_internal.table_indexes` and `information_schema.statistics`. A new column `visible` has also been added to the output of `SHOW INDEX`, `SHOW INDEXES`, and `SHOW KEYS`. The `is_visible` or `visible` column indicates whether the index is visible to the optimizer. [#84776][#84776]
- Bulk operations and CDC will accept an `external` scheme URI that points to a previously created External Connection object, These operations can then interact with the underlying resource represented by the object as they did before. [#84931][#84931]
- Introduced VIEWACTIVITY, VIEWACTIVITYREDACTED, VIEWCLUSTERSETTING, CANCELQUERY, and NOSQLLOGIN as system privileges. [#84198][#84198]
- The SHOW DEFAULT PRIVILEGES command now has a column that says if the default privilege will give the grant option to the grantee. [#85027][#85027]
- Previously, ALTER DEFAULT PRIVILEGES errored out on functions. With this change, the statement would perform the grant/revoke the newly added `EXECUTE` privilege from default privileges. [#84471][#84471]
- The structured payloads used for telemetry logs now include the following new fields: MaxFullScanRowsEstimate: Maximum number of rows scanned by a full scan, as estimated by the optimizer. TotalScanRowsEstimate: Total number of rows read by all scans in the query, as estimated by the optimizer. OutputRowsEstimate: The number of rows output by the query, as estimated by the optimizer. StatsAvailable: Whether table statistics were available to the optimizer when planning the query. NanosSinceStatsCollected: The maximum number of nanoseconds that have passed since stats were collected on any table scanned by this query. BytesRead: The number of bytes read from disk. RowsRead: The number of rows read from disk. RowsWritten: The number of rows written. [#85169][#85169]
- Renaming statement to stmt,   and transaction to txn in columns. Adding   txn_fingerprint_id, query, status, start_time,   end_time, full_scan, user_name, app_name,   database_name, plan_gist, rows_read, rows_written,   priority, and retries columns to   crdb_internal.node_execution_insights [#85131][#85131]
- Can now specify explicit "true" and "false" values for "detached" and "revision_history" arguments in CREATE BACKUP and CREATE SCHEDULE FOR BACKUP. [#85146][#85146]
- Removes the DatabaseID field from the `SampledQuery` telemetry log due to the potential of indefinite blocking in the case of a lease acquisition failure. [#85017][#85017]
- CockroachDB now supports secondary regions. Secondary regions makes it possible to specify a failover region, which will recieve the leaseholder if the primary region fails. [#84450][#84450]
- Parser now supports creating an index with the option to mark them as invisible. But no implementation has done yet, and executing it returns an “unimplemented” error immediately. [#84783][#84783]
- Expand crdb_internal.complete_stream_replication to take successfulIngestion argument, which indicates if this stream ingestion finished successfully. [#83310][#83310]
- CREATE VIEW statements can now have a constant NULL column definition. The resulting column is of type TEXT. [#85134][#85134]
- GCP KMS can be represented as an External Connection object, that can be used during a backup or restore using the `external` URI. [#85075][#85075]
- Users can now IMPORT INTO a table with partial indexes from CSV, AVRO, and Delimited formats. This was previously disallowed. [#85244][#85244]
- Change `EXPLAIN` output of full scans with soft limits to "FULL SCAN (SOFT LIMIT)" instead of "FULL SCAN", to distinguish them from unlimited full scans. Unlimited full scans always scan the entire index. Full scans with soft limits could scan the entire index, but usually halt early once enough rows have been found to satisfy their parent operator. [#85421][#85421]
- Support privileges on virtual tables. Previously users were unable to GRANT on virtual tables, ie tables in crdb_internal / pg_catalog / information_schema.  Now users can GRANT/REVOKE `SELECT` privilege on virtual tables. `SELECT` is needed to query a virtual table.  Note that virtual tables privileges are NOT per database. Doing `GRANT SELECT ON crdb_internal.tables TO foo` allows foo to select on `crdb_internal.tables` across all databases.  Even if one does `GRANT SELECT ON dbname.crdb_internal.tables TO foo` the database is ignored, there is a warning saying the database is ignored. [#83604][#83604]
- The `pg_proc.proisstrict` column is now correctly populated instead of always being `false`. If this column is `true`, it indicates that the function will not be called if any of its inputs are `NULL`. Instead, it will directly evaluate to `NULL`. [#85676][#85676]
- When statistics are refreshed for a table, CockroachDB now deletes any old statistics on that table from columns or sets of columns that do not have their statistics refreshed by default. This ensures that stale statistics are removed and do not impact the optmizer's ability to create a high quality query plan. The retention time for these statistics is controlled by a new cluster setting, sql.stats.non_default_columns.min_retention_period, which defaults to 24 hours. [#85586][#85586]
- The structured payloads used for telemetry logs now include the following new fields: `InnerJoinCount`: The number of inner joins in the query plan. `LeftOuterJoinCount`: The number of left (or right) outer joins in the query plan. `FullOuterJoinCount`: The number of full outer joins in the query plan. `SemiJoinCount`: The number of semi joins in the query plan. `AntiJoinCount`: The number of anti joins in the query plan. `IntersectAllJoinCount`: The number of intersect all joins in the query plan. `ExceptAllJoinCount`: The number of except all joins in the query plan. `HashJoinCount`: The number of hash joins in the query plan. `CrossJoinCount`: The number of cross joins in the query plan. `IndexJoinCount`: The number of index joins in the query plan. `LookupJoinCount`: The number of lookup joins in the query plan. `MergeJoinCount`: The number of merge joins in the query plan. `InvertedJoinCount`: The number of inverted joins in the query plan. `ApplyJoinCount`: The number of apply joins in the query plan. `ZigZagJoinCount`: The number of zig zag joins in the query plan. [#85524][#85524]
- This change introduces the `ALTER DATABASE database_name ALTER LOCALITY {GLOBAL|REGIONAL|REGIONAL IN} set_zone_config` syntax which allows setting the zone config extension. The zone config extension, introduced by #78044, "_represents per-locality zone configurations that influence the zone configurations derived for corresponding objects. A locality type's associated extension acts as a targeted set of rewrite rules for its associated objects' (database, table, partition) derived zone configurations._" [#83605][#83605]
- EXPLAIN output no longer annotates simple operations (like `render` and `project`) with the execution statistics or estimates since that information is redundant (it is copied from the child operations). [#85649][#85649]
- Users can now `GRANT USAGE ON EXTERNAL CONNECTION` and `REVOKE USAGE ON EXTERNAL CONNECTION` to grant and revoke the `USAGE` privilege. This privilege is required by all operations that interact with external connections. [#85556][#85556]
- Previously pg_proc table was only populated with builtin functions. With createing UDFs supported, pg_proc table is extended to be populated with UDFs data as well. [#85656][#85656]
- A new virtual table crdb_internal.create_function_statements is added, so that users can use to query create statements of user defined functions, as well as parent db and schema ids. [#85656][#85656]
- This commit adds support for the SHOW CREATE FUNCTION statement. If given function name is qualified, the explicit schema will be searched. If function name is not qualified, the schemas on search path are searched and functions from the most significant schema are returned. [#85656][#85656]
- Previously, the `::regproc` casting only supported builtin functions. Now it's extened to support user-defined functions as well. [#85656][#85656]
- Adding last_retry_reason and exec_node_ids columns to crdb_internal.node_execution_insights [#85634][#85634]
- This pr adds the schema_only flag to RESTORE, allowing a user to run a normal RESTORE, without restoring any user table data. This can be used to quickly validate that a given backup is restorable. A schema_only restore runtime is O(# of descriptors) which is a fraction of a regular restore's runtime O(# of table rows).  Note that during a cluster level, schema_only restore, the system tables are read from S3 and written to disk, as this provides important validation coverage without much runtime cost (system tables should not be large).  After running a successful schema_only RESTORE, the user can revert the cluster to its pre-restore state by simply dropping the descriptors the schema_only restore added (e.g. if the user restored a database, they can drop the database after the restore completes). Note that in the cluster level case, the restored system data cannot be reverted, this shouldn't matter, as the cluster was empty before hand.  For the Backup validation use case, RESTORE with schema_only provides near total validation coverage. In other words, if a user's schema_only RESTORE works, they can be quite confident that a real RESTORE will work. There's one notable place schema_only RESTORE lacks coverage:  It doesn't read (or write) from any of the SSTs that store backed up user table data. To ensure a Backup's SSTs are where the RESTORE cmd would expect them to be, a user should run SHOW BACKUP ... with check_files. Further, in an upcoming patch, another flag for RESTORE validation will be introduced -- the verify_backup_table_data flag -- which extends schema_only functionality to read the table data from S3 and conduct checksums on it. Like with the schema_only flag, no table data will be ingested into the cluster. [#85231][#85231]
- Add VIEWDEBUG and VIEWCLUSTERMETADATA system privileges. [#85280][#85280]
- Add `ContentionTime` field to the `SampledQuery` telemetry log. Query-level statistics are collected earlier to facilitate the adding of contention time to query execution logs. The earlier collection of query-level statistics requires the additional overhead of fetching the query's trace twice (instead of previously once). [#84718][#84718]
- Index recommendations are generated for statements. New recommendations are generated every hour and available on `system.statement_statistics` and `crdb_internal.statement_statistics`. New cluster setting with default value of 100k sql.metrics.statement_details.max_mem_reported_idx_recommendations [#85343][#85343]
- SELECT ... FOR {UPDATE,SHARE} SKIP LOCKED is now supported. The option can be used to skip rows that cannot be immediately locked instead of blocking on contended row-level lock acquisition. [#85720][#85720]
- DROP FUNCTION is implemented in legacy schema changer. Now users can drop a function with a function name or a function signature. [#85718][#85718]
- A new crdb_internal virtual table, cluster_execution_insights, was introduced, offering a cluster-wide view of the same node-local information available in node_execution_insights. The insights subsystem is, as of this commit, still under development and disabled by default, so there will not yet be much to see here. [#85339][#85339]
- Users can now GRANT DROP ON EXTERNAL CONNECTION and REVOKE DROP ON EXTERNAL CONNECTION to grant and revoke the DROP privilege. This privilege is required by the user to DROP a particular External Connection. [#85770][#85770]
- Users can now `CREATE EXTERNAL CONNECTION` to represent a `kafka` sink. Subsequently, users can run `CREATE CHANGEFEED` with an `external:///<external-connection-object-name` URI as the sink to use the kafka resource represented by the external connection object. [#85410][#85410]
- The strptime and strftime builtin functions were added as aliases for experimental_strptime and experimental_strftime. [#85756][#85756]
- Users can now `CREATE EXTERNAL CONNECTION` to represent an s3 URI. [#85680][#85680]
- Added the format builtin function. format interpolates arguments into a string in the style of C's sprintf. For example, format('Hello, %s', 'world') returns 'Hello, world'. [#84107][#84107]
- Declarative schema changer now falls back to legacy schema changer when a user-defined function is found in the dependency graph when a `DROP` statement instead of throwing an unimplemented error. [#85981][#85981]
- Creating an external connection to represent and ExternalStorage will now write a sentinel file, list it, and read the contents back to validate the underlying resource. [#85847][#85847]
- Arrays can now be imported in a CSV file using the {} format, similar to COPY FROM. Importing array expressions (e.g. ARRAY[1, 2, 3]) is still supported as well. [#85850][#85850]
- Creating a not visible index using `CREATE TABLE …(INDEX … NOT VISIBLE)` or `CREATE INDEX … NOT VISIBLE` is now supported. [#85794][#85794]
- Make SHOW STATISTICS output more deterministic. [#77070][#77070]
- Add a new WITH FORECAST option to SHOW STATISTICS which calculates and displays forecasted statistics along with the existing table statistics. [#77070][#77070]
- Added the trunc(decimal, int) builtin function, which truncates the given decimal value to the specified number of decimal places. A negative value can be used for the scale parameter, which will truncate to the left of the decimal point.  Example: ``` > select trunc(541.234, 2), trunc(541.234, 0), trunc(541.234, -1);    trunc  | trunc | trunc ---------+-------+---------   541.23 |   541 | 5.4E+2 ``` [#85890][#85890]
- Users can now `CREATE EXTERNAL CONNECTION` to represent an underlying userfile resource. [#86006][#86006]
- Parser now supports altering an index to visible or not visible. But no implementation has done yet, and executing it returns an “unimplemented” error immediately.  # Conflicts: #	pkg/sql/sem/tree/stmt.go [#85473][#85473]
- Altering an index to visible or not visible using ALTER INDEX … VISIBLE | NOT VISIBLE is now supported. [#86032][#86032]
- When performed by the declarative schema changer (as is the case by default) the ALTER PRIMARY KEY statement now also drops the rowid column when no references are held to it anywhere. The rowid column is a hidden column which is implicitly added and serves as primary key on any table which is created without explicitly specifying a primary key. [#86071][#86071]
- Session setting `optimizer_use_not_visible_indexes` and cluster setting `sql.defaults.optimizer_use_not_visible_indexes.enabled` can be used to disable not visible index feature. When they are enabled, optimizer treats not visible indexes as they are visible and can choose to use them for query plan. By default, they are disabled. [#86033][#86033]
- Google Cloud KMS will now accept the `gcp-kms` scheme alongwith the existing `gs` scheme. External Connections will only recognize the `gcp-kms` scheme when being created to represent a KMS resource. [#85957][#85957]
- The asynchronous garbage collection process has been changed such that very soon after dropping a table, index, or database, or after refreshing a materialized view, the system will issue range deletion tombstones over the dropped data. These tombstones will result in the KV statistics properly counting these bytes as garbage. Before this change, the asynchronous "gc job" would wait out the TTL and then issue a lower-level operation to clear out the data. That meant that while the job was waiting out the TTL, the data would appear in the statistics to still be live. This was confusing. [#85878][#85878]
- Users can now `CREATE EXTERNAL CONNECTION` to represent an underlying google storage resource. [#85964][#85964]
- A new subsystem, "insights," has been enabled by default, gathering slow statement executions in the `crdb_internal.cluster_execution_insights` table along with possible reasons for the slowness: full scans / missing indexes, contention, plan changes, retries, etc. This system may be tuned by a handful of new cluster settings and monitored with a handful of new metrics, all in the `sql.insights` namespace. [#86216][#86216]
- When running `ALTER TABLE ... ADD PRIMARY KEY` or `ALTER TABLE ... ADD CONSTRAINT ... PRIMARY KEY` in a single-statement, implicit transaction, when no primary key had been added to the table, the old `rowid` column which had been automatically created as the table's `PRIMARY KEY` will now be dropped. [#86195][#86195]
- Adds contention  time to execution_insights [#85959][#85959]
- Secondary regions, like the primary regions can either be set inside or outside of a super region. In order to move a secondary region `alter_primary_region_super_region_override` must be enabled and the primary region moved. [#84999][#84999]
- We now support the `IF EXIST` syntax on `DROP SECONDARY REGION`. Using it will avoid returning an error if a secondary region isnt defined on a database. [#84999][#84999]
- Users can now `CREATE EXTERNAL CONNECTION` to represent an `azure-storage` URI. [#86257][#86257]
- Add support for `SHOW CREATE EXTERNAL CONNECTION` and `SHOW CREATE ALL EXTERNAL CONNECTIONS` that displays the connection name and the unredacted query used to create the external connection. This can only be run by users of the admin role today. [#86161][#86161]
- Adds index recommendation to execution_insights [#86055][#86055]
- This patch adds the verify_backup_table_data flag to RESTORE. When the user passes this flag, along with the required schema_only flag, a schema_only RESTORE will get run _and_ all user data will get read from external storage, checksummed, and disarded before getting written to disk.  This flag provides two additional validation steps that a regular schema_only RESTORE and a SHOW BACKUP with check_files cannot provide: This RESTORE verifies that all data can get read and rekeyed to the Restoring Cluster, and that all data passes a checksum check.  Release justification: low risk, high impact change to improve restore validation [#86136][#86136]
- Users can now `CREATE EXTERNAL CONNECTION` to represent an `aws-kms` scheme that represents an AWS KMS resource. [#86402][#86402]
- DROP OWNED BY cannot be performed if the user has synthetic privileges (in system.privileges) [#86619][#86619]
- We now support DISCARD SEQUENCES, which discards all sequence-related state such as currval/lastval information. DISCARD ALL now also discards sequence-related state.  Release justification: Bug Fix [#86230][#86230]
- EXPLAIN ANALYZE output now contains a warning when the estimated row count for scans is inaccurate and includes a hint to collect the table statistics manually. [#86677][#86677]
- New cluster setting `sql.stats.response.show_internal` with default value of `false` can be set to true, to display information about internal stats on SQL Activity page, with fingerprint option. [#86679][#86679]
- Fix the insight execution priority to have correct value instead of always being default. Changed the column to be a string to avoid converting it in the ui. [#86901][#86901]
- A new session setting, enforce_home_region, is added, which when true causes queries which have no home region or which may scan rows via a database connection outside of the query's home region to error out. Also, only tables in multiregion databases with ZONE survivability may be scanned without error when this setting is true because with REGION survivability, ranges in a down region may be served non-local to the gateway region, so are not guaranteed to have low latency.  Release justification: Low risk feature [#85704][#85704]
- This change introduces a new `BACKUP` privilege that is grantable as a system, database or table/type/schema level privilege. Users can opt-in to the new privilege model by granting the appropriate privileges as per the following model:  1. Cluster backups - user requires the system BACKUP privilege  2. Database backups - user requires the database BACKUP privilege  3. Table backups - user requires the table BACKUP privilege  In 22.2 we will continue to respect the old privilege model, but will completely swithover to the `BACKUP` privilege in 23.1.  Release justification: high impact change to offer fine grained privileges for bulk operations [#86495][#86495]
- This commit adds a new session setting, `optimizer_use_forecasts`, which can be set to false to disable usage of statistics forecasts when optimizing a query. [#86834][#86834]
- The structured payloads used for telemetry logs now include the new `Regions` field which indicates the regions of the nodes where SQL processing ran for the query. [#86829][#86829]
- Add the json{,b}_to_record{,set} builtin functions, which transform JSON into structured SQL records. [#82435][#82435]
- Add a new cluster setting `sql.stats.forecasts.enabled` which controls whether statistics forecasts are generated by default for all tables. (Note that this is different from the session setting `optimizer_use_forecasts` which controls whether statistics forecasts are used when optimizing the current query. If forecasting is disabled, then even if `optimizer_use_forecasts` is true for a given query it won't have any forecasts to use.) [#86932][#86932]
- Add a new table setting `sql_stats_forecasts_enabled` which controls whether statistics forecasts are generated for a specific table. When set, this overrides cluster setting `sql.stats.forecasts.enabled`. [#86986][#86986]
- This change introduces a new RESTORE privilege that is grantable as a system or database level privilege. Users can opt-in to the new privilege model by granting the appropriate privileges as per the following model:  Cluster backups - user requires the system RESTORE privilege  Database backups - user requires the system RESTORE privilege  Table backups - user requires the database RESTORE privilege  In 22.2 we will continue to respect the old privilege model, but will completely swithover to the RESTORE privilege in 23.1.  Release justification: high impact change to offer fine grained privileges for bulk operations [#86918][#86918]
- SHOW REGIONS now shows information about secondary regions.  Release justification: low risk update to new functionality. [#86924][#86924]
- SHOW SYSTEM GRANTS [FOR ROLE ...] allows you to see the grants done by GRANT SYSTEM ... [#86700][#86700]
- Support is now added for SHOW GRANTS ON EXTERNAL CONNECTION "name" FOR [users...] [#86700][#86700]

<h3 id="v22-2-0-alpha-2-operational-changes">Operational changes</h3>

- The meaning of the recently introduced `transaction_rows_written_err` and `transaction_rows_read_err` (as well as the corresponding `_log` variables) have been adjusted a bit to indicate the largest number of rows that is still allowed. In other words, originally reaching the limit would result in an error, and now only exceeding the limit would.  Release justification: low-risk adjustment to new functionality. [#69945][#69945]
- Cockroach debug zip will now include the raw system.settings table. This table makes it possible to determine whether a cluster settings has been explicitly set. [#70498][#70498]
- Job IDs and Session IDs are no longer redacted. These values do not represent sensitive or identifiable data, but do aid in debugging problems with the jobs system. [#71062][#71062]
- The meaning of `sql.distsql.max_running_flows` cluster setting has been extended so that when the value is negative, it would be multiplied by the number of CPUs on the node to get the maximum number of concurrent remote flows on the node. The default value is -128, meaning that on a 4 CPU machine we will have up to 512 concurrent remote DistSQL flows, but on a 8 CPU machine up to 1024. The previous default was 500. [#71787][#71787]
- Some existing settings related to BACKUP execution are now listed  by SHOW CLUSTER SETTINGS. [#71962][#71962]
- The cluster settings affecting the admission control system enablement are now set to defaults that enable admission control. [#68535][#68535]
- A new setting bulkio.ingest.flush_delay is added to act as a last-resort option to manually slow bulk-writing processes if needed for cluster stability. This should only be used if there is no better suited back-pressure mechanism available for the contended resource. [#73705][#73705]
- The default value of the kv.rangefeed.catchup_scan_iterator_optimization.enabled cluster setting is now true. [#73473][#73473]
- The license expiry metric is now available in the DB Console and includes the expected `HELP` and `TYPE` annotations in the promtheus output on `_status/vars`. [#71740][#71740]
- Added a metric `addsstable.aswrites` which tracks the number of `AddSSTable` requests ingested as regular write batches. [#73910][#73910]
- Added a metric `replica.uninitialized` which tracks the number of `Uninitialized` replicas in a store. [#73975][#73975]
- Sending a cockroach process, including one running a client command, a SIGUSR2 signal now causes it to open an http port that is serving the basic go performance inspection endpoints for use with pprof. [#75678][#75678]
- Operators who wish to access HTTP endpoints of the cluster through a proxy can now request specific nodeIDs through a `remote_node_id` query param or cookie with the value set to the nodeID they would like to proxy the connection to. [#72659][#72659]
- The admission.epoch_lifo.enabled cluster setting, disabled by default, enabled the use of epoch-LIFO adaptive queueing behavior in admission control. [#71882][#71882]
- The cluster setting bulkio.backup.resolve_destination_in_job.enabled can be used to delay resolution of backup's destination until the job starts running. [#76670][#76670]
- An off-by-default server.max_connections cluster setting has been added to limit the maximum number of connections to a server. [#76401][#76401]
- BACKUP now resolves incremental backup destinations during the job's execution phase rather than while it is being created to reduce contention on the system.jobs table. The setting bulkio.backup.resolve_destination_in_job.enabled that enabled this in some 21.2 patch releases is removed. [#76853][#76853]
- The cluster setting kv.raft_log.loosely_coupled_truncation.enabled can be used to disable loosely coupled truncation. [#76215][#76215]
- RESTORE now runs at a higher parallelism by default to improve performance. [#76907][#76907]
- Admission.epoch_lifo.epoch_duration, admission.epoch_lifo.epoch_closing_delta_duration, admission.epoch_lifo.queue_delay_threshold_to_switch_to_lifo are new cluster settings for configuring epoch-LIFO queueing. [#76951][#76951]
- Add `server.shutdown.connection_wait` to the draining process configuration. This provides a workaround when customers encountered intermittent blips and failed requests when they were performing operations that are related to restarting nodes.  Release justification: Low risk, high benefit changes to existing functionality (optimize the node draining process). [#72991][#72991]
- The cluster settings admission.kv.tenant_weights.enabled and admission.kv.stores.tenant_weights.enabled can be used to enable tenant weights in multi-tenant storage servers. The default is disabled. [#77575][#77575]
- This patch adds a new metric that charts the number of bytes received via snapshot on any given store. [#78278][#78278]
- Bulk ingest operations like IMPORT, RESTORE or CREATE INDEX will now fail if they try to write to a node that has less than 5% storage capacity remaining, configurable via the setting kv.bulk_io_write.min_capacity_remaining_fraction. [#78541][#78541]
- IMPORT jobs will now pause if a node runs out of disk space. [#78546][#78546]
- CREATE INDEX and some other schema changes will now pause if a node is running out of disk space. [#78546][#78546]
- RESTORE will now pause if a node is running out of disk space. [#78546][#78546]
- Rangefeed memory budgets got a cluster setting kv.rangefeed.memory_budgets.enabled that disables memory budgeting for all new feeds. This setting could be used on dedicated clusters to disable budgeting as a mitigation for bugs for example if feeds abort while nodes have sufficient free memory. [#78600][#78600]
- The `kv.allocator.load_based_rebalancing_interval` cluster setting now lets operators the interval at which each store in the cluster will check for load-based lease or replica rebalancing opportunities. [#78962][#78962]
- Rangefeed memory budgets could be disabled on the fly when cluster setting is changed without the need to restart the feed. [#78969][#78969]
- Adds a new metric for monitoring storage-level background migrations. [#79100][#79100]
- Changefeed creations and failures event logs are now emitted to the telemetry channel [#79513][#79513]
- Introduce cluster settings `kv.allocator.l0_sublevels_threshold` and `kv.allocator.L0_sublevels_threshold_enforce`, which enable excluding stores as targets for allocation and rebalancing of replicas when they have high read amplification, indicated by the number of L0 sub-levels in level 0 of the store's LSM. When both `kv.allocator.l0_sublevels_threshold` and the cluster average is exceeded, the action corresponding to `kv.allocator.l0_sublevels_threshold_enforce` is taken. `block_none` will exclude no candidate stores, `block_none_log` will exclude no candidates but log an event, `block_rebalance_to` will exclude candidates stores from being targets of rebalance actions, `block_all` will exclude candidate stores from being targets of both allocation and rebalancing. Default `kv.allocator.l0_sublevels_threshold` is set to `20` and `kv.allocator.l0_sublevels_threshold_enforce` is set to `block_none_log`. [#78608][#78608]
- Added `requests-per-second`, exposed through the `rebalancing.requestspersecond` metric. `requests-per-second` tracks the average number of requests received per store, aggregated over te ranges it contains. Added `reads-per-second`, exposed through the `relanacing.readspersecond` metric. `reads-per-second` tracks the count of keys read per second, on a replica basis. [#76609][#76609]
- HottestRanges will now report additional range statistics for the reported ranges. These statistics are: requests per second, the number of requests received by this range recently per second; writes per second, the number of keys written to in this range recently per second; reads per second, the number of keys read from this range recently, per second; write bytes per second, the number of bytes written to this range recently, per second; and the read bytes per second, the number of bytes read from this range recently, per second. [#76609][#76609]
- Increase the default value of `kv.transaction.max_refresh_span_bytes` from 256KB to 4MB. [#80115][#80115]
- Debug zip and merge-logs commands will now work with JSON formatted logs. [#79356][#79356]
- The default value for `storage.max_sync_duration` has been lowered from `60s` to `20s`. Cockroach will exit sooner with a fatal error if a single slow disk operation exceeds this value.  Touches #80942, #74712. [#81075][#81075]
- Tenants now account for bytes read and written to external services. Such reads and writes consume tenant resource units.  Release justification: High priority feature for multi-tenant resource accounting. [#76495][#76495]
- Added new 6 metrics (range.snapshots.shapshots.(unknown|recovery|rebalancing).sent-bytes and range.snapshots.shapshots.(unknown|recovery|rebalancing).rcvd-bytes) to the metrics dashboard. This will allow users to track the number of bytes sent/received for each type of metric in addition to the total bytes sent/received. [#81860][#81860]
- Disk stalls no longer prevent the cockroach process from crashing when Fatal errors are emitted. [#81708][#81708]
- The application name that is part of a SQL session, is no longer considered redactable information [#82742][#82742]
- A new setting `bulkio.backup.checkpoint_interval` controls the minimum interval between writes of progress checkpoints to external storage. [#83151][#83151]
- `httpSink`'s and `fluentSinks`'s will now, by default, have buffered writes enabled. This means that writes to these sinks will be asynchronous. This is enabled via a new default `buffering` configuration for both the `httpSink` and `fluentSink`, where the default values are as follows:  ``` buffering:     // The maximum amount of time between flushes to the underlying     // http or fluent sink.     max-staleness: 5s     // `flush-trigger-size` is the size in bytes of accumulated messages     //  in the buffer which will trigger a flush. 0 disables this trigger.     flush-trigger-size: 1MiB     // `max-buffer-size` limits the size of the buffer. When a new message     // is causing the buffer to overflow beyond this limit, old messages     // are dropped     max-buffer-size: 50MiB ``` This will show in `debug check-log-config` as well as impact the default behavior of these two types of network sinks. [#82893][#82893]
- Tenant-related crdb_internal function now require the admin role to use. [#83800][#83800]
- I/O admission control now reduces the likelihood of storage layer write stalls, which can be caused by memtable flushes becoming a bottleneck. This is done by limiting write tokens based on flush throughput, so as to reduce storage layer write stalls. Consequently, write tokens are now limited both by flush throughput, and by compaction throughput out of L0. This behavior is enabled by default. The new cluster setting admission.min_flush_util_fraction, defaulting to 0.5, can be used to disable or tune flush throughput based admission tokens. Setting it to a value much much greater than 1, say 10, will disable flush based tokens. Tuning the behavior, without disabling it, should be done only on the recommendation of a domain expert. [#82440][#82440]
- The `admission.kv.pause_replication_io_threshold` cluster setting can be set to a nonzero value to reduce I/O throughput on followers that are driven towards an inverted LSM by replication traffic. The functionality is disabled by default. A suggested value is 0.8, meaning that replication traffic to nonessential followers is paused before these followers will begin throttling their foreground traffic. [#83851][#83851]
- Telemetry logs will now display more finely redacted error messages from sql execution. Previously, the entire error string was fully redacted. [#83807][#83807]
- The way we track memory against `kv.transaction.max_intents_bytes` and `kv.transaction.max_refresh_spans_bytes` has been adjusted to be more precise (we no longer ignore some of the overhead). As a result, the stability of CRDB improves (we're less likely to OOM), however, this change effectively reduces the budgets determined by those cluster settings. In practice, this means that - the intents might be tracked more coarsely (due to span coalescing) which makes the intent resolution less efficient - the refresh spans become more coarse too making it more likely that `ReadWithinUncertaintyIntervalError`s are returned to the user rather than are retried transparently. [#84230][#84230]
- Added the storage metrics `rangekeycount`, `rangekeybytes`, `rangevalcount`, and `rangevalbytes` for MVCC range keys (i.e. MVCC range tombstones). These are analogous to the corresponding point key metrics (e.g. `keycount`). [#85453][#85453]
- Added new metrics `range.snapshots.(send|recv)-queue` and `range.snapshots.(send|recv)-in-progress` to track the number of queued and in-progress snapshots being sent or received on a store. [#84947][#84947]
- The cluster settings `bulkio.restore_at_current_time.enabled` and `bulkio.import_at_current_time.enabled`, which were introduced in 22.1 and defaulted to `true`, have been retired. They are now in effect always enabled. [#85757][#85757]
- Added new metrics: ``` queue.replicate.addreplica.(success|error) queue.replicate.removereplica.(success|error) queue.replicate.replacedeadreplica.(success|error) queue.replicate.removedeadreplica.(success|error) queue.replicate.replacedecommissioningreplica.(success|error) queue.replicate.removedecommissioningreplica.(success|error) ``` [#85844][#85844]
- Clusters can now run nodes with different --max-offset settings at the same time. This enables operators to perform a rolling restart to change the value of each node's --max-offset flag. [#85983][#85983]
- Introduce a new cluster setting (`server.secondary_tenants.redact_trace`) which controls if traces should be redacted for ops run on behalf of secondary tenants. [#85853][#85853]
- The `admission.kv.pause_replication_threshold` cluster setting is now set to a default value of 0.8. On a fully migrated v22.2+ deployment, this will allow the KV layer to pause replication streams to followers located on stores that are close to activating their I/O admission control subsystem (thereby protecting these followers from additional overload). The cluster setting can be disabled by setting it to zero. [#86147][#86147]
- The `sql.insights.execution_insights_capacity` cluster setting was introduced, limiting the number of SQL execution insights retained in memory per node. [#86272][#86272]
- The new `sql.insights.high_retry_count.threshold` cluster setting may be used to configure how many times a slow statement (as identified by the execution insights system) must have been retried to be marked as having a high retry count. [#86415][#86415]
- Finalizing an upgrade to 22.2 requires that all in-flight schema changes enter a terminal state. This may mean that finalization takes as long as the longest-running schema change. [#76154][#76154]
- The option `sql.mvcc_compliant_index_creation.enabled` has been removed. [#76154][#76154]
- Added a new timeseries metric `storage.keys.range-key-set.count` for observing the count of internal range key set keys in the storage engine. In the 22.2 release these RangeKeySet keys only used during DROP/TRUNCATE table or canceling an import. [#86570][#86570]
- The `sql.insights.anomaly_detection.enabled` cluster setting now defaults to true, and the `sql.insights.anomaly_detection.latency_threshold` cluster setting now defaults to 50ms, down from 100ms to complement the fixed-threshold detector's default of 100ms. [#86673][#86673]
- Disk bandwidth constraint can now be used to control admission of elastic writes. This requires configuration for each store, via the --store flag, that now contains an optional provisioned-rate field. The provisioned-rate field, if specified, needs to provide a disk-name for the store and optionally a disk bandwidth. If the disk bandwidth is not provided the cluster setting kv.store.admission.provisioned_bandwidth will be used. The cluster setting defaults to 0 (which means that the disk bandwidth constraint is disabled). If the effective disk bandwidth, i.e., using the possibly overridden cluster setting is 0, there is no disk bandwidth constraint. Additionally, the admission control cluster setting admission.disk_bandwidth_tokens.elastic.enabled (defaults to true) can be used to turn off enforcement even when all the other configuration has been setup. Turning off enforcement will still output all the relevant information about disk bandwidth usage, so can be used to observe part of the mechanism in action. To summarize, to enable this for a cluster with homogenous disk, provide a disk-name in the provisioned-rate field in the store-spec, and set the kv.store.admission.provisioned_bandwidth cluster setting to the bandwidth limit. To only get information about disk bandwidth usage by elastic traffic (currently via logs, not metrics), do the above but also set admission.disk_bandwidth_tokens.elastic.enabled to false.  Release justification: Low risk, high benefit change that allows an operator to enable new functionality (disabled by default). [#86063][#86063]
- The admission.kv.pause_replication_io_threshold cluster setting now default to zero (off). This supersedes an earlier release note about this setting. [#86776][#86776]
- Clusters that are upgraded to an alpha or other manual build from the development branch will not be able to be subsequently upgraded to a release build.  Release justification: high-priority change to existing functionality, to allow releasing alphas with known version upgrade bugs while ensuring they do not subsequently upgrade into stable version but silently corrupted clusters. [#86345][#86345]
- Added logging on replicate queue processing in the presence of errors or when the duration exceeds 50% of the timeout.  Release justification: Low risk observability change. [#86007][#86007]
- Full cluster restores now fail if an upgrade may be in progress. [#86848][#86848]

<h3 id="v22-2-0-alpha-2-command-line-changes">Command-line changes</h3>

- It is now possible to mix and match severity filters for different channels on a single log sink. For example:  ``` file-groups:    monitoring:      channels: {WARNING: [OPS, STORAGE], INFO: HEALTH} ```  This defines a single file sink "monitoring" which captures all messages from the HEALTH channel, and only messages at severity WARNING or higher from the OPS and STORAGE channels.  Another example:  ``` file-groups:    default:       channels: {INFO: all except STORAGE, WARNING: STORAGE} ```  This captures all messages on all channels except the STORAGE channel, plus the messages at severity WARNING or higher from STORAGE.  Note: the previous syntax remains supported. When 'channel' is specified without explicit severities, the 'filter' attribute is used as default (like previously). [#70052][#70052]
- It is now possible to mix and match severity filters for different channels on a single log sink. For example:  ``` file-groups:    monitoring:      channels: {WARNING: [OPS, STORAGE], INFO: HEALTH} ```  This defines a single file sink "monitoring" which captures all messages from the HEALTH channel, and only messages at severity WARNING or higher from the OPS and STORAGE channels.  Another example:  ``` file-groups:    default:       channels: {INFO: all except STORAGE, WARNING: STORAGE} ```  This captures all messages on all channels except the STORAGE channel, plus the messages at severity WARNING or higher from STORAGE.  Note: the previous syntax remains supported. When 'channel' is specified without explicit severities, the 'filter' attribute is used as default (like previously). [#69958][#69958]
- It is now possible to mix and match severity filters for different channels on a single log sink. For example:  ``` file-groups:    monitoring:      channels: {WARNING: [OPS, STORAGE], INFO: HEALTH} ```  This defines a single file sink "monitoring" which captures all messages from the HEALTH channel, and only messages at severity WARNING or higher from the OPS and STORAGE channels.  Another example:  ``` file-groups:    default:       channels: {INFO: all except STORAGE, WARNING: STORAGE} ```  This captures all messages on all channels except the STORAGE channel, plus the messages at severity WARNING or higher from STORAGE.  Note: the previous syntax remains supported. When 'channel' is specified without explicit severities, the 'filter' attribute is used as default (like previously). [#69955][#69955]
- It is now possible to mix and match severity filters for different channels on a single log sink. For example:  ``` file-groups:    monitoring:      channels: {WARNING: [OPS, STORAGE], INFO: HEALTH} ```  This defines a single file sink "monitoring" which captures all messages from the HEALTH channel, and only messages at severity WARNING or higher from the OPS and STORAGE channels.  Another example:  ``` file-groups:    default:       channels: {INFO: all except STORAGE, WARNING: STORAGE} ```  This captures all messages on all channels except the STORAGE channel, plus the messages at severity WARNING or higher from STORAGE.  Note: the previous syntax remains supported. When 'channel' is specified without explicit severities, the 'filter' attribute is used as default (like previously). [#69715][#69715]
- Cockroach demo will now begin processing scheduled jobs after 15s, instead of the 2-5min in a production environment. [#70242][#70242]
- The default logging configuration now redirects the HEALTH logging channel to a distinct log file (`cockroach-health.log`).  NB: This choice was informed by a preference of users for separate log files in the default configuration. As a result, the decision to deprecate the default configuration into separate log files is hereby reversed. [#70388][#70388]
- The default logging configuration now redirects the output on the SQL_SCHEMA channel to a new separate file group `sql-schema` (`cockroach-sql-schema.log`), and the `PRIVILEGES` and `USER_ADMIN` channels to a new separate file group `security` (`cockroach-security.log`). The new `security` group has the `auditable` flag set.  As previously, the administrator can inspect the default configuration with `cockroach debug check-log-config`. [#70388][#70388]
- The server logging configuration now also includes a copy of messages from all logging channels at severity WARNING or higher into the default log file. This ensures that severe messages from all channels are also included in the main log file used during troubleshooting.  NB: This configuration is only used when the operator does not customize the file output. As usual, the default configuration can be inspected using `cockroach debug check-log-config`. [#70388][#70388]
- Version details have been added to all json formatted log entries. Refer to the reference docs for details about the field. [#70285][#70285]
- The 25 max QPS rate limit for workloads on `cockroach` demo can now be configured with a `workload-max-qps` flag. [#70642][#70642]
- The sql shell now supports the `\du USER` command to show information for the current user. [#70609][#70609]
- Added support for a cli shortcut that displays constraint information similar to PostgreSQL. The shortcut is `\dd TABLE`. [#69783][#69783]
- `cockroach mt start-sql` will now support the following flags to configure ephemeral storage for SQL when processing large queries: `--store`, `--temp-dir`, and `--max-disk-temp-storage`. [#71040][#71040]
- `cockroach mt start-sql` will now support the `--max-sql-memory` flag to configure maximum SQL memory capacity to store temporary data.  Release justification: The upcoming Serverless MVP release plans to use a different value for --max-sql-memory instead of the default value of 25% of container memory. This commit is only a flag change that will only be used in multi-tenant scenarios, and should have no impact on dedicated customers. [#71011][#71011]
- Added a `--read-only` flag to `cockroach sql` which will set the `default_session_read_only` variable upon connecting. This is effectively equivalent to the `PGTARGETSESSIONATTRS=read-only` option added to libpq and `psql` in postgres 13. [#71003][#71003]
- Adds support for "${fpath}" in --prefix arg [#71254][#71254]
- Add option in demo movr command to populate user_promo_code table  Signed-off-by: Tharun <rajendrantharun@live.com> [#61531][#61531]
- Allow demoing of CockroachDB's multitenant features via the --multitenant flag to cockroach demo. [#71026][#71026]
- The SQL shell now supports a `\statement-diag` command for listing and downloading statement diagnostics bundles. [#71680][#71680]
- Cockroach demo now runs by default in multi-tenant mode. See 71026 for more details. [#71988][#71988]
- Add buffering to log sinks. This can be configured with the new "buffering" field on any log sink provided via the "--log" or "--log-config-file" flags.  Release justification: This change is safe because it is a no-op without a configuration change specifically enabling it. [#70330][#70330]
- The server identifiers (cluster ID, node ID, tenant ID, instance ID) are not any more duplicated at the start of every new log file (during log file rotations). They are now only logged when known during server start-up. (The copy of the identifiers is still included in per-event envelopes for the various `json` output logging formats.) [#73306][#73306]
- The `cockroach node drain` command is now able to drain a node by ID, specified on the command line, from another node in the cluster. It now also supports the flag `--self` for symmetry with `node decommission`. Using `node drain` without neither `--self` nor a node ID is now deprecated. [#73991][#73991]
- The deprecated command `cockroach quit` now accepts the flags `--self` and the ability to specify a node ID like `cockroach node drain`. Even though the command is deprecated, this change was performed to ensure symmetry in the documentation until the command is effectively removed. [#73991][#73991]
- A bug affecting the redactability of logging tags in output log entries has been fixed. This bug had been introduced in the v21.2 release. [#72992][#72992]
- Not finding the right certs in the certs dir or not specifying a certs dir or certificate path will now fall back on checking server CA using Go's TLS code to find the certificates in the OS trust store. If no matching certificate is found, then an x509 error will occur announcing that the certificate is signed by an unknown authority. [#73776][#73776]
- Fixed the CLI help text for ALTER DATABASE to show correct options for ADD REGION and DROP REGION, and include some missing options such as CONFIGURE ZONE. [#74929][#74929]
- If graceful drain range lease transfer encounters issues, verbose logging is automatically set to help with troubleshooting. [#68488][#68488]
- All `cockroach` commands now log their stack but do not exit when sent a SIGQUIT signal. This behavior is consistent with that already implemented for `cockroach start`. [#75678][#75678]
- The `debug zip` utility now also scrapes the cluster-wide KV replication reports in the output. [#75239][#75239]
- The flag `--self` of the `cockroach node decommission` command is deprecated. Instead, operators should specify the node ID of the target node as an explicit argument. The node that the command is connected to should not be a target node. [#74319][#74319]
- Add new optional version argument to the doctor examine command. This can be used to enable / disable validation when examining older zip directories. [#76166][#76166]
- This PR extends the debug zip CLI command to support exporting system and crdb_internal tables to a zip folder for tenants. [#75572][#75572]
- Added instructions to an error message when initializing tsdump. [#75880][#75880]
- `cockroach sql` (and `demo`) now continue to accept user input when Ctrl+C is pressed at the interactive prompt and the current input line is empty. Previously, it would terminate the shell.  To terminate the shell, the client-side command `\q` is still supported. The user can also terminate the input altogether via EOF (Ctrl+D). The behavior in non-interactive use remains unchanged. [#76427][#76427]
- The interactive SQL shell (`cockroach sql`, `cockroach demo`) now supports interrupting a currently running query with Ctrl+C, without losing access to the shell. [#76437][#76437]
- A new CLI flag `--max-tsdb-memory` is now available, that can set the memory budget for timeseries queries when processing requests from the Metrics page in DB Console. Most customers should not need to tweak this setting as the default of 1% of system memory or 64 MiB, whichever is greater, is adequate for most deployments. In the case where a deployment of hundreds of nodes has low per-node memory available (below 8 GiB for instance) it may be necessary to increase this value to `2%` or higher in order to render timeseries graphs for the cluster using the DB Console. Otherwise, the default settings will be adequate for the vast majority of deployments. [#74662][#74662]
- A drain of node now ensures that SQL statistics are not lost during the process; they are now preserved in the statement statistics system table. [#76397][#76397]
- CLI now auto completes on tab by using `SHOW COMPLETIONS AT OFFSET`. [#72925][#72925]
- Debug tsdump command allows viewing timeseries data even in case of node failures by rerunning the command with the import filename set to "-".  Release justification: low risk, high benefit changes to existing functionality [#77247][#77247]
- Fixes a bug where demo with the --global flag would not simulate latencies correctly when combined with the --insecure flag. [#77861][#77861]
- If decommissioning is slow or stalls, decommissioning replicas are printed to the operator.  Release justification: low risk, high benefit changes to existing functionality [#76516][#76516]
- Introduce a new `ttllogger` workload which creates a TTL table emulating a "log" with rows expiring after the duration specified in the `--ttl` flag. [#77649][#77649]
- The mechanism for query cancellation is disabled in the `sql` shell until a later patch release. [#79739][#79739]
- COPY ... FROM STDIN now works from the cockroach CLI. It is not supported inside transactions. [#79629][#79629]
- Add support for \password cli command that enables secure alteration of the password for a user. The given password will always be pre-hashed with the password hash method obtained via the session variable password-encryption, e.g. scram-sha-256 as the default hashing algorithm. [#77975][#77975]
- The standalone SQL shell executable `cockroach-sql` can now be installed (renamed/symlinked) as `cockroach`, and invoked via `cockroach sql`. For example, the following commands are all equivalent:  ``` $ cockroach-sql -f foo.sql $ cockroach-sql sql -f foo.sql after running `ln -s cockroach-sql cockroach`: $ cockroach sql -f foo.sql ``` [#80833][#80833]
- A new flag `--advertise-http-addr` is available for setting the HTTP advertise address explicitly. Previously, this address was derived from the OS hostname, the `--advertise-addr` and the `--http-addr` flags in that order. The new logic will override the HTTP advertise host with the host from `--advertise-addr` first if set, and then the host from `--http-addr`. The port will *never* inherit from `--advertise-host` and only from `--http-addr`, which is 8080 by default. The HTTP advertise address is used to report the DB Console address to access on a cluster and by nodes to proxy HTTP connections as described in #73285. It may be necessary to set this flag in order for that feature to work correctly in some deployments. [#79966][#79966]
- Changes the default `debug compact` maximum compaction concurrency to the number of processors, and adds a `--max-concurrency` flag for overriding the new default. [#78987][#78987]
- `cockroach debug zip` now includes all system tables by default, except for a few (a deny list). [#81306][#81306]
- The standalone `cockroach-sql` executable now has more compatibility with `cockroach sql`, so it can be used as a drop-in replacement. For example, it supports running without a URL, using connection defaults. It also supports overriding `--certs-dir` and other client-side options also supported by `cockroach sql`. [#82020][#82020]
- The client cert generation command is being extended to create a tenant scoped client certificates. Tenant scoped certs will authenticate a client for a specific tenant. [#79064][#79064]
- BYTEA values are now formatted according to the bytea_output session setting. [#81943][#81943]
- The statement tag displayed for INSERT statements now has the full information returned by the server. It is the string "INSERT" followed by the OID of the row that was inserted (which is currently always 0 in CockroachDB), followed by the number of rows inserted. [#81943][#81943]
- CLI commands that use a SQL connection (e.g. `cockroach sql`, `cockroach node status`, etc) now support connecting with PGPASSFILE and PGSERVICEFILE. The behavior is compatible with how libpq (the psql C library) behaves.  PGPASSFILE defaults to ~/.pgpass. It is a file that contains lines in the format ``` hostname:port:database:username:password ``` The password field from the first line that matches the current connection parameters will be used to connect to the database.  PGSERVICEFILE defaults to ~/.pg_service.conf. It is a file that contains lines in the format ``` [myservice] host=somehost port=26257 user=someuser ``` Any connection parameters (including passfile or password) can be specified here. Then, a connection string that specifies the `service=myservice` connection parameter will use the values in PGSERVICEFILE to connect. [#82389][#82389]
- CLI commands that use a SQL connection (e.g. `cockroach sql`, `cockroach node status`, etc) now default to using the the file in ~/.postgresql/root.crt for the `sslrootcert` when connecting. The file can still be configured using the PGSSLROOTCERT environment variable or the `sslrootcert` URL parameter. [#82389][#82389]
- Using COPY in the CLI is now supported while inside an explicit transaction. [#82101][#82101]
- Ctrl+C (the interrupt signal) can now be used in the CLI to attempt to cancel the currently executing SQL query. [#82101][#82101]
- `cockroach sql` (and thus `cockroach demo` too) now support the client-side commands `\o` and `\qecho` like `psql`. The command `\o` can redirect the output of SQL queries to a file. `\qecho` adds an arbitrary text to the current query output file. [#83118][#83118]
- Cockroach demo now enables rangefeeds by default. You can restore the old behavior with --auto-enable-rangefeeds=false. [#83282][#83282]
- CockroachDB now produces a clearer error when the path specified via `--socket-dir` is too long. [#84532][#84532]
- When the flag `--background` is specified, CockroachDB now makes 3 attempts to find a suitable directory to create the notification socket: the value of `--socket-dir` if specified, the value of `$TMPDIR` (or /tmp if the env var is empty), and the current working directory. If none of these directories has a name short enough, an explanatory error is printed. [#84532][#84532]
- The CLI now contains a flag (--log-config-vars) that allows for environment variables to be specified for expansion within the logging configuration file. This change allows for a single logging configuration file to service an array of sinks without further manipulation of the configuration file. [#82147][#82147]

<h3 id="v22-2-0-alpha-2-api-endpoint-changes">API endpoint changes</h3>

- CREATE CHANGEFEED on a CloudStorage sink now allows a new query parameter to specify how the file paths are partitioned, for example partition_format="daily" represents the default behavior of splitting into dates (2021-05-01/), while partition_format="hourly" will further partition them them by hour (2021-05-01/05/), and partition_format="flat" will not partition at all [#70207][#70207]
- Serverless ListContentionEvent RPC now returns cluster-wide contention events. [#70959][#70959]
- Serverless's IndexUsageStatistics RPC now returns cluster-wide data. [#70966][#70966]
- CombinedStatementStats RPC is now allowed for tenant. [#71027][#71027]
- OIDC support for DB Console is no longer marked as "experimental" [#71183][#71183]
- The tenant `/_status/cancel_session` endpoint was made available over HTTP and augmented to fan out requests in a multi-pod world. [#71174][#71174]
- The tenant `/_status/cancel_query` endpoint was made available over HTTP and augmented to fan out requests in a multi-pod world. [#71503][#71503]
- `aggregationInterval` field has been added to combined statements response. [#71538][#71538]
- Add new api endpoint for getting a table's index statistics. [#72660][#72660]
- Added new batch RPC and batch method counters now visible in DB console and _status/vars. [#72767][#72767]
- Creation of new endpoint `/sqlroles` that returns a list of the SQL roles for the SQL user logged in. [#74920][#74920]
- The `/_status/load` endpoint, which delivers an instant measurement of CPU load, is now available for regular CockroachDB nodes and not just multitenant SQL-only servers. (This is arguably a bug fix - this endpoint should have been available from the start.) [#75852][#75852]
- StatusClient interface has been extended with a new request called NodesListRequest. This request returns a list of KV nodes for KV servers and SQL nodes for SQL only servers with their corresponding SQL and RPC addresses. [#75572][#75572]
- Users with the VIEWACTIVITYREDACTED role will not have access to the full queries with constants in the the ListSessions response. [#76675][#76675]
- New Statement Details endpoint that returns the details for a selected statement, and its execution separated by aggregation timestamp (statementsPerAggregatedTs) and by plan hash (statementsPerPlanHash). [#76592][#76592]
- Introducing GET `/_status/transactioncontentionevents` endpoint, that returns cluster-wide in-memory historical transaction contention events. The endpoint require either VIEWACTIVITYREDACTED OR VIEWACTIVITY role option to access. However, if user has VIEWACTIVTYREDACTED role, the contending key will be redacted. The contention events are stored in memory. The amount of contention events stored is controlled via 'sql.contention.event_store.capacity' cluster setting.  Release Justification: Low risk, high benefit change [#76917][#76917]
- The status api will now have a newly exposed `_status/tenant_ranges` endpoint available to tenants, although it's not currently used except for debug.zip (see following commit).  Release justification: low-risk updates to new functionality [#76743][#76743]
- Added logic to support dropping unused index recommendations. [#77642][#77642]
- `ListSessions` now returns closed sessions in addition to open sessions; `ListSessionsRequest` now has a `exclude_closed_sessions` flag; `serverpb.Session` now has `end` and `status` fields. [#78650][#78650]
- Update api/v2/rules endpoint to include alerts defined in our customer facing docs. [#80274][#80274]
- The ListSessions api has a new field `last_auto_retry_reason` under the `active_txn` field for a session. This field contains the string describing the retry reason or nil if none exists.  This is also surfaced in the `crdb_internal.{cluster,node}_transactions` tables and the `SHOW TRANSACTIONS` command under the `last_auto_retry_reason` column. [#81531][#81531]
- The `serverpb.Session` struct now has three new fields: number of transactions executed, transaction fingerprint IDs, and total active time. [#82352][#82352]
- A new `/api/v2/sql/` endpoints enable execution of simple SQL queries over HTTP. [#79663][#79663]
- Add information about total bytes, live (non MVCC) bytes and live (non MVCC) percentage to Table Details endpoint. [#83677][#83677]
- Returning index recommendations on the statement details api. [#85863][#85863]

<h3 id="v22-2-0-alpha-2-db-console-changes">DB Console changes</h3>

- Update 'clear SQL stats' color and change to lower case on Transaction and Statements page [#70039][#70039]
- Fix color for link on tooltip on Metrics page for chart Transaction Retries [#70051][#70051]
- Updating ui of o11y pages to match remaning pages (e.g. spacing, colors, font sizes) [#70034][#70034]
- Update error message on date picker on Statements and Transactions page. [#70053][#70053]
- Add tooltips on Databases pages and make SQL Box scrollable. [#70065][#70065]
- When requesting the pprofui endpoints from the Advanced Debug page in DB Console, operators can now query by node ID in order to request pprofui data from any node in the cluster without having to connect to its DB Console directly. Profiling UI links are in a separate section along with a nodeID selector to allow for easy targeting. [#68019][#68019]
- Replicas awaiting to be GCed were causing the range report page to not load at all due to a JS error. The page will now load and display an empty "Replica Type" while in this state. [#69443][#69443]
- Add column selector to transaction page [#70262][#70262]
- Fix drag to zoom on custom charts [#70229][#70229]
- Persisted statements are now enabled for tenants. In the statements and transactions pages, users now view the aggregated statistics for statements and transactions over a date range. A date range selector is present in both pages order to select the range of persisted stats to view. Note that the two pages share a single date range. [#70218][#70218]
- Updating job table style to match all other tables on the console and also  update column name from `Users` to `User`. [#70374][#70374]
- Fix bug where Clock Offset graph rendered incorrectly on nodes with multiple stores. [#70363][#70363]
- Fix drag-to-timerange for specific window issue [#70326][#70326]
- Show info not yet sampled on Statement Details page as unavailable, instead of value 0. [#70534][#70534]
- Add mean rows written to statement details page [#70377][#70377]
- Remove last cleared status from Statements, Transactions and Transaction Details page and updates the tooltip on clear SQL stats to indicate it will clean also the persisted data. [#70601][#70601]
- On the explain plan tab in statement details, Users will be able to hover over underlined explain plan attributes to get tooltips with more information on the attribute. [#70568][#70568]
- A new column, "Rows Written" has been added onto the Statements and Transactions tables. This column will not show up by default, but can be selected from the column selector. A new metric "Mean rows written" has also been added to the Transaction Details page. [#70593][#70593]
- For statement detail URLs, the app name and database name are now query string parameters. The route to statement details is now definitively `/statement/:implicitTxn/:statement?{queryStringParams}`.  e.g. `statement/true/SELECT%20city%2C%20id%20FROM%20vehicles%20WHERE%20city%20%3D%20%241?database=movr&app=movr` [#70600][#70600]
- Remove link to Statement Details on the Session table [#70785][#70785]
- A new column, 'Interval Start Time (UTC)', has been added to both statement and transaction tables. The column represents the start time in UTC of the stats aggregation interval for a statement. By default, the aggregation interval is 1 hour. 'Interval Start Time' has been added to the statement details page under 'Statement Details'.  A new query parameter has been added to statement details pages. If the search param `aggregated_ts` is set, it will display the statement details for statements aggregated at that interval. If unset, we will display the statement details for the statement aggregated over the current date range. [#70282][#70282]
- Add presizing calc for metrics page graphs [#70838][#70838]
- The terminate session and terminate query buttons have been temporarily disabled in the cluster ui. [#70955][#70955]
- Update color, fonts and spaces on Statements, Statements Details, Transaction, Transactions Details and Session pages [#70948][#70948]
- Non-Admin users of the DB Console have regained the ability to view the cluster overview page. Users without the Admin role will still see most data about their nodes but information such as command line arguments, environment variables, and IP addresses and DNS names of nodes will be hidden. [#71181][#71181]
- Replace `(internal)` on filter and details on Statements page for `$ internal` to align with Transactions Page. [#71581][#71581]
- Show new statement summaries on the Statements page. This applies for SELECT, INSERT/UPSERT, and UPDATE statements, and will enable them to be more detailed and less ambiguous than our previous formats. [#71534][#71534]
- Session, Statement and Transaction pages are now grouped inside the new SQL Activity page. [#71325][#71325]
- The /debug/pprof/goroutineui/ page has a new and improved look. [#71690][#71690]
- `Interval Start Time (UTC)` column in statements and transactions pages has been renamed `Aggregation Interval (UTC)` and is the interval of aggregation. The statement details page will also display the interval for which the user is viewing statement details. [#71538][#71538]
- When an error is encoutered in the statement/ transaction/session page, user can now click on reload button to reload the page. [#71846][#71846]
- Use new summarized formats for SELECT, INSERT/UPSERT, and UPDATE statements on the Sessions and Transaction pages, to be consistent with the Statements page. Show "Mean rows written" as a metric for all statement types on the Statements page, instead of hiding this metric for SELECT statements. [#71817][#71817]
- App filter on Transaction and Statement pages is now multi select. [#71897][#71897]
- TransactionDetail page now shows statement statistics scoped by the transaction fingeprint. [#71967][#71967]
- The default value when no App is selected on Transactions and Statements filter is now excluding internal Transactions and Statements. [#71966][#71966]
- All Nodes report notifies user is they need more privileges to view information. [#71960][#71960]
- Update tooltip text on Statement column on Session table to the accurate information that we show only currently active statements. [#72057][#72057]
- Node events will now display a permission error rather than an internal server error when user does not have admin priviledges to view events. [#72416][#72416]
- Fix issue on Metrics page when graphs don't show data for date ranges older than 10 days [#72431][#72431]
- Show gaps for metrics graphs instead of data interpolation. [#72431][#72431]
- Updated Not Found page [#72689][#72689]
- Show gaps for metrics graphs instead of data interpolation. [#71810][#71810]
- New page for when something goes wrong and the page crashes. [#72770][#72770]
- Fix drag-to-zoom granularity issue [#70594][#70594]
- The absolute links on the Advanced Debug page within DB Console have been updated to relative links. This will enable these links to work with the superuser dashboard in Cloud Console. [#72837][#72837]
- The Advanced Debug page on DBConsole contains an additional link under the metrics header called Rules. This endpoint exposes Prometheus compatible alerting and aggregation rules for CRDB metrics. [#72677][#72677]
- Add index stats table and button to clear index usage stats on the Table Details page for each table. [#72948][#72948]
- Visual improvements to db console [#73253][#73253]
- Add ability to remove dashed underline from sorted table headers for headers with no tooltips. Remove the dashed underline from the Index Stats table headers. [#73455][#73455]
- Add new Index Details page, which exists for each index on a table. [#73178][#73178]
- The jobs overview table in DBConsole now shows when jobs have the status "reverting", and shows the badge "retrying" when running or reverting jobs are also retrying. Hovering the status for a "retrying" job will show the "Next execution time" in UTC. Two new columns, "Last Execution Time (UTC)" and "Execution Count", were also added to the jobs overview table in DBConsole, and the "Status" column was moved left to the second column in the table.  The `status` query parameter in the `/jobs` endpoint now supports the values `reverting` and `retrying`. [#72291][#72291]
- Update "reset index stats" button text to be more clear [#73700][#73700]
- The time pickers on the Statements and Transactions pages now have the same style and functionality as the time picker on the Metrics page. [#73608][#73608]
- The "clear SQL stats" links on the statement and transaction pages were relabeled "reset SQL stats," for consistency with the language in the SQL shell. [#73922][#73922]
- Updated text of filter drop-down for consistency [#73917][#73917]
- Add ability to create conditional statement diagnostics by adding two new fields 1) minimum execution latency, which specifies the limit for when a statement should be tracked and 2) expiry time, which specifies when a diagnostics request should expire. [#74112][#74112]
- The terminate session and terminate query buttons are again available to be enabled in the cluster ui. [#74408][#74408]
- Added formatting to statements on the statement, transaction and index details pages. [#73853][#73853]
- Remove `$ internal` as one of the apps option under the Statements and Transactions page filters. [#75470][#75470]
- Removed formatting to statements on the statement, transaction and index details pages, change to replace raw statement with statement ID in the URL remained. [#75443][#75443]
- Change the order of tabs under SQL Activity page to be Statements, Transactions and Sessions. [#75490][#75490]
- Logical plan text included in searchable text for stmts page. [#75097][#75097]
- If the user has the role VIEWACTIVITYREDACTED, we hide the Statement Diagnostics bundle info on Statement page (diagnostics column), Statement Details page (diagnostics tab) and Advanced Debug page (diagnostics history). [#75274][#75274]
- Loading and error pages are now below page config in txns and stmts pages. [#75458][#75458]
- Add `Circuit Breaker` graphs on Replication metrics page in Db Console. [#75613][#75613]
- Added an option to cancel a running request for statement diagnostics. [#75733][#75733]
- DB Console requests can be routed to arbitrary nodes in the cluster. Users can select a node from a dropdown in the Advanced Debug page of the DB Console UI to route their UI to that node. Manually initiated requests can either add a `remote_node_id` query param to their request or set a `remote_node_id` HTTP cookie in order to manage the routing of their request. [#72659][#72659]
- We don't show information about aggregations timestamp in Statements overview and Details pages, since now all the statement fingerprints are grouped inside the same time selection. [#76301][#76301]
- - Added status of automatic statistics collection to the Database and Database table pages on the DB Console. - Added timestamp of last statistics collection to the Database details and Database table pages on the DB Console. [#76168][#76168]
- Open SQL Transactions and Active SQL Transactions are downsampled using MAX instead of AVG and will more accurately reflect narrow spikes in transaction counts when looking and downsampled data. [#76348][#76348]
- Display circuit breakers in problems ranges and range status [#75809][#75809]
- The "Now" button had been added in this commit https://github.com/jocrl/cockroach/commit/82f2673babe8f930114cf6b8289caaa64ff84045 to the Statements and Transactions Pages. This commit removes the "reset time" link which the "Now" button replaces. [#76691][#76691]
- Change invalid lease to expired lease on problem ranges page [#76757][#76757]
- Added column selector, filters, new columns to the sessions page and sessions details. [#75965][#75965]
- Add long loading messages to SQL Activity pages. [#76739][#76739]
- ; display locality information in problem ranges and range status.  Release justification: Low risk, high benefit changes to existing functionality [#76892][#76892]
- Display is_leaseholder and lease_valid information in problem ranges and range status pages.  Release justification: Low risk, high benefit changes to existing functionality [#76892][#76892]
- Add Hot Ranges page and link to it on the sidebar  Release justification: bug fixes and low-risk updates to new functionality [#77330][#77330]
- Remove stray parenthesis at the end of the duration time for a succeeded job. It had been accidentally introduced to unreleased master and a 21.2 backport.  Release justification: Category 2, UI bug fix [#77438][#77438]
- Add alert banner on overview list page for staggered node versions  Release justification: [#76932][#76932]
- The Flushes/Compactions graph on the Storage metrics Dashboard now shows bytes written by these operations, and has been split into separate graphs which are each  per-node. [#77558][#77558]
- Explain Plan tab on Statement Details shows statistics for all the plans executed by the selected statement on the selected period. [#77632][#77632]
- Fixed a bug where the clicking the "Reset SQL stats" button on Statements and Transactions pages caused, in DB Console, an infinite loading spinner and, in CC Console, the statements/transactions table to be reloaded without limiting to the time range that the user had selected. The button now correctly reloads the table according to the selected time in both DB Console and CC Console.  Release justification: Category 2, UI bug fix [#77571][#77571]
- Active operations can now be inspected in a new page linked from "Advanced Debug". [#77712][#77712]
- Add Full Scan, distributed and vectorized information of the plan displayed on Statement Details page (Overview and Explain Plan tabs)  Release justification: low risk, high benefit change [#77936][#77936]
- Improved colors for status badges on the Jobs page. Three status on the Jobs page, `cancel-requested`, `pause-requested`, and `revert-failed`, previously had blue status badge colors that were uninformative of their meaning. This commit modifies the badge colors to reflect their meaning. Now `cancel-requested` and `pause-requested` have gray badges and `revert-failed` has a red badge. [#78186][#78186]
- The `_status/nodes` endpoint is avaible to all users with the `VIEWACTIVITY` role option, not just Admins. In the DB Console, the Nodes Overview and Node Reports pages will now display unredacted information containing node hostnames and IP addresses for all users with the `VIEWACTIVITY` role option. Previously this was also gated for Admins only. [#78045][#78045]
- App names and database names in the dropdown menu are sorted. [#78095][#78095]
- Add index created time as an option on the db-console database table page [#78283][#78283]
- The replication dashboard now includes a graph of snapshot bytes received per node. [#78562][#78562]
- Fixes a bug where a node in the `UNAVAILABLE` state will not have latency defined and cause the network page to crash. [#78292][#78292]
- Users can now see actively running queries and transactions in the SQL Activity tab. The transactions and statements tabs in SQL activity now have a menu to show either active or historial transactions and statements data. [#76753][#76753]
- Add last modified timestamp and coordinator ID to Jobs page to aid in debugging jobs issues. [#78501][#78501]
- Minor styling changes on Hot Ranges page to follow the same style as other pages. [#79133][#79133]
- Add index recommendations to the databases pages (databases, database details, database table, and index details pages) for db console. [#79365][#79365]
- Filtering by column is added to Hot Ranges page. [#79038][#79038]
- More jobs now shows up as a types filter on the jobs page. [#79936][#79936]
- Statements are not longer separated by aggregation interval on Statement Page. Now all statements with same fingerprint show as a single row. [#80116][#80116]
- Add dropdown filter on the node diagnostics page to view by active, decomissioned or all nodes. [#79900][#79900]
- Fix resizing of table on Hot Ranges page [#80481][#80481]
- Sessions overview and session details pages now display closed sessions; sessions overview page now has username and session status filters [#80410][#80410]
- The time picker (in the Metrics and SQL Activity, among other, pages) custom selection now defaults to the currently selected time. [#80660][#80660]
- The time selection component previously on the Statements and Transactions Pages has been added to the Statement Details Overview and Explain Plan tabs, and the Transaction Details page. [#76687][#76687]
- Previously, when the Jobs page timed out, it would have the message "Promise timed out after 30000 ms". Now, it has a more helpful error message, and an information message that appears after 2 seconds of loading and indicates that the loading might take a while. [#80743][#80743]
- Fix the size of table area on Statement and Transactions pages to not cut the columns selector and filters. [#81049][#81049]
- The tool tip for a sessions status has been updated with a more explicit definition. [#80726][#80726]
- Update all dates to use 24h format in UTC [#81077][#81077]
- The time picker component has been improved such that users can use keyboard input to select a time without having to type `" (UTC)"` [#81200][#81200]
- The "Learn more" link on an empty transactions link now mentions transactions. [#81530][#81530]
- Circuit Breaker Tripped events chart displays rate of events per interval instead of accumulated number of events. [#81438][#81438]
- The job status page in the DB Console will now show the status column for changefeed jobs and display the `highwater_timestamp` value in a separate column. Thise more closely matches the SQL output of `SHOW changefeed JOBS`. The highwater timestamp now displays as the nanosecond system time value by default with the human-readable value in the tooltip since the decimal value is copy/pasted more often. [#81213][#81213]
- The Jobs Page now shows the oldest time (in UTC) that jobs are shown for. [#81148][#81148]
- The time picker now opens directly to the custom time selection menu when a custom time is already selected. A "Preset Time Ranges" navigation link has been added to go to the preset options from the custom menu. [#81855][#81855]
- Display old version of cluster (cluster_version - Mixed Versions) when cluster runs nodes with different versions. [#82118][#82118]
- Add stream ingestion metrics [#79714][#79714]
- Statement Details page now shows charts for: Execution and Planning Time, Rows Processed, Execution Retries, Execution Count and Contention. [#82426][#82426]
- Update README in pkg/ui with Bazel dev directions. [#82999][#82999]
- Add confirmation modal to `reset SQL Stats` [#83108][#83108]
- Fix grammer on mixed version banner alert [#83150][#83150]
- Add period label to pages Statement, Statement Details and Transaction, with information about the period to which we're showing information from. Removal of exec stats tab under Statement Details page. [#83103][#83103]
- In the statements page, users can no longer filter statements by searching for text in the EXPLAIN plan. [#83423][#83423]
- The period selected on the Metrics page and the SQL Activity pages are now aligned. If the user changes in one page, the value will be the same for the other. [#83107][#83107]
- Combine columns rows read and rows written on Statements and Transactions pages into a single column called Rows Processed, which is displayed by default. [#83443][#83443]
- Updated tooltips on the Statements and Transactions pages in the DB Console for improved UX. [#83420][#83420]
- Removal of the 10 and 30min options on the SQL Activity page. [#83229][#83229]
- In the SQL Activity Page, the selection to view historical or active executions will persist between tabs. [#83903][#83903]
- The Active Statements and Active Transactions pages now have a single filter option for internal apps. These pages no longer display internal statements and transactions by default. [#83014][#83014]
- Ability to search for the exact terms in order when wrapping the search in quotes. [#84044][#84044]
- Adds mvcc info to tables list inside the Database page and on the Tables details page. [#84037][#84037]
- Removal of `View Statement Details` link inside the Sessions Details page. [#84485][#84485]
- Update of labels from "date range" to "time interval" on time picker (custom option, preset title, previous and next arrows) [#84486][#84486]
- Update Jobs Details page to new design and add information about Last Execution Time, Next Execution Time and Execution Count. [#84498][#84498]
- Update on Statement Details, Active Statement Details, Transaction Details and Active Transaction Details summary component, updating its style. [#84500][#84500]
- Update the message when there is no data on the selected time interval on Statement and Transaction pages. [#84494][#84494]
- Update time picker options to remove "1" on the hour and day options. [#84510][#84510]
- Adds new Last Execution Time to Statements, which is hidden by default. [#84501][#84501]
- Added "Range Key Bytes" and "Range Value Bytes" stats on Node details page. [#85599][#85599]
- Fix issue with incorrect start time position of selected time range on Metrics page. [#85809][#85809]
- A new section, 'Wait Time Insights' has been added to the active statement and transaction details page. The section is included if the txn being viewed is experiencing contention and includes info on the blocked schema, table, index name, time spent blocking, and the txns blocking or waiting for the viewed txn.  Only users having `VIEWACTIVITY` or higher can view this feature. The column 'Time Spent Waiting' has been added to the active executions tables that shows the total amount of time an execution has been waiting for a lock. [#85081][#85081]
- Displaying insights of index recommendations on the Explain Plans tab on Statement Details page. [#85863][#85863]
- Added new Insights page to DB Console [#84612][#84612]
- The following fields have been added to the active stmt/txn details pages: - Full Scan: indicates if the execution contains a full scan - Last Retry Reason (txn page only): the last recorded reason the txn was retried - Priority (txn page only): the txn priority The following fields have been added to the sessions table and page: - Transaction  count: the number of txns executed by the session - Session active duration: the time a session spent executing txns - Session most recent fingerprint ids [#85974][#85974]
- Remove back to sessions link on Session Details not found page. [#86050][#86050]
- The statements and transaction fingerprint now refresh data every 5 minutes for non-custom time ranges  Release justification: bug fix [#85772][#85772]
- The `time spent waiting` columns for active execution tables has been  hidden on CC [#86264][#86264]
- Txns and stmts in active exec pages that are waiting for a lock will now have the status 'Waiting' [#86329][#86329]
- Added new Workload Insight Details page to DB Console  Release justification: low-risk updates to new functionality [#86325][#86325]
- Adding a button to perform the index recommendation directly from DB Console. Being added to the Statement Details page, under the Explain Plan tab.  Release justification: category 2, update to new functionality [#86382][#86382]
- Remove the Next Planned Execution Time label, when the job doesn't have a next planned execution scheduled. [#86486][#86486]
- Filter live nodes based on MembershipStatus and retrieve livenesses directly from kv. [#86252][#86252]
- New styles of summary cards on Session Details page to align with other details pages. [#86572][#86572]
- Add link to explain plan table linking to explain doc page. [#86581][#86581]
- Surface paused replicas to range report, problem ranges, and replication metrics pages. [#86407][#86407]
- Use plan gist instead of plan ID on plans table inside the Explain Plan tab of Statement Details. Also add the plan gist as the first line on the actual Explain Plan display. [#86653][#86653]
- Add clarification of compression to tooltip of table size. [#86821][#86821]
- Changing the height of SQL Box usage on Session Details, Active Transaction Details, Job Details and Active Statement Details. [#86812][#86812]
- Added new Schema Insights page to DB Console. The Schema Insights page displays a table of schema insights - currently different types of index recommendations (i.e. drop/create/replace index recommendations). Each schema insight row offers the user the ability to execute the corresponding SQL query that realizes their schema insight via a clickable button. Filters are available to filter the surfaced schema insights by database and insight type, as well as search.  Release justification: low risk, high benefit changes to existing functionality [#86317][#86317]
- Adds insights overview page for statements to show if there are index recommendations, high retry count, and unknown for scenarios that don't fall into those categories. [#86688][#86688]
- Add page to view schedules in DB console.  Release justification: Low-risk - new, read-only page. [#86409][#86409]
- Added statement insight details page to DB Console [#86779][#86779]
- Adds Transaction and Statement fingerprint id to correlating SQL Activity overview pages. New columns are hidden by default. [#85464][#85464]
- Change column name from `User` to `User Name` on Table Details, Grant tab. [#86990][#86990]
- Update Sub-Optimal label to Suboptimal [#87068][#87068]

<h3 id="v22-2-0-alpha-2-bug-fixes">Bug fixes</h3>

- Fixed a bug where index/partition subzones may not have inherited the `global_reads` field correctly in some cases from their parent. [#69983][#69983]
- Previously, if the tracing (`sql.trace.txn.enable_threshold` cluster setting) was enabled on the cluster, the statement diagnostics collection (`EXPLAIN ANALYZE (DEBUG)`) wouldn't work. This is now fixed.  Release justification: low-risk fix to a long-standing bug. [#69975][#69975]
- Drop database cascade can fail while resolving a schema in a certain scenarios with the following error:  "ERROR: error resolving referenced table ID <ID>: descriptor is   being dropped" [#69789][#69789]
- Temporary tables were not properly cleaned up for tenants. [#69486][#69486]
- Backfills will now always respect the most up-to-date value of "changefeed.backfill.concurrent_scan_requests" even during an ongoing backfill. [#69933][#69933]
- Columns that were hidden by default where not being displayed when selected. This commits fixes the behaviour. [#70043][#70043]
- Fix all broken links to documentation [#70047][#70047]
- The GC queue now respects the `kv.queue.process.guaranteed_time_budget` cluster setting. [#69816][#69816]
- DNS unavailability during range 1 leaseholder loss will no longer cause significant latency increases for queries and other operations. [#70038][#70038]
- Default columns being displayed on Statements page on CC console when the user never made any selection [#70162][#70162]
- The debug merge-logs command no longer returns an error when the log decoder attempts to parse older logs. [#68282][#68282]
- Last Execution Timestamp is now properly updating. [#70281][#70281]
- The Postgres-compatible "Access Privilege Inquiry Functions" (e.g. has_foo_privilege) were incorrectly returning whether all comma-separated privileges were held, instead of whether any of the provided privileges were held. This incompatibility has been resolved.  Release justification: None [#69939][#69939]
- Fixes a bug in full cluster restores where dropped descriptor revisions would cause the restore to fail.  Release justification: Fixes a bug in full cluster restore where dropped descriptor revisions were causing restore jobs to fail. [#69655][#69655]
- Cockroach mt start-proxy now appropriately sets the .ServerName member of outgoing TLS connections. This allows the proxy to function appropriately when the --insecure and --skip-verify CLI flags are ommitted.  Release justification: Having a verified TLS connection betweeen the SQLProxy and SQL Pods in Cockroach Serverless is a requirement for the beta release. This code change enables that secure connection without making any changes to CockroachDB, itself. [#70323][#70323]
- Fix a bug preventing tuple type labels from being propagated across queries when run under DistSQL. [#70375][#70375]
- Queries involving arrays of tuples will no longer spuriously fail due to an encoding error. [#63996][#63996]
- Avoid dialing nodes in performance-critical code paths, which could cause substantial latency when encountering unresponsive nodes (e.g. when a VM or server is shut down). [#70017][#70017]
- Previously, `EXPLAIN (VEC)` on some queries could lead to a crash. The bug has been present only in 21.2 testing releases. [#70466][#70466]
- Fixes a problem where the TPC-C workload, when used in a multi-region setup, will not properly assign workers to the local partitions. [#70121][#70121]
- Fix styling issues in tooltip text on statement and transaction table columns [#70639][#70639]
- `cockroach sql -e` (and `demo -e`) can now process all client-side commands, not just `\echo`, `\set` and a few others. [#70671][#70671]
- `cockroach sql --set=auto_trace=on -e 'select ...'` (and the similar `demo` command) now produces an execution trace properly. [#70671][#70671]
- The exit status of the `cockroach` command did not follow the previously-documented table of exit status codes when an error occurred during the command start-up. (Only errors occuring after startup were reported using the correct code.) This defect has been fixed. This bug had existed ever since reference exit status codes had been introduced. [#70673][#70673]
- Statement/Transaction Page now is able to display and reset persisted SQL Stats. [#70586][#70586]
- The `cockroach debug unsafe-remove-dead-replicas` tool was improved to handle the existence of learners. It will now produce the desired results in more circumstances. The tool remains dangerous and can irrevocably corrupt a cluster. [#70251][#70251]
- Fixed internal error with joins that are both LATERAL and NATURAL/USING. [#70721][#70721]
- Bulk insert/update in implicit txn can retry indefinitely if the statement exceeds the default leasing deadline of 5 minutes. [#69936][#69936]
- CockroachDB is now less likely to OOM when queries reading a lot of data are issued with high concurrency (these queries are likely to hit the memory budget determined by `--max-sql-memory` startup parameter). [#70729][#70729]
- Fix Z and M coordinate columns causing a panic for geometry_columns and geography_columns. [#70788][#70788]
- Fix a bug where CockroachDB did not exit with the correct exit code when it ran out of disk space while the node was running. This behavior was new in 21.2 and was not behaving as intended. [#70799][#70799]
- Fix an incorrect bug hint for `sql.defaults.datestyle.enabled`. [#70842][#70842]
- The SQL server no longer panics under memory pressure when the query profiler is enabled. [#70994][#70994]
- The selected app name in the statements page is now derived from the route parameters. [#70999][#70999]
- When using the `json-fluent` and `json-fluent-compact` logging format, the `tag` field now uses the same normalization algorithm as used for output to files. That is, if the CockroachDB executable is renamed to contain periods (e.g. `cockroach.testbinary`), the periods are now eliminated instead of replaced by `_`. This is the behavior that was originally intended. This change does not affect deployments that use the standard executable name `cockroach`. [#70528][#70528]
- The `cockroach debug zip` command, as well as `cockroach debug list-files` and the advanced debug UI screen that enables log file access, are now able to gather log files stored across all configured logging directories. Prior to this patch, only log files from the directory associated with the DEV file sink were visible. This bug had existed ever since CockroachDB v19.x.  Note that the behavior remains incomplete if two or more file groups in the logging configuration use similar names that only differ in their use of periods (e.g. a file group named `one.two` and another one named `onetwo`). To avoid any issue related to this situation, use more clearly different file group names. [#70528][#70528]
- IMPORT now respects the spacial index storage options specified in PGDUMP files on indexes it creates.  Release justification: bug fix. IMPORT now respects the spacial index storage options specified in PGDUMP files on indexes it creates. [#66903][#66903]
- Correct how the `type` displays for ZM shapes geometry_columns to match PostGIS output. This previously incorrectly included the Z/M lettering. [#70856][#70856]
- Correct how `type` displays in geography_columns to better match PostGIS. This was previously in the wrong casing. [#70856][#70856]
- Statement details page in CC now filters statements by the provided aggregated_ts in the query param string. [#71069][#71069]
- Fixes IMPORT in tpcc workload. [#71013][#71013]
- A bug has been fixed that caused the optimizer to erroneously discard `WHERE` filters when executed prepared statements, causing incorrect results to be returned. This bug was present since version 21.1.9. [#71035][#71035]
- Fixes a bug which caused ALTER COLUMN TYPE statements to fail when they shouldn't have. [#71097][#71097]
- A bug has been fixed which caused internal errors when collecting statistics on tables with virtual computed columns. [#71105][#71105]
- Some query patterns that previously could cause a single node to become a hot spot have been fixed so that the load is evenly distributed across the whole cluster. [#70648][#70648]
- Previously, CockroachDB could encounter an internal error when executing a zigzag join in some cases (when there are multiple filters present and at least one filter refers to the column that is part of STORING clause of the secondary index that is used by the zigzag join), and this has been fixed. [#71226][#71226]
- Statement statsitics are now grouped by the statement's corresponding transaction fingerprints. [#70261][#70261]
- Fixed a panic that could occur with invalid GeoJSON input using ST_GeomFromGeoJSON/ST_GeogFromGeoJSON. [#71110][#71110]
- Fixes a bug where SHOW CREATE SCHEDULES was not redacting sensitive fields before displaying the `CREATE SCHEDULE` query. [#71339][#71339]
- Fix a bug where cluster backups were backing up opt-out system tables unexpectedely. [#71288][#71288]
- Fixes an incorrect "no data source matches prefix" error for queries that use a set-returning function on the right-hand side of a `JOIN` (unless `LATERAL` is explicitly specified). [#71396][#71396]
- Fixed a bug whereby setting the CACHE for a sequence to 1 was ignored. Before this change ALTER SEQUENCE ... CACHE 1 would succeed but would not modify the cache value. [#71439][#71439]
- A bug that could cause a CockroachDB node to deadlock upon startup in extremely rare cases has been fixed. If encountered, a stack trace generated by SIGQUIT would show the function `makeStartLine()` near the top. This bug had existed since v21.1. [#71406][#71406]
- Connect timeout for grpc connections is set to 20s to match pre 20.2 default value. [#71417][#71417]
- Fixed a bug from an earlier beta whereby a migration to create the system.statement_statistics table was not run. [#71492][#71492]
- Previously, using CREATE TABLE AS with a source query that referred to a sequence would not work. This is fixed now. [#71222][#71222]
- Schema changes running during node shutdown could sometimes fail permanently when they should not. [#71547][#71547]
- In prior betas of 21.2, some error codes returned when looking for a descriptor in a non-existent database were changed from UndefinedDatabase (3D000) to UndefinedObject (42704). The behavior has been reverted and more generally name resolution when the current database is undefined will return UndefinedDatabase. [#71440][#71440]
- Show All statements when filter All is selected and not only the ones with empty string [#71567][#71567]
- Previously, CockroachDB could incorrectly read the data of a unique secondary index that used to be a primary index that was created via ALTER PRIMARY KEY in 21.1.x or prior versions. [#71545][#71545]
- Fixes certificate bundle building logic [#71548][#71548]
- Transaction page no longer crashes when a statement is not found. [#71596][#71596]
- The `txnwaitqueue.pusher.waiting` metric no longer over- reports the number of pushing transactions in some cases. [#71360][#71360]
- CockroachDB could crash if network connectivity was impaired. The stack trace (in cockroach-stderr.log) would contain `server.(*statusServer).NodesUI` in that case. [#71749][#71749]
- The setval builtin previously did not invalidate cached sequence values. This is fixed now. [#71643][#71643]
- The 2-parameter setval builtin previously caused the sequence to increment incorrectly one extra time. This is fixed now. If you do need the sequence to increment, then use `setval(seq, val, true)`. [#71643][#71643]
- Previously, the effects of the setval and nextval builtin functions would be rolled back if the surrounding transaction was rolled back. This was not correct, as setval is not supposed to respect transaction boundaries. This is fixed now. [#71643][#71643]
- A bug has been fixed which caused incorrect results for some queries that utilized a zig-zag join. The bug could only reproduce on tables with at least two multi-column indexes with nullable columns. The bug was present since version 19.2.0. [#71758][#71758]
- In 21.2, jobs which fail to revert are retried unconditionally, but with exponential backoff. In the mixed version state there is no exponential backoff, so it'd be bad to retry unconditionally. The behavior has been changed such that before 21.2 is finalized, these jobs will enter the revert-failed state as in 21.1. [#71780][#71780]
- Fixed a bug which prevented rollback of ALTER PRIMARY KEY when the old primary key was interleaved. [#71780][#71780]
- Adding new values to a user-defined enum type will previously would cause a prepared statement using that type to not work. This now works as expected. [#71632][#71632]
- `IMPORT INTO` no longer crashes when encountering unresolved write intents. [#71676][#71676]
- Previously, some instances of a broken client connection could cause an infinite loop while processing commands from the client. This is fixed now. [#71940][#71940]
- Fixed a bug where certain schema changes (e.g. SET NULL) did not work if there was a expression-based index on the table. [#72015][#72015]
- Previously, atttypmod in pg_catalog.pg_attributes for DECIMAL types with precision but no width was incorrectly -1. This is now populated correctly. [#72016][#72016]
- Fixed a rare condition that could cause a range merge to get stuck waiting on itself. The symptom of this deadlock was a goroutine stuck in `handleMergeInProgressError` for tens of minutes. [#71950][#71950]
- A bug has been fixed that incorrectly populated the `indkey` column of `pg_catalog.pg_index` for expression indexes. This bug was present since the introduction of expression indexes in version 21.2.0. [#72055][#72055]
- Previously, specifying IntervalStyle or DateStyle on `options=-c...` in a pgurl would fail, even if the sql.defaults.datestyle.enabled and sql.defaults.intervalstyle.enabled cluster settings were set. This has now been resolved. [#72010][#72010]
- Previously, session variables passed in the connection string were case-sensitive. Now they are all correctly normalized to lower case. [#72010][#72010]
- Previously, when records and enums containing escape sequences were shown in the CLI, they would be incorrectly double-escaped. This is now fixed. [#71916][#71916]
- The `indexprs` column of `pg_catalog.pg_index` is now populated with string representations of every expression element in the index. If the index is not an expression index, `indexprs` is `NULL`. The `indexdef` column of `pg_catalog.pg_indexes` and the `indpred` column of `pg_catalog.pg_index` now correctly display user-defined types. [#72238][#72238]
- Support `"{}"` format for array column in COPY FROM STDIN WITH CSV [#71688][#71688]
- Fixes potential descriptor corruption bug for tables with a column with a DEFAULT expression referencing a SEQUENCE and with an ON UPDATE expression. [#72327][#72327]
- This change fixes two bugs in the logic that optimized the number of spans to backup. [#72293][#72293]
- Previously, when creating an object default privileges from users that were not the user creating the object would be added to the privileges of the object. This fix ensures only the relevant default privileges are applied. [#72323][#72323]
- Previously, CockroachDB could not set the `TableOID` and `TableAttributeNumber` attributes of `RowDescription` message of pgwire protocol in some cases (these values would be left as 0), and this is now fixed. [#72071][#72071]
- Fixed a bug causing tracing to external tracers to inadvertently stop after the Enqueue Range or the Allocator debug pages was used. [#72443][#72443]
- Previously, CockroachDB could encounter an internal error or crash when some queries involving tuples with ENUMs were executed in a distributed manner. This is now fixed. [#72406][#72406]
- Update browser tab when SQL Activity tab is changed. [#72516][#72516]
- SCHEMA CHANGE and SCHEMA CHANGE GC jobs following a DROP ... CASCADE now have sensible names, instead of '' and 'GC for ', respectively. [#70630][#70630]
- 'RESTORE ... FROM LATEST IN' now works to restore the latest backup from a collection without needing to first inspect the collection to supply its actual path. [#72409][#72409]
- Previously, introspection tables and error messages would not correctly display intervals according to the `intervalstyle` session variable. This is fixed now. [#72587][#72587]
- Fixed a race condition that could have caused core changefeeds whose targeted table became invalid to not explain why when shutting down. [#72490][#72490]
- Cockroach demo could be launched with --global and --multitenant=true options. [#72750][#72750]
- The query backing crdb_internal.cluster_contended_indexes improperly assumed that index ids were unique across the database. This change adds the proper scoping by table descriptor id, truing up the contents of that view. [#72780][#72780]
- Previously, index definitions in pg_catalog.pg_indexes would not format intervals according to the intervalstyle session variable. This is fixed now. [#72892][#72892]
- System tenant backups of individual tables and databases no longer include tenants as well. [#72871][#72871]
- Fix a bug where GENERATED ... IDENTITY would panic when using a non-int value during table creation. [#72966][#72966]
- Manually enqueueing ranges via the DB Console will no longer crash nodes that contain an uninitialized replica for the enqueued range. [#73023][#73023]
- Fixed a bug that could cause some semi lookup joins on REGIONAL BY ROW tables to return early before finding all data. This bug is currently only present on 21.2.0. This problem only manifested if there was an ON condition on top of the equality condition used for the lookup join, and the lookup columns did not form a key in the index being looked up into. The primary impact of this issue for most users relates to uniqueness checks on mutations of REGIONAL BY ROW tables, since uniqueness checks are implemented with a semi lookup join with an ON condition. The result of this bug was that uniqueness checks were not comprehensive, and could miss an existing duplicate key on a remote node. This could cause data to be erroneously inserted with a duplicate key when it should have failed the uniqueness check. These problems have now been fixed. [#73040][#73040]
- The timeout when checking for Raft application of upgrade migrations has been increased from 5 seconds to 1 minute, and is now controllable via the cluster setting `kv.migration.migrate_application.timeout`. This makes migrations much less likely to fail in clusters with ongoing rebalancing activity during upgrade migrations. [#72987][#72987]
- Y-axis labels on custom charts no longer display 'undefined'. [#73055][#73055]
- Fixed an internal error that could occur during planning for some set operations (e.g., UNION, INTERSECT or EXCEPT) when at least one side of the set operation was ordered on a column that was not output by the set operation. This bug was first introduced in 21.2.0 and does not exist in prior versions. [#73125][#73125]
- Fixed a crash with message "attempting to propose command writing below closed timestamp" that could occur, typically on overloaded systems experiencing non-cooperative lease transfers. [#73114][#73114]
- Fix bug in database and schema restore cleanup that results in a dangling descriptor entry on job failure. [#73139][#73139]
- Transaction page now using the correct selector for sort setting and filters. [#73286][#73286]
- Raft snapshots now detect timeouts earlier and avoid spamming the logs with `context deadline exceeded` errors. [#73279][#73279]
- Error messages produced during import are now truncated. Previously, import could potentially generate large error messages that could not be persisted to the jobs table, resulting in a failed import never entering the failed state and instead retrying repeatedly. [#73303][#73303]
- Fixed a rare internal error "estimated row count must be non-zero", which could occur when planning queries using an inverted index. This error could occur if the histogram on the inverted index showed that there were no rows. [#73340][#73340]
- Servers no longer crash due to panics in HTTP handlers. [#72395][#72395]
- Previously, CockroachDB could crash when reading of a secondary index with STORING clause in reverse direction (because of ORDER BY col DESC). The bug was introduced in 21.2. [#73272][#73272]
- Crdb_internal.table_indexes now shows if an index is sharded or not. [#73380][#73380]
- Create indexes with special characters would fail to identify indexes with the same matching name, which caused an internal error. [#73367][#73367]
- Prohibit mixed dimension linestrings in ST_MakePolygon. [#73489][#73489]
- Index create statements in pg_indexes table now shows hash sharding bucket count if an index is hash sharded. Column direction is removed from gin index in pg_indexes. [#73491][#73491]
- Internal columns created by the system to support expression indexes are now omitted from the output of `SHOW COLUMNS` statements and the `information_schema.columns` table. [#73447][#73447]
- A failed IMPORT INTO to a non-empty would previously be unable to clean up the partially imported data when run in a serverless cluster because the operation to do so was incorrectly denied for tenants. [#73532][#73532]
- Prevent a panic in the parser when trying to parse the .@n tuple field deference syntax in the (invalid) n=0 case. [#73461][#73461]
- Fix certain bugs where CREATE TABLE AS or CREATE MATERIALIZED VIEW may panic if the SELECT query is an internal table requiring internal database state. [#73577][#73577]
- Fixed an internal error, "empty Datums being compared to other", that could occur during planning for some SELECT queries over tables that included a DEFAULT partition value in a PARTITION BY LIST clause. This bug was present since 21.1.0 and has now been fixed. The bug does not exist on versions 20.2.x and earlier. [#73630][#73630]
- Use correct index count on the indexes column on the Database Details page [#73703][#73703]
- Changefeeds will emit null values for virtual computed columns. Previously, they would crash if these were set to NOT NULL. [#73702][#73702]
- Uninitialized replicas that are abandoned after an unsuccessful snapshot no longer perform periodic background work, so they no longer have a non-negligible cost. [#73362][#73362]
- The bug with the ungraceful shutdown of the distributed queries in some rare cases has been fixed. "Ungraceful" here means because of the `statement_timeout` (most likely) or because a node crashed. [#73887][#73887]
- A bug has been fixed that caused incorrect evaluation of placeholder values in EXECUTE statements. The bug presented when the PREPARE statement cast a placeholder value, for example `PREPARE s AS SELECT $1::INT2`. If the assigned value for `$1` exceeded the maximum width value of the cast target type, the result value of the cast could be incorrect. This bug has been present since version 19.1 or earlier. [#73762][#73762]
- Previously during restore we wouldn't insert a system.namespace entry for synthetic public schemas. [#73875][#73875]
- It was previously possible for `cockroach debug zip` and the log file viewer in the web UI to observe incomplete log entries at the end of log files—especially the log file currently being written to by the CockroachDB process. This bug had existed from a very early version of CockroachDB. This bug has now been fixed. [#71055][#71055]
- A bug has been fixed that caused internal errors when altering the primary key of a table. The bug was only present if the table had a partial index with a predicate that referenced a virtual computed column. This bug was present since virtual computed columns were added in version 21.1.0. [#74102][#74102]
- Foreign key referencing hash sharded key won't fail anymore. [#74140][#74140]
- Previously, CockroachDB could return a spurious "context canceled" error for a query that actually succeeded in extremely rare cases, and this has now been fixed. [#74163][#74163]
- Raft snapshots no longer risk starvation under very high concurrency. Before this fix, it was possible that a thundering herd of Raft snapshots could be starved and prevented from succeeding due to timeouts, which were accompanied by errors like `error rate limiting bulk io write: context deadline exceeded`. [#73288][#73288]
- A bug has been fixed which allowed queries to reference internal columns created by the system for expression indexes. These columns, which had names prefixed with "crdb_internal_idx_expr", can no longer be referenced in queries. This bug was present since version 21.2 when expression indexes were released. [#74245][#74245]
- Portals in the extended protocol of the Postgres wire protocol can now be used from implicit transactions and can be executed multiple times if there is a row-count limit applied to the portal. Previously, trying to execute the same portal twice would result in an "unknown portal" error. [#74242][#74242]
- Previously, CockroachDB could encounter an internal error when executing queries with multiple window functions and when one of those functions returned INT2 or INT4 type. [#74288][#74288]
- A bug has been fixed that incorrectly allowed creating computed column expressions, expression indexes, and partial index predicate expressions with mutable casts between string types and the types REGCLASS, REGNAMESPACE, REGPROC, REGPROCEDURE, REGROLE, and REGTYPE. Creating such computed columns, expression indexes, and partial indexes is now prohibited. Any tables with these types of expressions may be corrupt and should be dropped and recreated. [#74286][#74286]
- A bug was fixed that, in very rare cases, could result in a node terminating with fatal error "unable to remove placeholder: corrupted replicasByKey map". To avoid potential data corruption, users affected by this crash should not restart the node, but instead decommission it in absentia and have it rejoin the cluster under a new NodeID. [#73734][#73734]
- When foreign keys were included inside an add column statement and multiple columns were added in a single statement then the first added column would have the foreign key applied (or an error generated based on the wrong column). [#74411][#74411]
- A bug has been fixed which caused corruption of partial indexes, which could cause incorrect query results. The bug was only present when two or more partial indexes in the same table had identical `WHERE` clauses. This bug has been present since version 21.1.0. [#74431][#74431]
- A doubly nested enum in a distsql query would not get hydrated on remote nodes resulting in panic. [#74189][#74189]
- Fixed a panic when attempting to access the hottest ranges (e.g. via the `/_status/hotranges` endpoint) before initial statistics had been gathered. [#74507][#74507]
- Setting sslmode=require would check for local certificates, so omitting a certs path would cause an error even though "require" does not verify server certificates. This has been fixed by bypassing certificate path checking for sslmode=require. This bug has been present since 21.2.0. [#73776][#73776]
- Previously, CockroachDB could return incorrect results or internal errors on queries with window functions returning INT, FLOAT, BYTES, STRING, UUID, or JSON type when the disk spilling occurred. The bug was introduced in 21.2.0 and is now fixed. [#74491][#74491]
- CockroachDB could previously incorrectly calculate MIN/MAX when used as window functions in some cases after spilling to disk. The bug was introduced in 21.2.0 and is now fixed. [#74491][#74491]
- IMPORT TABLE ... PGDUMP with a COPY FROM statement in the dump file that has less target columns than the CREATE TABLE schema definition would result in a nil pointer exception. [#74601][#74601]
- Fix panic's possible in some distributed queries using enum's in join predicates. [#74659][#74659]
- A bug that could previously cause redundant lease transfers has now been fixed. [#74726][#74726]
- Fixed a bug where deleting data via schema changes (e.g. when dropping an index or table) could fail with a "command too large" error. [#74674][#74674]
- Previously, CockroachDB could encounter an internal error when performing UPSERT or INSERT ... ON CONFLICT queries in some cases when the new rows contained NULL values (either NULLS explicitly specified or NULLs used since some columns were omitted). [#74825][#74825]
- Previously, the scale of a `DECIMAL` column was not enforced when values given in scientific notation (e.g., `6e3`) where inserted into the column. This bug has been fixed. [#74869][#74869]
- Certain malformed backup schedule expressions no longer cause the node to crash. [#74881][#74881]
- Fix a case where a RESTORE job could hang if it encountered an error when ingesting restored data. [#74905][#74905]
- A bug has been fixed which caused errors in rare cases when trying to divide `INTERVAL` values by `INT4` or `INT2` values. [#74882][#74882]
- Fixed a bug that could occur when a TIMETZ column was indexed, and a query predicate constrained that column using a < or > operator with a timetz constant. If the column contained values with time zones that did not match the time zone of the timetz constant, it was possible that not all matching values could be returned by the query. Specifically, the results may not have included values within one microsecond of the predicate's absolute time. This bug was introduced when the timetz datatype was first added in 20.1. It exists on all versions of 20.1, 20.2, 21.1, and 21.2 prior to this patch. [#74914][#74914]
- Fixed an internal error, "estimated row count must be non-zero", that could occur during planning for queries over a table with a TimeTZ column. This error was due to a faulty assumption in the statistics estimation code about ordering of TimeTZ values, which has now been fixed. The error could occur when TimeTZ values used in the query had a different time zone offset than the TimeTZ values stored in the table. [#74914][#74914]
- The --user argument is no longer ignored when using `cockroach sql` in --insecure mode. [#75194][#75194]
- Previously, CockroachDB could incorrectly report `KV bytes read` statistic in `EXPLAIN ANALYZE` output. The bug is present only in 21.2.x versions. [#75175][#75175]
- A bug has been fixed that caused internal errors in queries with set operations, like UNION, when corresponding columns on either side of the set operation were not the same. This error only occurred with a limited set of types. This bug is present in versions 20.2.6+, 21.1.0+, and 21.2.0+. [#75219][#75219]
- CREATE INDEX statements using expressions previously failed in some cases if they encountered an internal retry. [#75056][#75056]
- When creating hash sharded index to an existing table, traffic could hit hard on the single range of the index before it is split into more ranges for shards as range size grows. This change make schema changer able to presplit ranges on shard boundaries before the index becomes writable. `sql.hash_sharded_range_pre_split.max` is the cluster setting added so that users can set the upbound of the amount of ranges to have. If the bucket count of the defined index is less than the cluster setting, the bucket count will be the amount of pre-split ranges. [#74923][#74923]
- Update the String() function of roleOption to add a space on the role `VALID UNTIL`. [#75271][#75271]
- Fix SQL Activity pages crashing when a column was sorted by the 3rd time. [#75473][#75473]
- If multiple columns were added to a table inside a transaction, then none of the columns will be backfilled if the last column did not require a backfill. [#75076][#75076]
- In particular cases, some queries that involve a scan which returns many results and which includes lookups for individual keys were not returning all results from the table. [#75475][#75475]
- Dropping and creating a primary index constraint with the same name in a transaction would incorrectly fail. [#75155][#75155]
- `crdb_internal.deserialize_session` now checks the session_user has the privilege to SET ROLE to the current_user before changing the session settings. [#75575][#75575]
- Dedicated clusters can now restore tables and databases from backups made by tenants. [#73647][#73647]
- A bug that caused high SQL tail latencies during background rebalancing in the cluster has been fixed. [#73697][#73697]
- A sequence is created when a column is defined as `SERIAL` type and the `serial_normalization` session variable is set to `sql_sequence`. In this case, the sequence is owned by the column and the table where the column exists. The sequence should be dropped when the owner table/column is dropped, which is the postgres behavior. However, cockroach never set ownership information correctly but only dependecy relationship. So the sequence stays even the owner table/column does not exist anymore. This fix assigns correct ownership information to sequence descriptor and column descriptor so that cockroach can align with postgres behavior. [#74840][#74840]
- The "options" query parameter is no longer removed when using the `\c` command in the cockroach SQL shell to reconnect to the cluster. [#75673][#75673]
- `cockroach node decommission` no longer causes query failure due to the decommissioning node not closing open SQL connections and still being marked as ready. The decommissioning process now includes a draining step that fixes this. In other words, a decommission now automatically drains a node. This also means that running a drain after a decommission is no longer necessary. It is optional, but recommended, that `cockroach node drain` is used before `cockroach node decommission` to avoid the possibility of a disturbance in query performance. [#74319][#74319]
- The CancelSession endpoint now correctly propagates gateway metadata when forwarding requests. [#75814][#75814]
- Fixed a bug which could cause nodes to crash when truncating abnormally large Raft logs. [#75793][#75793]
- A bug has been fixed that caused incorrect values to be written to computed columns when their expressions were of the form `j->x = y`, where `j` is a `JSON` column and `x` and `y` are constants. This bug also caused corruption of partial indexes with `WHERE` clauses containing expressions of the same form. This bug was present since version 2.0.0. [#75914][#75914]
- Changefeeds retry instead of fail on RPC send failure [#75517][#75517]
- Fixed a rare race condition that could lead to client-visible errors that looked like "found ABORTED record for implicitly committed transaction". These errors were harmless in that they did not indicate data corruption, but they could be disruptive to clients. [#75601][#75601]
- Swapping primary keys could lead to scenarios where foreign key references could lose their uniqueness. [#75820][#75820]
- CASE expressions with branches that result in types that cannot be cast to a common type now result in a user-facing error instead of an internal error. [#76193][#76193]
- A bug has been fixed that caused internal errors when querying tables with virtual columns in the primary key. This bug was only present since version 22.1.0-alpha.1 and does not appear in any production releases. [#75898][#75898]
- The DB console Databases page now shows stable, consistent values for database sizes. [#76315][#76315]
- Comments are not cleaned up when the table primary keys are swapped, which can cause SHOW TABLE to fail. [#76277][#76277]
- Some of the `cockroach node` subcommands did not handle `--timeout` properly. This is now fixed. [#76427][#76427]
- There is now a 20 minute timeout when sending Raft snapshots, to avoid stalled snapshot transfers preventing Raft log truncation, which can cause the Raft log to grow very large. [#76346][#76346]
- A bug has been fixed which caused the query optimizer to omit join filters in rare cases when reordering joins, which could result in incorrect query results. This bug was present since v20.2. [#76334][#76334]
- The list of recently decommissioned nodes and the historical list of decommissioned nodes correctly display decommissioned nodes.  fix tests  fix pb import and add default arg value [#76538][#76538]
- Previously, CockroachDB could incorrectly not return a row from a table with multiple column families when that row contains a NULL value when a composite type (FLOAT, DECIMAL, COLLATED STRING, or an arrays of such a type) is included in the PRIMARY KEY. For the bug to occur composite column from the PRIMARY KEY must be included in any column family other than the first one. [#76563][#76563]
- There is now a 1 hour timeout when sending Raft snapshots, to avoid stalled snapshot transfers preventing Raft log truncation and growing the Raft log very large. This is configurable via the `COCKROACH_RAFT_SEND_SNAPSHOT_TIMEOUT` environment variable. [#76589][#76589]
- Fixed an error that could sometimes happen when sorting the output of the SHOW CREATE ALL TABLES command. [#76639][#76639]
- Backup incorrectly backed up database, schema, and type descriptors that were in a DROP state at the time the backup was run. This bug resulted in the user being unable to backup and restore if their cluster had dropped and public descriptors with colliding names. [#76635][#76635]
- Fixed a race condition that in rare circumstances could cause a node to panic with `unexpected Stopped processor` during shutdown. [#76825][#76825]
- Fixed a bug where the different stages of preparing, binding, and executing a prepared statement would use different implicit transactions. Now these stages all share the same implicit transaction. [#76792][#76792]
- Attempting to run concurrent profiles works up to a concurrency limit of two. This will remove the occurrence of "profile id not found" errors while running upto two profiles concurrently. When a profile is not found, the error message has been updated to suggest remediation steps in order to unblock the user. [#76266][#76266]
- The content type header for the HTTP log sink is set to application/json if the format of the log output is JSON. [#77014][#77014]
- A bug has been fixed that could corrupt indexes containing virtual columns or expressions. The bug only occured when the index's table had a foreign key reference to another table with an `ON DELETE CASCADE` action, and a row was deleted in the referenced table. This bug was present since virtual columns were added in version 21.1.0. [#77052][#77052]
- The database no longer crashes when running a SQL PREPARE via the Postgres extended protocol. [#77063][#77063]
- Running SQL-level EXECUTE via the extended protocol previously had inconsistent behavior and could in some cases crash the server. [#77063][#77063]
- Previously, a bug in CRDB caused the Open Transaction chart in Metrics Page to constantly increase for empty transactions. This issue has now been fixed. [#77237][#77237]
- Previously, draining nodes in a cluster without shutting them down could stall foreground traffic in the cluster. This patch fixes this bug. [#77246][#77246]
- The information_schema tables administrable_role_authorizations and applicable_roles were incorrectly always returning the current user for the grantee column. Now, the column will contain the correct role that was granted the parent role given in the role_name column. [#77359][#77359]
- A bug has been fixed that caused errors when attempting to create table statistics (with CREATE STATISTICS or ANALYZE) for a table containing an index which indexed only virtual computed columns. This bug has been present since version 21.1.0. [#77507][#77507]
- Hide automatic jobs from the UI. [#77331][#77331]
- Added a limit of 7 concurrent asynchronous consistency checks per store, with an upper timeout of 1 hour. This prevents abandoned consistency checks from building up in some circumstances, which could lead to increasing disk usage as they held onto Pebble snapshots. [#77433][#77433]
- A bug causing incorrect counts of under_replicated_ranges and over_replicated_ranges in the crdb_internal.replication_stats table for multi-region databases has been fixed. [#76430][#76430]
- Intermittent validation failures could be observed on schema objects, where a job ID was detected as missing when validating objects in a transaction. [#76532][#76532]
- Fixed a bug when adding a hash-sharded index to a table watched by a changefeed. [#77316][#77316]
- A bug has been fixed that caused internal errors when COALESCE and IF expressions had inner expressions with different types that could not be cast to a common type. [#77608][#77608]
- A zone config change event now includes the correct details of what was changed instead of incorrectly displaying undefined [#77773][#77773]
- Fix successive schema change backfills from skipping spans that were checkpointed by an initial backfill that was restarted [#77797][#77797]
- Previously statements that arrived in a batch during the simple query protocol would all execute in their own implicit transactions. Now, we match the Postgres wire protocol, so all these statements share the same implicit transaction. If a BEGIN is included in a statement batch, then the existing implicit transaction is upgraded to an explicit transaction. [#76834][#76834]
- Fix an optimizer bug that prevented expressions of the form (NULL::STRING[] <@ ARRAY['x']) from being folded to NULL. [#77995][#77995]
- Fixes the implementation of function `substr()` in the vectorized execution engine for UTF-8 encodings. [#77308][#77308]
- Fix broken links to Statement Details page on Advanced Debug and Sessions page. [#78050][#78050]
- The LATEST file that points to the latest full backup in a collection was written to a directory path with the wrong structure. [#78243][#78243]
- CockroachDB might now fetch less rows when performing lookup and index joins on the queries with LIMIT clause. [#78224][#78224]
- A bug has been fixed that caused errors when trying to evaluate queries with NULL values annotated as a tuple type, such as `NULL:::RECORD`. This bug was present since version 19.1. [#78287][#78287]
- Previously, CockroachDB could lose INT2VECTOR and OIDVECTOR type of some arrays, and this is now fixed. [#78520][#78520]
- Fixed a bug whereby certain catalog interactions which occurred concurrently with node failures were not internally retried. [#78529][#78529]
- Fixed a bug in the captured index usage stats test. [#78649][#78649]
- Index usage stats are now properly captured for index joins. [#78333][#78333]
- Fixes a nil pointer exception during the cleanup of a failed or cancelled restore job. [#78940][#78940]
- A bug has been fixed which caused the optimizer to generate invalid query plans which could result in incorrect query results. The bug, which has been present since version 21.1.0, can appear if all of the following conditions are true: 1) the query contains a semi-join, such as queries in the form: `SELECT * FROM t1 WHERE EXISTS (SELECT * FROM t2 WHERE t1.a = t2.a);`, 2) the inner table has an index containing the equality column, like `t2.a` in the example query, 3) the index contains one or more columns that prefix the equality column, and 4) the prefix columns are `NOT NULL` and are constrained to a set of constant values via a `CHECK` constraint or an `IN` condition in the filter. [#78685][#78685]
- Fix num_runs being incremented twice for certain jobs upon being started [#77240][#77240]
- Fixed a bug whereby the cluster version could regress due to a race condition. [#78705][#78705]
- Previously, whenever a distributed query resulted in an error on the remote node, then the trace would be incomplete. This is now fixed. [#79084][#79084]
- `ALTER TABLE [ADD|DROP] COLUMN` are now subject to admission control, which will prevent these operations from overloading the storage engine. [#79115][#79115]
- Fixed a bug where `SHOW SCHEMAS FROM <schema>` would not include user-defined schemas. [#79301][#79301]
- Previously IMPORT INTO could create duplicate entries UNIQUE constraints in REGIONAL BY ROW tables and tables utilizing UNIQUE WITHOUT INDEX constraints. A new post-IMPORT validation step for those tables now fails and rolls back the IMPORT in such cases. [#79293][#79293]
- Fixed a bug in IO admission control which could result in admission control failing to rate-limit when traffic was stalled such that no work was admitted, despite the store's being in an unhealthy state. [#79302][#79302]
- Previously, CockroachDB could run into "memory budget exceeded" errors when performing lookup joins. This is now fixed in some cases. [#79250][#79250]
- Doing a lookup join on pg_type.oid no longer results in an error. Example: SELECT pg_type.oid FROM (SELECT null::OID AS b) AS a INNER LOOKUP JOIN pg_type ON pg_type.oid=a.b [#78960][#78960]
- Previously, the execution time as reported on DISTSQL diagrams within the statement bundle collected via EXPLAIN ANALYZE (DEBUG) could become negative when the statement encountered an error. This is now fixed. [#79252][#79252]
- Nextval/setval are non-transactional except when it is called in the same transaction that the sequence was created in. This change prevents a bug where creating a sequence and calling nextval/setval on it within a transaction caused the query containing nextval to hang. [#77949][#77949]
- LIMIT queries with an ORDER BY clause which scan the index of a virtual system tables, such as `pg_type`, could previously return incorrect results. This is corrected by teaching the optimizer that LIMIT operations cannot be pushed into ordered scans of virtual indexes. [#79313][#79313]
- A bug has been fixed that caused the optimizer to generate query plans with logically incorrect lookup joins. The bug can only occur in queries with an inner join, e.g., `t1 JOIN t2`, if all of the following are true:   1. The join contains an equality condition between columns of both      tables, e.g., `t1.a = t2.a`.   2. A query filter or `CHECK` constraint constrains a column to a set      of specific values, e.g., `t2.b IN (1, 2, 3)`. In the case of a      `CHECK` constraint, the column must be `NOT NULL`.   3. A query filter or `CHECK` constraint constrains a column to a      range, e.g., `t2.c > 0`. In the case of a `CHECK` constraint, the      column must be `NOT NULL`.   4. An index contains a column from each of the criteria above, e.g.,      `INDEX t2(a, b, c)`. This bug has been present since version 21.2.0. [#79389][#79389]
- A bug has been fixed which caused the optimizer to generate invalid query plans which could result in incorrect query results. The bug, which has been present since version 21.1.0, can appear if all of the following conditions are true:   1. The query contains a semi-join, such as queries in the form      `SELECT * FROM a WHERE EXISTS (SELECT * FROM b WHERE a.a @> b.b)`.   2. The inner table has a multi-column inverted index containing the      inverted column in the filter.   3. The index prefix columns are constrained to a set of values via the      filter or a `CHECK` constraint, e.g., with an `IN` operator. In the      case of a `CHECK` constraint, the column is `NOT NULL`. [#79389][#79389]
- A bug has been fixed that caused an internal error when the inner expression of a column access expression evaluated to `NULL`. For example, evaluation of the expression `(CASE WHEN b THEN ((ROW(1) AS a)) ELSE NULL END).a` would error when `b` is `false`. This bug has been present since version 19.1 or earlier. [#78423][#78423]
- A bug has been fixed that caused an error when accessing a named column of a labelled tuple. The bug only occurred when an expression could produce one of several different tuples. For example, `(CASE WHEN true THEN (ROW(1) AS a) ELSE (ROW(2) AS a) END).a` would fail to evaluate. This bug was present since version 22.1.0. Although present in previous versions, it was impossible to encounter due to limitations that prevented using tuples in this way. [#78423][#78423]
- Queries reading from an index or primary key on FLOAT or REAL columns DESC would read -0 for every +0 value stored in the index. Fix this to correctly read +0 for +0 and -0 for -0. [#79473][#79473]
- Privileges for restored table's were being generated incorrectly without taking into consideration their parent schema's default privilege descriptor. [#79085][#79085]
- Separate tenants now use unique values for the internal field ClusterID. Previously separate tenants that were hosted on the same storage cluster would be assigned the same ClusterID. [#74005][#74005]
- Fixes a bug where draining / drained nodes could re-acquire leases during an import or an index backfill. [#79295][#79295]
- Fix some cases where a job or schema change that had encountered an error would continue to execute for some time before eventually failing. [#79652][#79652]
- The setval function has an optional is_called parameter that was previously defaulting to false when not specified. It now defaults to true to match Postgres behavior. [#79761][#79761]
- Update props on the raft messages page to include functions to set the time window and time scale in order to fix date picker and drag-to-zoom functionality. [#79772][#79772]
- Contention statistics are now being collected for SQL Stats when tracing is enabled. [#79175][#79175]
- HTTP 304 responses no longer result in error logs. [#79811][#79811]
- Previously, CockroachDB could encounter an internal error when evaluating queries with OFFSET and LIMIT clauses when the addition of the `offset` and the `limit` value would be larger than `int64` range. [#79865][#79865]
- Previously, a custom time series metric `sql.distsql.queries.spilled` was computed incorrectly leading to exaggerated number, and this has now been fixed. [#79818][#79818]
- Fixed a bug that may have caused a panic if a Kafka server being written to by a changefeed failed at the wrong moment. [#79897][#79897]
- Added a detailed error message for index out of bounds when decoding a binary tuple datum. This does not fix the root cause, but should give more insight into what is happening. [#78637][#78637]
- In 22.1 beta, if the changefeed is created with a cursor time stamp prior to when the public schema migration happened, it would fail to resolve the public schema. This change allows us to resolve the schema. [#80132][#80132]
- Address issue where automatic encryption-at-rest data key rotation would get disabled after a node restart without a store key rotation. [#80114][#80114]
- Fixed a bug where NaN coordinates when using ST_Intersects/ST_Within/ST_Covers would return true instead of false for point in polygon operations. [#80136][#80136]
- Prior to this fix, queries with many joins and projections of multicolumn expressions, e.g. col1 + col2, either present in the query or within a virtual column definition, could experience very long optimization times or hangs, where the query is never sent for execution. [#80212][#80212]
- The formatting/printing behavior for ALTER DEFAULT PRIVILEGES was fixed, which will correct some mistaken error messages. [#80307][#80307]
- Fix a bug where ST_MinimumBoundingCircle would panic with infinite coordinates and a num_segments argument. [#80207][#80207]
- Errors encountered when sending rebalancing hints to the storage layer during IMPORTs and index creation are now only logged and no longer cause the job to fail. [#80300][#80300]
- This patch fixes queries which involve an ORDER BY clause, a DISTINCT ON clause and a GROUP BY clause, which may sometimes error out depending on the columns referenced in those clauses. [#80447][#80447]
- Fixes a rare crash which can occur when restarting a node after dropping tables. [#80551][#80551]
- Updated the type reported in the wire protocol for STRING(n) types to match VARCHAR(n). [#80414][#80414]
- Fixed a bug that allowed duplicate constraint names for the same table if the constraints were on hidden columns. [#80154][#80154]
- Creating a table with a locality of regional by row could intermittently fail with a missing type error. [#80590][#80590]
- Fixes a rare crash which can occur when restarting a node after dropping tables. [#78961][#78961]
- Previously, in very rare circumstances CockroachDB could incorrectly evaluate queries with ORDER BY clause when the prefix of ordering was already provided by the index ordering of the scanned table. [#80679][#80679]
- Fix the bug which was causing the unavailable ranges rule details to be flipped with the tripped circuit breakers. [#80274][#80274]
- Fixed a goroutine leak when internal rangefeed clients received certain kinds of retriable errors. [#80705][#80705]
- This PR fixes a bug where if a transaction's commit time is pushed forward from its initial provisional time, a enclosing `CREATE MATERIALIZED VIEW AS ...` might fail to find other descriptors created in the same transaction during the view's backfill stage. The detailed descriptor of this bug is summarized in issue #79015 [#80651][#80651]
- Index recommendations are no longer presented for system tables in the output of `EXPLAIN` statements. [#80923][#80923]
- `SHOW EXPERIMENTAL_FINGERPRINTS FROM TABLE` now works on tables with partial indexes. [#80539][#80539]
- Fixed a rare race condition that could allow for a transaction to serve a stale read and violate real-time ordering under moderate clock skew.  [^1]: see [pkg/kv/kvserver/observedts/doc.go](https://github.com/cockroachdb/cockroach/blob/master/pkg/kv/kvserver/observedts/doc.go) for an explanation of the role of observed timestamps in the transaction model. This commit updates that documentation to include this fix.  [^2]: see analysis in https://github.com/cockroachdb/cockroach/issues/36431#issuecomment-714221846. [#80706][#80706]
- The hex encoding for BYTEA values now works properly when used in `COPY FROM ... CSV` statements. [#81120][#81120]
- Fix a bug in row-level TTL where the last range key of a table may overlap with a separate table or index, resulting in a "error decoding X bytes" error message when performing row-level TTL. [#81207][#81207]
- Fixed a bug where format_type on the void type results in an error. [#81304][#81304]
- Fixed a bug in which some prepared statements could result in incorrect results when executed. This could occur when the prepared statement included an equality comparison between an index column and a placeholder, and the placholder was cast to a type that was different from the column type. For example, if column a was of type DECIMAL, the following prepared query could produce incorrect results when executed: SELECT * FROM t_dec WHERE a = $1::INT8; [#81331][#81331]
- Previously, when adding a column to a pre-existing table and adding a partial index referencing that column in the transaction, DML operations against the table while the schema change was ongoing would fail. Now these hazardous schema changes are not allowed. [#79691][#79691]
- Fix a bug where ST_MinimumBoundingCircle with NaN coordinates could panic. [#81406][#81406]
- Disk write probes during node liveness heartbeats will no longer get stuck on stalled disks, instead returning an error once the operation times out. Additionally, disk probes now run in parallel on nodes with multiple stores. [#81133][#81133]
- Fixed a bug where changefeeds could fail permanently if encountering an error while planning their distribution, even though such errors are usually transient. [#81480][#81480]
- Fixes issue where the 'Encryption status' field on the store details debug page on the DB console would display an error instead of displaying encryption details when encryption-at-rest is enabled. [#81373][#81373]
- Fixed a panic that was caused by setting the "tracing" session variable using SET LOCAL or ALTER ROLE ... SET. [#81420][#81420]
- In 21.1 a bug was introduced whereby default values were recomputed when populating data in new secondary indexes for columns which were added in the same transaction as the index. This arises, for example in cases like `ALTER TABLE t ADD COLUMN f FLOAT8 UNIQUE DEFAULT (random())`. If the default expression is not volatile, then the recomputation is harmless. If, however, the default expression is volatile, the data in the secondary index will not match the data in the primary index: a corrupt index will have been created. This bug has now been fixed. [#81486][#81486]
- Fixed a bug where GRANT ALL TABLES IN SCHEMA would not resolve the correct database name if it was explicitly specified. [#81382][#81382]
- Constants in sql query fields are correctly removed for VIEWACTIVITYREDACTED users [#80707][#80707]
- Fix a gap in disk-stall detection. Previously, disk stalls during filesystem metadata operations could go undetected, inducing deadlocks.  Now stalls during these types of operations will correctly fatal the process. [#81389][#81389]
- A bug has been fixed that caused errors with the message "unable to vectorize execution plan: unhandled expression type" in rare cases. This bug has been present since version 21.2.0. [#81104][#81104]
- Previously, cancelling COPY commands would have an XXUUU error, instead of 57014. This is now rectified. [#81564][#81564]
- Fixed a bug that caused duplicated schema change job description messages. [#81268][#81268]
- Fix false negatives produced by the JSON `?` operator when invoked on a JSON array with the vectorized engine set explicitly to off. [#81648][#81648]
- Previously when one did ALTER DEFAULT PRIVILEGES IN SCHEMA <virtual schema> a panic occured.  Now this returns the error message <virtual schema> is not a physical schema. [#81597][#81597]
- Previously CockroachDB would encounter an internal error when executing queries with lead or lag window functions when the default argument had a different type than the first argument. [#81681][#81681]
- Fixed a bug where sequences could return values that are out-of-bounds in some cases. [#81123][#81123]
- Fixed a bug where an unresponsive node (e.g. with a stalled disk) could prevent other nodes from acquiring its leases, effectively stalling these ranges until the node was shut down or recovered. [#81136][#81136]
- Prior to this change, virtual computed columns which were marked as NOT NULL could be added to new secondary index. After this change, attempts to add such columns to a secondary index will result in an error. Note that such invalid columns can still be added to tables. Work to resolve that bug is tracked in #81675. [#81679][#81679]
- An error message that referred to a non-existent cluster setting no refers to the correct cluster setting: bulkio.backup.deprecated_full_backup_with_subdir.enabled. [#81811][#81811]
- Fixed an issue where a left lookup join could have incorrect results. In particular, some output rows could have non-NULL values for right-side columns when the right-side columns should have been NULL. This issue only exists in 22.1.0 and prior development releases of 22.1. [#82054][#82054]
- Statement and Transaction pages no longer crash when search term includes '*'. [#81988][#81988]
- The output of SHOW CREATE VIEW now properly includes the keyword MATERIALIZED for materialized views. [#82026][#82026]
- Fixed the formatting of floats in arrays and tuples sent over the client-server pgwire protocol so that they respect the extra_float_digits parameter, and correctly  format infinity values. [#82022][#82022]
- Properly handle special characters to not being highlighted. [#82081][#82081]
- Before this change, not validation was performed when adding a virtual computed column which was marked `NOT NULL`. This meant that it was possible to have a virtual computed column with an active `NOT NULL` constraint despite having rows in the table for which the column was `NULL`. This has now been fixed. [#81693][#81693]
- Fixed the identity_generation column in the information_schema.columns table so its value is either `BY DEFAULT` or `ALWAYS` (or null). [#82094][#82094]
- Fix a bug where `\copy` in CLI would panic. [#82187][#82187]
- Fixed a bug introduced in v21.2 where the `sql-stats-compaction` job had a chance of not being scheduled during a 21.1 to 21.2 upgrade, causing persisted Statement and Transaction statistics to be enabled without memory accounting. [#82171][#82171]
- Fixed an edge case where VALUES clauses with nested tuples couold fail to be type-checked properly in rare cases. [#82193][#82193]
- This fixes SHOW STATISTICS output so statistics involving dropped columns are not displayed. [#82190][#82190]
- This patch fixes the `CREATE SEQUENCE ... AS` statement to return a valid error message when the specified type name does not exist. [#82276][#82276]
- Fixed a bug where changefeeds created before upgrading to 22.1 would silently fail to emit any data other than resolved timestamps. [#82371][#82371]
- The DateStyle session setting is no longer ignored when using the CLI when set in the `options` URL parameter. [#82101][#82101]
- Index joins now consider functional dependencies from their input when determining equivalent columns instead of returning an internal error. [#81844][#81844]
- Fixed a crash that could happen when preparing a statement with unknown placeholder types. [#82641][#82641]
- Dropping tables with foreign key dependencies would generate the wrong pgcode (Uncategorized vs DependentObjectsStillExist). [#80142][#80142]
- Adding a foreign key and having the referenced table drop during validation can lead to a hang. [#80142][#80142]
- Previously, using AS OF SYSTEM TIME of two different statements in the same line would result in an assertion error. This is now a PG error with code 0A000. [#82504][#82504]
- Fixed a bug where CockroachDB would sometimes automatically retry the BEGIN statement of an explicit transaction. [#82622][#82622]
- In earlier 22.1 releases of cockroach, added validation could cause problems for descriptors which carried invalid backreferences due to an earlier bug in 21.1. This stricter validation could result in a variety of query failures. This patch weakens the validation to permit the corruption as we know it. A subsequent patch in 22.2 will be created to repair the invalid reference. [#82833][#82833]
- Fix a bug where the startup of an internal component after a server restart could result in the delayed application of zone configuration. [#82724][#82724]
- Treat node unavailable error as a retryable changefeed error. [#82768][#82768]
- Ensure running changefeeds do not inhibit node shutdown. [#82768][#82768]
- Views are no longer allowed to reference types that are defined in different databases. Even though this was allowed at view-creation time before, it would cause errors, since cross-database type references are not supported. [#82763][#82763]
- Add missing support for preparing a DECLARE cursor statement with placeholders. [#82754][#82754]
- Use proper multiplying factor to contention value on Statement Details page. [#82911][#82911]
- Last Execution time now shows the correct value on Statement Details page (Overview and Explain Plans). [#83110][#83110]
- CREATE TABLE AS in explicit transaction would fail with an error if the size of the source table exceeded the raft command size limit. [#82951][#82951]
- Prevent disabling TTL with `ttl = 'off'` to avoid conflicting with other ttl settings. To disable TTL, use `RESET (ttl)`. [#83122][#83122]
- Fixed a panic that could happen if the inject_retry_errors_enabled setting is true and an INSERT is executed outside of an explicit transaction. [#83043][#83043]
- A bug has been fixed that prevented partial indexes from be used in some query plans. For example, a partial index with a predicate `WHERE a IS NOT NULL` was not previously used if `a` was a `NOT NULL` column. [#83152][#83152]
- Range lease transfers are no longer permitted to follower replicas that may require a Raft snapshot. This ensures that lease transfers are never delayed behind snapshots, which could previously create range unavailability until the snapshot completed. Lease transfers now err on the side of caution and are only allowed when the outgoing leaseholder can guarantee that the incoming leaseholder does not need a snapshot. [#82758][#82758]
- Fixes the issue when creating a unique, expression index on a REGIONAL BY table. See #83076. [#83125][#83125]
- Due to a bug in transaction lifetime management, a lock could be held for a long period of time when adding a new column to a table (or altering a column type). This contention could make the jobs page non-responsive and job adoption slow. This bug has now been fixed. [#83257][#83257]
- Statement Details now find the stats when the `unset` app filter is selected. [#83008][#83008]
- Previously a user could be connected to a database, but be unable to see the metadata for that database in pg_catalog if the user did not have privileges (e.g. CONNECT) for the database. Now, a user can always see the pg_catalog metadata for the current database they are connected to.  This is needed because CockroachDB currently does not require the CONNECT privilege to connect to a database (see https://github.com/cockroachdb/cockroach/issues/59875). [#83339][#83339]
- The statements table for a txn in the txn details page now shows the correct number of stmts for a transaction. [#83191][#83191]
- Fixed a bug where a panic could occur during server startup when restarting a node which is running a GC job. [#83280][#83280]
- Fix behavior of soundex function when passed certain unicode inputs. Previously, certain unicode inputs could result in crashes, errors or incorrect outputs. [#82761][#82761]
- The period selected on Metrics time picker continues the same when refreshing the page, no longer changing to a custom period. [#83107][#83107]
- Previously, the CREATE statement for the `crdb_internal.cluster_contended_keys` view was missing the `crdb_internal.table_indexes.descriptor_id = crdb_internal.cluster_contention_events.table_id` JOIN condition, resulting in the view having more rows than expected. Now, the view properly joins the `crdb_internal.cluster_contention_events` and `crdb_internal.table_indexes` tables with all necessary JOIN conditions. [#82945][#82945]
- Changefeeds no longer error out when attempting to checkpoint during intermediate pause-requested or cancel-requested states. [#83530][#83530]
- Retry s3 operations when they error out with a read connection reset error instead of failing the top level job. [#83533][#83533]
- Fixes bug where ADD/DROP COLUMN with the legacy schema changer could fail on tables with large rows due to exceeding the raft command max size. [#83544][#83544]
- Prevent a rare case where a stale read could be returned. [#83345][#83345]
- Fix bug where BACKUP may be missing data when the cluster was configured with a very low values for kv.bulk_sst.max_allowed_overage and kv.bulk_sst.target_size [#83102][#83102]
- A bug has been fixed which could crash nodes when visiting the console statements page. This bug was present since version 21.2.0. [#83541][#83541]
- Fixed a rare issue where the failure to apply a Pebble manifest change (typically due to block device failure or unavailability) could result in an incorrect LSM state. Such a state would likely result in a panic soon after the failed application. This change alters the behavior of Pebble to panic immediately in the case of a failure to apply a change to the manifest. [#83704][#83704]
- Fix issue where some exports would receive "unexpected closure of consumer" rather than the actual error the export encountered. [#77938][#77938]
- A bug causing a graceful node shutdown to stall forever has been fixed. [#83824][#83824]
- A bug in transaction conflict resolution which could allow backups to wait on long-running transactions has been resolved. [#83366][#83366]
- Statement and transaction stats are now properly recorded for implicit txns with multiple stmts. [#83616][#83616]
- A Flush message sent during portal execution in the pgwire extended protocol no longer results in an error. [#83675][#83675]
- CockroachDB previously would not normalize `timestamp/timestamptz - timestamp/timestamptz` like Postgres does in some cases (depending on the query), and this is now fixed. [#83944][#83944]
- The PASSWORD option of the CREATE/ALTER ROLE commands now requires the password to be surrounded with single quotes. This fixes confusion that could arise when a mixed-case string is used, since previously that would cause the password to be normalized to lower-case. [#83924][#83924]
- This patch fixes the row_to_json SQL function so it does not error out with input having the VOID data type. [#83876][#83876]
- Fixed a bug that was introduced in release 21.2 that could cause increased memory usage when scanning a table with wide rows. [#83870][#83870]
- Active transactions page no longer shows transactions from closed sessions [#83896][#83896]
- The `SessionTransactionReceived` session phase time is no longer recorded incorrectly, fixing large transaction times from appearing on the UI, also renamed to `SessionTransactionStarted`. [#83590][#83590]
- Fixed a bug that could cause an optimizer panic in rare cases when a query had a left join in the input of an inner join. [#83875][#83875]
- Fixes a critical bug (#83687) introduced in 22.1.0 where failure to transfer a lease in the joint config may result in range unavailability. The fix allows the original leaseholder to re-aquire the lease so that lease transfer can be retried. [#83686][#83686]
- Move connection OK log and metric to same location after auth completes for consistency. This resolves an inconsistency (see linked isssue) in the DB console where the log and metric did not match. [#83597][#83597]
- Fixed the following builtins so that users can only run them if they have SELECT privileges on the relevant tables: crdb_internal.revalidate_unique_constraints_in_all_tables, crdb_internal.revalidate_unique_constraints_in_table, and crdb_internal.revalidate_unique_constraint. [#83959][#83959]
- Custom time period selection is now aligning between Metrics and SQL Activity page. [#84088][#84088]
- A minor bug has been fixed that caused internal errors and poor index recommendations when running `EXPLAIN` statements. [#84169][#84169]
- Fix a bug that led to the querySummary field in crdb_internal.statements_statistics's metadata column being empty. [#84170][#84170]
- Addresses issue where imports and rebalances were being slowed down due to the accumulation of empty directories from range snapshot applications. [#84100][#84100]
- DROP SCHEMA ... CASCADE in the legacy schema changer now correctly fails when a backup restore or an import of an underlying table or type is concurrently underway. [#84189][#84189]
- DROP ... CASCADE of a database or a schema in the declarative schema changer now correctly fails when a backup restore or an import is concurrently underway. [#84189][#84189]
- Replication stream checkpoints now persist across changing plans due to storing span-based checkpoints rather than partition-based checkpoints. [#83813][#83813]
- A bug has been fixed that could cause internal errors in rare cases when running queries with `GROUP BY` clauses. [#84092][#84092]
- A bug has been fixed that caused internal errors in rare cases when performing `DELETE`s on a table that had foreign key references to it with the `ON DELETE CASCADE` option. For example, imagine tables `a` and `b` already exist, and `b` has a FK `ON DELETE CASCADE` column referencing `a`. If table `c` is added with a FK `ON DELETE CASCADE` column referencing table `b` and a `DELETE` statement is performed on table `a` in the same transaction, and internal error could occur. This bug has been present since v21.1.0. [#84219][#84219]
- A bug has been fixed that could corrupt indexes and cause incorrect query results with `INTERVAL` values greater than about 290 years or less than about -290 years. [#84045][#84045]
- Previously, the querySummary metadata field in the crdb_internal.statement_statistics table was inconsistent with the query metadata field for executed prepared statements. These fields are now consistent for prepared statements. [#83673][#83673]
- The Parse, Bind, and Execute pgwire commands now return an error if they are used during an aborted transaction. COMMIT and ROLLBACK statements are still allowed during an aborted transaction. [#84177][#84177]
- Fixed an internal error "node ... with MaxCost added to the memo" that could occur during planning when calculating the cardinality of an outer join when one of the inputs had 0 rows. [#84366][#84366]
- The SQL execution HTTP endpoint did not properly support queries with multiple result values. This is now fixed. This bug was introduced when the feature was first implemented. [#84386][#84386]
- Fix on conversion on jobs endpoint, so the Jobs page won't return 500 error when the job contained an error with quotes. [#84205][#84205]
- Previously, CockroachDB could deadlock when evaluating analytical queries f multiple queries had to spill to disk at the same time. This is now fixed by making some of the queries error out instead. [#84398][#84398]
- Fix bug where an ephemeral I/O error could crash a node. [#84449][#84449]
- In case client-provided session params fail to parse, CRDB no longer leaks accounted for memory. [#83335][#83335]
- This PR fixed a bug where, in a `ALTER PRIMARY KEY`, if the new PK columns is a subset of the old PK columns, we will not rewrite existing secondary index, and hence those secondary indexes continue to have some of the old PK columns in their `suffixColumns`. But the user might, reasonably, think those columns are not used anymore and proceed to drop them. The bug then caused those dependent secondary indexes to be dropped, unexpectedly for the user. [#84303][#84303]
- CLI `cockroach` commands connecting to a remote server will not produce spurious "latency jump" warnings any more. This bug had been introduced in CockroachDB v21.2. [#84031][#84031]
- Fixed a bug in `Concat` projection operators on arrays that gave output of nulls when the projection operator can actually handle null arguments and may result in a non-null output. [#84159][#84159]
- This patch fixes vectorized evaluation of COALESCE involving expressions of type VOID and enhances type checking of NULLIF expressions with VOID, so incompatible comparisons can be caught during query compilation instead of during query execution. [#83868][#83868]
- Sorting on the plans table inside the Statement Details page is now properly working. [#84515][#84515]
- Fixed a bug introduced in 20.2 that could cause a panic when an expression contained a geospatial comparison like `~` that was negated. [#84524][#84524]
- Changing the time window using arrow buttons and 'Now' button will now properly turn the timeframe into a moving window when endTime = now. [#84649][#84649]
- The server process does not any more announce that it is shutting down on stdout when running with `--background`. [#84532][#84532]
- Crdb_internal.decode_plan_gist will no longer produce an internal error when it is used to decode a plan gist for which no schema information is available. [#84682][#84682]
- Previously, the information_schema and SHOW GRANTS command did not report that object owners have permission to GRANT privileges on that object. This is fixed now. [#84749][#84749]
- Fixes a bug where cluster restores of older backups would silently clobber system tables or fail to complete. [#84495][#84495]
- The crdb_internal.deserialize_session builtin function no longer causes an error when handling an empty preprared statement. [#84945][#84945]
- Fixed incorrect error handling that could cause casts to OID types to fail in some cases. [#85086][#85086]
- Fixed a bug where the privileges for an object owner would not be correctly transferred when the owner is changed. [#84879][#84879]
- The public role no longer can be granted default privileges with the grant option. This was a bug because the public role already cannot have the grant option on regular privileges. [#85027][#85027]
- Previously concatenating a UUID with a string would not use the normal string representation of the UUID values. Now it does, so `'eb64afe6-ade7-40ce-8352-4bb5eec39075'::UUID || 'foo'` returns `eb64afe6-ade7-40ce-8352-4bb5eec39075foo` rather than the encoded representation. [#85150][#85150]
- Fixed a bug where new leaseholders (with a `VOTER_INCOMING` type) would not always be detected properly during query execution, leading to occasional increased tail latencies due to unnecessary internal retries. [#85140][#85140]
- Ingestion job is now able to fall back to alternate nodes from its latest topology if the original streamaddress is unavailable. [#84445][#84445]
- Fixed a bug existing since release 20.1 that could cause a panic in rare cases when the unnest function was used with a tuple return type. [#85069][#85069]
- The protected timestamp of the producer job is no longer able to exceed the persisted ingestion frontier. [#84286][#84286]
- Fixed a bug where clients could sometimes receive errors due to lease acquisition timeouts of the form `operation "storage.pendingLeaseRequest: requesting lease" timed out after 6s`. [#84865][#84865]
- Fixed a bug that was introduced in 22.1.0 that could cause the optimizer to not use auto-commit for some mutations in multi-region clusters when it should have done so. This could cause poor query performance. [#85423][#85423]
- Fixed a bug that was introduced in 22.1.0 that could cause the optimizer to reject valid bounded staleness queries with the error "unimplemented: cannot use bounded staleness for DISTRIBUTE". This has now been fixed. [#85423][#85423]
- Streaming cutover no longer relies on successful job planning [#84173][#84173]
- Fixed a bug that we forgot to initialize a connExecutor's schemaChangerState from the corresponding session variable (`use_declarative_schema_changer`), which can cause DDL statements to be executed under the legacy schema changer unknowningly. [#85344][#85344]
- Stmt details page now renders properly for statements where the hex representation of the fingerprint_id is less than 16 digits. [#85174][#85174]
- Previously, CockroachDB could run into an error when the query included a limited reverse scan and some rows needed to be retrieved by Get requests. The bug was introduced in 21.2.0. [#85544][#85544]
- When a CockroachDB node is being, all queries that are still running on that node are now forcefully canceled after waiting the `server.shutdown.query_wait` period. [#82752][#82752]
- Fixed a bug introduced in 21.2 that could cause union queries to return incorrect results in rare cases. [#85594][#85594]
- The SQL unix socket, when requested, now contains a port number compatible with the connection URL when `--listen-addr` is configured to auto-allocate a port number. This bug had existed since CockroachDB v1.0. [#84910][#84910]
- Previously, if a unix socket was requested but it already existed on disk, CockroachDB would exit with an error even if the original owner process was not running any more.  This limitation would e.g. prevent reuse of a unix socket after an abnormal shutdown. It had been present since CockroachDB v1.0. This limitation was lifted. [#84910][#84910]
- Fixes a panic when loading tenant http endpoints for statement stats [#85407][#85407]
- Fixed a bug where EXECUTE did not accept placeholder arguments if the type did not exactly match. [#85861][#85861]
- Fixed an issue where the NO_INDEX_JOIN hint could be ignored by the optimizer in some cases, causing it to create a query plan with an index join. [#85843][#85843]
- Fixed a bug where we incorrectly only handle the first validation operation and skip the rest in a stage of validation operations in the declarative schema changer. [#85781][#85781]
- Fixed a bug internal to drawing dependency graph of a DDL statement under the declarative schema changer. [#85773][#85773]
- Previously, an empty column in the input to COPY ... FROM CSV would be treated as an empty string. Now, this is treated as NULL. The quoted empty string can still be used to input an empty string, Similarly, if a different NULL token is specified in the command options, it can be quoted in order to be treated as the equivalent string value. [#84487][#84487]
- Fixed a rare bug where errors could occur related to the use of arrays of enums. [#85940][#85940]
- CockroachDB now more precisely respects the `distsql_workmem` setting which improves the stability of each node and makes OOMs less likely. [#85440][#85440]
- Fixed a bug in post deserialization changes where we might incorrectly change constraint ID of a constraint that lives in the mutation slice of a table descriptor. [#85778][#85778]
- Changefeed jobs undergoing catch-up scans could fail with an error "expected provisional value for intent with ts X, found Y". The problem would either spontaneously resolve or be rectified after a high-priority scan of the affected index. This bug is now fixed. [#85889][#85889]
- Fix an issue where secondary tenants could route follower reads to a random, far away replica instead of one closer. [#85853][#85853]
- Active execution pages will no longer crash if there are no filters set in local settings.  Release justification: bug fix [#86139][#86139]
- Fixed a bug that existed on v22.1.0-v22.1.5, where attempting to select data from a table that had different partitioning columns used for the primary and secondary indexes could cause an error. This occured if the primary index had zone configurations applied to the index partitions with different regions for different partitions, and the secondary index had a different column type than the primary index for its partitioning column(s). [#86173][#86173]
- Use proper parameter name for database on SQL api  Release justification: bug fix [#86169][#86169]
- The statements and transaction fingerprint will no longer get stuck on the loading page in CC after 5 minutes idling on the page [#85772][#85772]
- Intersection spatial operations would previously potentially return incorrect results on ARM. This is now resolved.  Release justification: bug fix for existing functionality [#86126][#86126]
- Make sequence integer bound consistent with the cluster setting `default_int_size`.  Release justification: bug fix [#84555][#84555]
- Users that create an external connection are now granted `ALL` privileges on the object. [#86336][#86336]
- Fixed a vulnerability in the optimizer that could cause a panic in rare cases when planning complex queries with `ORDER BY`.  Release justification: fixes a release-blocker [#86193][#86193]
- Fix a bug in backup where spans for views were being backed up. Because ranges are not split at view boundaries, this can cause the backup to send export requests to ranges that do not belong to any backup target.  Release justification: bug fixes and low-risk updates to new functionality [#85158][#85158]
- Previously, SET SESSION AUTHORIZATION DEFAULT would have no effect. Now, it causes the current role to be reset to the original user who logged into the session.  Release justification: low risk bug fix to existing functionality [#86485][#86485]
- Search in active execution overview pages works as expected, properly filtering out stmts and txns that do not contain the search string [#86764][#86764]
- Fixed a longstanding bug that could cause the optimizer to produce an incorrect plan when aggregate functions `st_makeline` or `st_extent` were called with invalid-type and empty inputs respectively. [#86722][#86722]
- Fixed a crash that could happen when formatting queries that have placeholder BitArray arguments. [#86607][#86607]
- Fixed a crash/panic that could occur if placeholder arguments were used with the with_min_timestamp or with_max_staleness functions.  Release justification: Fix a crash caused by a panic. [#86605][#86605]
- Fixed a bug that caused some special characters to be misread if they were being ready by COPY ... FROM into a TEXT[] column.  Release justification: bug fix to existing functionality. [#86712][#86712]
- Previously, CockroachDB would return an internal error when evaluating `json_build_object` builtin when an enum or a void datums were passed as the first argument, and this is now fixed. [#86675][#86675]
- Timescale object is properly constructed from session storage, preventing  bugs and crashes in pages that use the time scale object when reloading the page [#86909][#86909]
- Previously, escaping a double quote (`"`) with `COPY` in `CSV` mode could ignore all subsequent lines in the same COPY if an `ESCAPE` clause were specified. This is now resolved. [#86929][#86929]
- Changefeeds emitting to Kafka upon receiving a "message too large" error will now halve the size of their batches until it either succeeds or a batch size of 1 fails.  Release justification: high priority bug fix, new code is mostly only ran in cases where an unrecoverable error would've occurred previously and can be toggled with a cluster setting. [#86138][#86138]
- Adds a missing memory accounting call when appending a KV to the underlying kvBuf  Release justification: low risk bug fix that prevents an import from panicking on non-release builds [#86738][#86738]
- Fixed the latency that is reported for COPY comands in the CLI and stats reporting.  Release justification: low risk bug fix [#86991][#86991]

<h3 id="v22-2-0-alpha-2-performance-improvements">Performance improvements</h3>

- WKT conversion to a spatial type is slightly improved. [#70096][#70096]
- A limitation has been fixed that made creating partial indexes inefficient. [#70120][#70120]
- Mutation statements with a RETURNING clause that are not inside an explicit transaction are faster in some cases. [#70200][#70200]
- Collect basic table statistics during import, to help the optimizer until full statistics collection completes. [#67106][#67106]
- The accuracy of histogram calculations for BYTES types has been improved. As a result, the optimizer should generate more efficient query plans in some cases. [#68740][#68740]
- A SELECT query with both MIN(LeadingIndexColumn) and MAX(LeadingIndexColumn) can now be performed with two LIMITED SCANs instead of a single FULL SCAN. [#70496][#70496]
- A SELECT query from a single table with more than one MIN or MAX scalar aggregate expression and a WHERE clause can now be performed with LIMITED SCANs, one per aggregate expression, instead of a single FULL SCAN.  Note: No other aggregate function, such as SUM, may be present       in the query block in order for it to be eligible for       this transformation. This optimization should occur when       each MIN or MAX expression involves a leading index column,       so that a sort is not required for the limit operation, and       the resulting query plan will appear cheapest to the optimizer. [#70854][#70854]
- Queries with many ORed WHERE clause predicates previously took an excessive amount of time for the optimizer to process, especially if the predicates involved index columns, and if there were more than 1000 predicates (which could happen with application-generated SQL). To fix this, we optimized the processing of SQL with many ORed predicates to make sure a query plan can be generated in seconds instead of minutes or hours. [#71247][#71247]
- The performance of transaction deadlock detection is now more stable even with significant transaction contention. [#71360][#71360]
- Follower reads that encounter many abandoned intents are now able to efficiently resolve those intents. This resolves an asymmetry where follower reads were previously less efficient at resolving abandoned intents than regular reads evaluated on a leaseholder. [#70382][#70382]
- Creating many schema changes in parallel now runs faster due to improved concurrency notifying the jobs subsystem. [#71909][#71909]
- The sqlinstance subsystem no longer reads from the backing SQL table for every request for SQL instance details. This will result in improved performance for when we support multi-region setup for the multi-tenant architecture. [#69976][#69976]
- Fixed a performance regression in planning that could occur for simple queries on schemas with a large number of indexes. [#72136][#72136]
- Improved `IMPORT INTO` performance in cases where it encounters large numbers of unresolved write intents. [#72042][#72042]
- Improve efficiency of looking up old historical descriptors. [#71239][#71239]
- Improves performance of some GROUP BY queries with a LIMIT if there is an index ordering that matches a subset of the grouping columns. In this case the total number of aggregations needed to satisfy the LIMIT can be emited without scanning the entire input, enabling the execution to be more effective. [#71546][#71546]
- Backfills initiated by schema changes now periodically checkpoint progress to avoid excessive re-emitting of already emitted spans. [#71848][#71848]
- Bulk ingestion of small write batches (e.g. index backfill into a large number of ranges) is now throttled, to avoid buildup of read amplification and associated performance degradation. Concurrency is controlled by the new cluster setting `kv.bulk_io_write.concurrent_addsstable_as_writes_requests`. [#73904][#73904]
- Var_pop and stddev_pop aggregate functions are now evaluated more efficiently in a distributed setting. [#73712][#73712]
- Improved job performance in the face of concurrent schema changes by reducing contention. [#72297][#72297]
- Incremental BACKUPs now use less memory to verify coverage of prior backups. [#74393][#74393]
- CockroachDB now retrieves the password credentials of the SQL client concurrently with waiting for the password response during the authentication exchange. This can yield a small latency reduction in new SQL connections. [#74365][#74365]
- Allow rangefeed streams to use separate http connection when `kv.rangefeed.use_dedicated_connection_class.enabled` setting is turned on.  Using separate connection class reduces the possiblity of OOMs when running rangefeeds against very large tables.  The connection window size for rangefeed can be adjusted via `COCKROACH_RANGEFEED_INITIAL_WINDOW_SIZE` environment variable, whose default is 128KB. [#74222][#74222]
- The merging of incremental backup layers during RESTORE now uses a simpler and less memory intensive algorithm. [#74394][#74394]
- The memory representation of DECIMAL datums has been optimized to save space, avoid heap allocations, and eliminate indirection. This increases the speed of DECIMAL arithmetic and aggregation by up to 20% on large data sets. [#74590][#74590]
- RESTORE operations in serverless clusters now explicitly ask the host cluster to distribute data more evenly. [#75105][#75105]
- IMPORT, CREATE INDEX and other bulk ingestion jobs run in serverless clusters now collaborate with the host cluster to spread ingested data more during ingest. [#75105][#75105]
- `covar_pop` aggregate function is now evaluated more efficiently in a distributed setting. [#73062][#73062]
- Queries using `NOT expr` syntax can now be evaluated faster in some cases. [#75058][#75058]
- Regr_sxx, regr_sxy, regr_syy aggregate functions are now evaluated more efficiently in a distributed setting. [#75619][#75619]
- Transaction read refresh operations performed during optimistic concurrency control's validation phase now use a time-bound file filter when scanning the LSM tree. This allows these operations to avoid scanning files that contain no keys written since the transaction originally performed its reads. [#74628][#74628]
- A set of bugs that rendered QPS-based lease and replica rebalancing in CRDB 21.2 and prior ineffective under heterogenously loaded cluster localities has been fixed. Additionally a limitation which prevent CRDB from effectively alleviating extreme QPS hotspots from nodes has also been fixed. [#72296][#72296]
- The optimizer better optimizes queries that include both foreign key joins and self-joins. [#75582][#75582]
- A LIMIT can now be pushed below a foreign key join or self-join in more cases, which may result in more efficient query plans. [#75582][#75582]
- The performance of many DECIMAL arithmetic operators has been improved by as much as 60%. These operators include division (`/`), `sqrt`, `cbrt`, `exp`, `ln`, `log`, and `pow`. [#75770][#75770]
- Stores will now server side retry requests that are directed at the incorrect Range, most commonly following a recent range split. This patch has the effect of reducing tail latency following Range splits. [#75446][#75446]
- The optimizer can now generate lookup joins in certain cases for non-covering indexes, when performing a left outer/semi/anti join. [#58261][#58261]
- The optimizer now plans inner lookup joins using expression indexes in more cases, resulting in more efficient query plans. [#76078][#76078]
- Certain forms of automatically retried "read uncertainty" errors are now retried more efficiently, avoiding a network round trip. [#75905][#75905]
- Regr_avgx, regr_avgy, regr_intercept, regr_r2, and regr_slope aggregate functions are now evaluated more efficiently in a distributed setting [#76007][#76007]
- IMPORTs and index backfills should now do a better job of spreading their load out over the nodes in the cluster. [#75894][#75894]
- Fixed a bug in the histogram estimation code that could cause the optimizer to think a scan of a multi-column index would produce 0 rows, when in fact it would produce many rows. This could cause the optimizer to choose a suboptimal plan. This bug has now been fixed, making it less likely for the optimizer to choose a suboptimal plan when multiple multi-column indexes are available. [#76486][#76486]
- Introduced `kv.replica_stats.addsst_request_size_factor` cluster setting. This setting is used to tune Queries-Per-Second (QPS) sensitivity to large imports. By default, this setting is disabled. When enabled, the size of any AddSSTableRequest will contribute to QPS in inverse relation to this settings magnitude. By default this setting configured to a conservative 50,000; every 50 kilobytes will be accounted for as an additional 1 QPS. [#76252][#76252]
- Queries with a LIMIT clause applied against a single table, either explicitly written, or implicit such as in an uncorrelated EXISTS subquery, now scan that table with improved latency if the table is defined with LOCALITY REGIONAL BY ROW and the number of qualified rows residing in the local region is less than or equal to the hard limit (sum of the LIMIT clause and optional OFFSET clause values). This optimization is only applied if the hard limit is 100000 or less. [#75431][#75431]
- Fixes a limitation which meant that, upon adding a new node to the cluster, lease counts among existing nodes could diverge until the new node was fully upreplicated. [#74077][#74077]
- The optimizer attempts to plan lookup joins on indexes that include computed columns in more cases, which may improve query plans. [#76817][#76817]
- The optimizer produces more efficient query plans for `INSERT .. ON CONFLICT` statements that do not have explicit conflict columns or constraints and are performed on partitioned tables. [#76961][#76961]
- Corr, covar_samp, sqrdiff, and regr_count aggregate functions are now evaluated more efficiently in a distributed setting [#76754][#76754]
- Queries of the form `SELECT * FROM t1 WHERE filter_expression ORDER BY secondIndexColumn LIMIT n;` where there is a NOT NULL CHECK constraint of the form: `CHECK (firstIndexColumn IN (const_1, const_2, const_3...)` may now be rewritten as a UNION ALL `skip scan` to avoid the previously-required sort operation.  Release justification: low risk change for hash index performance [#76893][#76893]
- Improved the optimizer's cardinality estimates for predicates involving many constrained columns. This may result in better index selection for these queries.  Release justification: low risk, high benefit changes to existing functionality [#76786][#76786]
- Ranges are split and rebalanced during bulk ingestion only when they become full, reducing excessive splits and subsequent merging and associated rebalancing-related performance impact. [#77588][#77588]
- Unused JS files are no longer downloaded when the admin UI loads. [#78533][#78533]
- Browser caching of files loaded in the admin UI is now supported. [#78460][#78460]
- Previously, uniqueness checks performed for inserts into REGIONAL BY ROW tables always searched all regions for duplicates. In some cases, these checks will now only search a subset of regions when inserting a single row of constant values. [#77943][#77943]
- Performance of inner, semi or anti join between two tables with ORed equijoin predicates is improved by enabling the optimizer to select a join plan in which each equijoin predicate is evaluated by a separate join, with the results of the joins unioned or intersected together. [#74303][#74303]
- Bulk ingestion writes now use a lower priority for admission control. [#79126][#79126]
- Browser caching of files loaded in the admin UI is now supported. [#78978][#78978]
- Rollback of CREATE TABLE AS with large quantities of data has similar performance to regular DROP TABLE. [#79543][#79543]
- Expressions using the overlaps (&&) operator for arrays now support index-acceleration for faster execution in some cases.  Release justification: low risk, high benefit changes to existing functionality. [#77418][#77418]
- Fixes a regression in previous betas which made running multiple schema changes concurrently less efficient. [#79906][#79906]
- Improved the optimizer's ability to detect contradictions in filter conditions of the form `x IS NULL` when x can never be null. This enables the optimizer to simplify query plans. [#80211][#80211]
- Bulk ingestion of unsorted data during IMPORT and schema changes uses a higher level of parallelism to send produced data to the storage layer. [#79967][#79967]
- Per-span checkpointing added to cases when the high-water mark lags excessively behind the leading edge of the frontier in order to avoid re-emitting the majority of spans due to a small minority that is experiencing issues progressing.  Release Justification: Important fix to enable changefeed to operate on very large tables when performing large catchup scan. [#77763][#77763]
- Significantly improve performance of IMPORTs when the source is producing data not sorted by the destination table's primary key, especially if the destination table has a very large primary key with lots of columns. [#81062][#81062]
- The optimizer's cost model is now more aware of the cost of executing expensive functions (such as spatial functions) in filter conditions. This may lead to improved query plans. [#81924][#81924]
- Changefeed catchup scans now use time-bound iterators, which improves their performance by avoiding accessing data that is outside the catchup scan time interval. Previously, this was controlled by the default-off cluster setting `kv.rangefeed.catchup_scan_iterator_optimization.enabled`, which has now been removed (it is in effect always enabled). [#82450][#82450]
- Decommissioning should now be substantially faster, particularly for small to moderately loaded nodes. [#80993][#80993]
- Queries with filters containing tuples in `= ANY` expressions, such as `(a, b) = ANY(ARRAY[(1, 10), (2, 20)])`, are now index accelerated. [#82616][#82616]
- The optimizer now explores more efficient query plans when index computed columns and expressions have `IS NULL` expressions. [#83619][#83619]
- The optimizer can now return the results of a join in sorted order in more cases. This can allow the optimizer to avoid expensive sorts that need to buffer all input rows. [#84689][#84689]
- The optimizer is now less likely to take an excessive amount of time to plan queries with many joins. [#85100][#85100]
- The optimizer is now less likely to take an excessive amount of time to plan queries with many joins. [#85100][#85100]
- The optimizer can detect contradictory filters in more cases, leading to more efficient query plans. [#85351][#85351]
- The row-level TTL job has been modified to distribute work using DistSQL. This usually results in the leaseholder nodes managing deleting of the spans they own. [#84728][#84728]
- The execution engine can now short-circuit execution of lookup joins in more cases, which can decrease latency for queries with limits. [#85731][#85731]
- ILIKE and NOT ILIKE filters can now be evaluated more efficiently in some cases. [#85695][#85695]
- MVCC garbage collection should now be much less disruptive to foreground traffic than before. [#83213][#83213]
- Previously if there was sudden increase in the volume of pending MVCC GC work, there was an impact on foreground latencies. These sudden increases commonly occurred when: - gc.ttlseconds was reduced dramatically over tables/indexes that accrue   a lot of MVCC garbage (think "rows being frequently deleted") - a paused backup job from a while ago (think > 1 day) was   canceled/failed - a backup job that started a while ago (think > 1 day) just finished  Indicators of a large increase in the volume of pending MVCC GC work is a steep climb in the "GC Queue" graph found in the DB console page, when navigating to 'Metrics', and selecting the 'Queues' dashboard. With this patch, the effect on foreground latencies as a result of this sudden build up should be reduced. [#85823][#85823]
- The execution engine can now perform lookup joins in more cases. This can significantly improve join performance when there is a large table with an index that conforms to the join ON conditions, as well as allow joins to halt early in the presence of a limit. [#85597][#85597]
- Point deletes in SQL are now more efficient during concurrent workloads. [#63416][#63416]
- The crdb_internal.range_statistics function now uses a vectorized implementation which allows the lookup of range metadata to occur in parallel. [#85442][#85442]
- Enable table statistics forecasts, which predict future statistics based on historical collected statistics. Forecasts help the optimizer produce better plans for queries that read data modified after the latest statistics collection. We use only the forecasts that fit the historical collected statistics very well, meaning we have high confidence in their accuracy. Forecasts can be viewed using `SHOW STATISTICS FOR TABLE ... WITH FORECAST`. [#86078][#86078]
- Optimize the execution of COPY FROM.  Release justification: low risk high benefit changes to existing functionality [#83840][#83840]
- Long-running sql sessions are now less likely to maintain large allocations for long periods of time, which decreases the risk of OOM and improves memory utilization.  Release justification: bug fix to reduce likelihood of OOM [#85949][#85949]
- SQL statement that cause events to be logged to `system.eventlog` are now able to complete faster. [#86174][#86174]
- Planning time has been reduced for queries over tables with a large number of columns and/or indexes. [#86606][#86606]

<h3 id="v22-2-0-alpha-2-build-changes">Build changes</h3>

- Upgrade to new version of Go [#69603][#69603]
- Upgrade to Go 1.17.6 [#74655][#74655]
- Upgrade to golang 1.18.4 [#84590][#84590]
- Build *experimental* Linux ARM64 binary Release justification: build *experimental* Linux ARM64 binary for release [#86043][#86043]

<h3 id="v22-2-0-alpha-2-miscellaneous">Miscellaneous</h3>

<h4 id="v22-2-0-alpha-2-<category"><category</h4>

- <what> <show> <why> [#82477][#82477]
- <what> <show> <why> [#82147][#82147]
- <what> <show> <why> [#84400][#84400]
- <what> <show> <why> [#82999][#82999]
- <what> <show> <why> [#82354][#82354]
- <what> <show> <why> [#78595][#78595]
- <what> <show> <why> [#78166][#78166]
- <what> <show> <why> [#76213][#76213]
- <what> <show> <why> [#73064][#73064]
- <what> <show> <why> [#71943][#71943]

<h4 id="v22-2-0-alpha-2-backup-change">Backup change</h4>

- The `sql.multi_region.allow_abstractions_for_secondary_tenants.enabled` cluster setting is consulted when a secondary tenant tries to restore a multi-region database now. [#79536][#79536]

<h4 id="v22-2-0-alpha-2-bug">Bug</h4>

- Fix a bug where it was possible to accrue MVCC garbage for much longer than needed. [#82956][#82956]

<h4 id="v22-2-0-alpha-2-bux-fix">Bux fix</h4>

- Rollback of materialized view creation left references inside dependent objects. [#82087][#82087]

<h4 id="v22-2-0-alpha-2-ccl-change">Ccl change</h4>

- Changefeeds now rate limit log messages related to resolved timestamps. [#82838][#82838]

<h4 id="v22-2-0-alpha-2-docker">Docker</h4>

- Refactor the initialization process of the docker image to accomodate the use case with memory storage. [#80036][#80036]
- Support env variables and init scripts in docker-entrypoint-initdb.d for `start-single-node` command [#70238][#70238]

<h4 id="v22-2-0-alpha-2-missing-category">Missing category</h4>

- A new cluster setting (kv.log_range_and_node_events.enabled) is introduced to disable transactionally logging range events (e.g., merges, splits and rebalancing) and node join and restart events to system tables, to remove the dependency on such tables and improve performance.  Release justification: stability improvement [#85593][#85593]
- Fix a panic. [#86607][#86607]
- Test only change [#86794][#86794]
- User-define functions are disallowed in any expressions (column, index, constraint) in tables. [#85718][#85718]
- Change the MVCC GC queue to recompute MVCC stats on a range, if after doing a GC run it still thinks there is garbage in the range. [#83194][#83194]
- A trace recording will now output an additional field per tracing span that corresponds to metadata bucketed by operation name of the spans' children. [#83409][#83409]
- A rare crash indicating a nil-pointer deference in google.golang.org/grpc/internal/transport.(*Stream).Context(...) was fixed. [#80878][#80878]
-  [#80592][#80592]
- Add a `changefeed.backfill.scan_request_size` setting to control scan request size during backfill.  Relese Justification: Low danger stability and performance improvement. [#79690][#79690]
- Improve jobs system resilience to scheduled jobs that may lock up jobs/scheduled job table for long periods of time.  Each schedule now has a limited amount of time to complete its execution.  The timeout is controlled via  `jobs.scheduler.schedule_execution.timeout` setting.  Release Justification: System stability improvement. [#77372][#77372]
- Scheduled jobs scheduler now runs on a single node by default in order to reduce contention on scheduled jobs table. [#73319][#73319]
- The crdb_internal.node_inflight_trace_spans virtual table will now present traces for all operations ongoing on the respective node. Before, the table was reflecting a small percentage of ongoing operations unless tracing was explicitly enabled. [#76403][#76403]
- The default value of `kv.rangefeed_concurrent_catchup_iterators` has been lowered to 16 to help avoid overload during CHANGEFEED restarts. [#75851][#75851]
-  [#75990][#75990]
-  [#74425][#74425]
- Add admit and commit latency metrics to changefeeds. [#72111][#72111]
- Update and improve the set of sink specific changefeed metrics. [#72111][#72111]
- The default snapshot recovery/rebalance rates `kv.snapshot_rebalance.max_rate` and `kv.snapshot_recovery.max_rate` were bumped from 8MB/s to 32MB/s, production experience has taught us that earlier values were too conservative. Users might observer higher network utilization during rebalancing/recovery in service of rebalancing/recovering faster (for the latter, possibly reducing the MTTF). If the extra utilization is undesirable, users can manually revert these rates back to their original settings of 8 MB/s. [#71814][#71814]
-  [#71823][#71823]

<h4 id="v22-2-0-alpha-2-none">None</h4>

-  [#83417][#83417]
-  [#77606][#77606]

<h4 id="v22-2-0-alpha-2-ops">Ops</h4>

- Add `rebalancing.writebytespersecond` and `rebalancing.readbytespersecond` timeseries metrics. These metrics reflect the average number of bytes written and read across all replicas per store, over the last 30 minutes of time. [#80245][#80245]

<h4 id="v22-2-0-alpha-2-security-upgrade">Security upgrade</h4>

- Modifies default testserver method of getting http unauthenticated clients with a more verbose name to encourage use of authenticated sessions. The default authenticated admin http client getter is simplified in turn. [#77732][#77732]

<h4 id="v22-2-0-alpha-2-changes-without-release-note-annotation">Changes without release note annotation</h4>

- [#86906][#86906] [6590b9f4f][6590b9f4f] docs: fix duplicate typo (Pavel Kalinnikov <pavel@cockroachlabs.com>)
- [#86957][#86957] [fb5ec492b][fb5ec492b] roachpb: reduce size of BatchRequest struct below 256 bytes (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#86841][#86841] [566bb1651][566bb1651] workload/ycsb: give each worker a separate sql.Conn (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#86255][#86255] [1cc5b550c][1cc5b550c] upgrades,upgrade,upgrades_test: Added an upgrade for updating invalid column ID in seq's back references (Xiang Gu <xiang@cockroachlabs.com>)
- [#86255][#86255] [9ec6d411f][9ec6d411f] upgrades,upgrade,upgrades_test: Added an upgrade for updating invalid column ID in seq's back references (Xiang Gu <xiang@cockroachlabs.com>)
- [#86255][#86255] [b7be578e9][b7be578e9] upgrades,upgrade,upgrades_test: Added an upgrade for updating invalid column ID in seq's back references (Xiang Gu <xiang@cockroachlabs.com>)
- [#86255][#86255] [f1f0697bf][f1f0697bf] upgrades,upgrade,upgrades_test: Added an upgrade for updating invalid column ID in seq's back references (Xiang Gu <xiang@cockroachlabs.com>)
- [#86255][#86255] [831bfe703][831bfe703] upgrades,upgrade,upgrades_test: Added an upgrade for updating invalid column ID in seq's back references (Xiang Gu <xiang@cockroachlabs.com>)
- [#86566][#86566] [51709f3b1][51709f3b1] kv: deflake TestLeaseTransferWithPipelinedWrite (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#85392][#85392] [7a8f50124][7a8f50124] streamingccl: support sst event in random stream client (Casper Liu <casper@cockroachlabs.com>)
- [#86319][#86319] [fa0e39a3f][fa0e39a3f] kv: improve IllegalReplicationChangeError (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#86236][#86236] [82e4af40f][82e4af40f] tracing: re-use childrenMetadata map across trace spans (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#86152][#86152] [454826e72][454826e72] docs: remove 'api change' from git commit scripts (Ryan Kuo <8740013+taroface@users.noreply.github.com>)
- [#85764][#85764] [c7c154af8][c7c154af8] kv: pass explicit Now timestamp on BatchRequest, remove timestamp downcasting (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#76233][#76233] [35151c9c6][35151c9c6] kv: remove clock update on BatchResponse (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74337][#74337] [7f713fb31][7f713fb31] kv: pool rangeCacheKey objects (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#85819][#85819] [51c5a382c][51c5a382c] kv: use max timestamp during below-Raft scan to gossip liveness (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#85326][#85326] [bfcdb544e][bfcdb544e] ui: update cluster ui to v22.2.0-prerelease-5 (Marylia Gutierrez <marylia@cockroachlabs.com>)
- [#85072][#85072] [4844cfce0][4844cfce0] gossip: use syncmap to avoid read lock in AddressResolver (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#85159][#85159] [ac2185f82][ac2185f82] requestbatcher: nil unused slice entries in batchQueue heap (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#84208][#84208] [d270fa08c][d270fa08c] Update activerecord.go v7 support (Gemma Shay <75328174+gemma-shay@users.noreply.github.com>)
- [#84744][#84744] [c5bc00186][c5bc00186] kv/bulk: use Key.Next in createSplitSSTable, not Key.PrefixEnd (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#84744][#84744] [8891fd39d][8891fd39d] kv/bulk: use Key.Next in createSplitSSTable, not Key.PrefixEnd (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#84686][#84686] [ea7d6fbd2][ea7d6fbd2] Adjust per_changefeed_limit to 128MiB (Matt Sherman <sherman@cockroachlabs.com>)
- [#84670][#84670] [5b7a1335a][5b7a1335a] roachprod: change file permissions on prom/grafana files to 0777 (Michael Butler <butler@cockroachlabs.com>)
- [#84106][#84106] [a345d4612][a345d4612] kv: avoid heap alloc of RangeAppliedState per Raft apply batch (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#84108][#84108] [4a9816b59][4a9816b59] kv/batcheval: replace command hash-map with array (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#84110][#84110] [35e0f4a6a][35e0f4a6a] kv: use atomic bool to avoid read lock in Replica.IsInitialized (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74342][#74342] [2904f8937][2904f8937] storage: short-circuit in recordIteratorStats if not recording (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82151][#82151] [8e6b85b53][8e6b85b53] kv: add debug information to track down #77663 (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#83614][#83614] [27772d931][27772d931] ui: v22.2.0-prerelease-3 (Marylia Gutierrez <marylia@cockroachlabs.com>)
- [#83377][#83377] [667b46adb][667b46adb] streamingccl → tenant-streaming team in CODEOWNERS (Matt Sherman <sherman@cockroachlabs.com>)
- [#83377][#83377] [f7407c71a][f7407c71a] streamingccl → tenant-streaming team in CODEOWNERS (Matt Sherman <sherman@cockroachlabs.com>)
- [#79134][#79134] [dd4049bd5][dd4049bd5] kv: support FOR {UPDATE,SHARE} SKIP LOCKED (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79134][#79134] [06cc64493][06cc64493] kv: support FOR {UPDATE,SHARE} SKIP LOCKED (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79134][#79134] [745208894][745208894] kv: support FOR {UPDATE,SHARE} SKIP LOCKED (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79134][#79134] [f3f8c79ed][f3f8c79ed] kv: support FOR {UPDATE,SHARE} SKIP LOCKED (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79134][#79134] [0ca54c768][0ca54c768] kv: support FOR {UPDATE,SHARE} SKIP LOCKED (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#83510][#83510] [88b2b015d][88b2b015d] authors: add Jeremy Yang to authors (Jeremy Yang <jyang@cockroachlabs.com>)
- [#83520][#83520] [5d4c0d71b][5d4c0d71b] kv: don't try to reject lease transfer when flushing proposal buffer (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82798][#82798] [09e60c061][09e60c061] kv: clean up BatchRequest.IsLeaseRequest (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82797][#82797] [f20ff698f][f20ff698f] kv: extract etcd/raft utilities into raftutil library (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#81933][#81933] [b6e0a6f85][b6e0a6f85] kv: don't skip "may need snapshot" protection for VOTER_INCOMING replicas (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82744][#82744] [c869c9ab9][c869c9ab9] ui: update cluster-ui to v22.2.0-prerelease-2 (Marylia Gutierrez <marylia@cockroachlabs.com>)
- [#81879][#81879] [d32226b97][d32226b97] kv: remove dead code in `Replica.raftTruncatedStateLocked` (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#81879][#81879] [82ea33c88][82ea33c88] kv: remove dead code in `Replica.raftTruncatedStateLocked` (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#81879][#81879] [613ef47b8][613ef47b8] kv: remove dead code in `Replica.raftTruncatedStateLocked` (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82479][#82479] [c5497ba47][c5497ba47] keys: resolve subtle non-bug by exporting RaftLogKeyFromPrefix (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82479][#82479] [8012d6a92][8012d6a92] keys: resolve subtle non-bug by exporting RaftLogKeyFromPrefix (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82479][#82479] [74d1fb9b7][74d1fb9b7] keys: resolve subtle non-bug by exporting RaftLogKeyFromPrefix (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#82476][#82476] [486dcc307][486dcc307] update cluster-ui to v22.2.0-prerelease-1 (Marylia Gutierrez <marylia@cockroachlabs.com>)
- [#82304][#82304] [575215b93][575215b93] [CRDB-15892] SQL: NULL geography concatenation is inconsistent with Postgres (Saad Ur Rahman <saadurrahman@apache.org>)
- [#82032][#82032] [bb750c965][bb750c965] docs: fix broken link in range merge RFC (Justin Jaffray <justin.jaffray@gmail.com>)
- [#81734][#81734] [78dd74f0a][78dd74f0a] ppc64le - fix test failures of TestBoundingBoxFromGeomT/GeographyType (Prashant Khoje <prashant.khoje@ibm.com>)
- [#81734][#81734] [4fafba71b][4fafba71b] ppc64le - fix test failures of TestBoundingBoxFromGeomT/GeographyType (Prashant Khoje <prashant.khoje@ibm.com>)
- [#81734][#81734] [0cb3190ea][0cb3190ea] ppc64le - fix test failures of TestBoundingBoxFromGeomT/GeographyType (Prashant Khoje <prashant.khoje@ibm.com>)
- [#81767][#81767] [718fe9f53][718fe9f53] kv: don't consider skipped snapshots to be "processed" by queues (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#81107][#81107] [fec45b870][fec45b870] sql: trace meta2 scans made by crdb_internal.probe_ranges (Josh Imhoff <josh@cockroachlabs.com>)
- [#81125][#81125] [d7d313b73][d7d313b73] storage: use provisional version value to determine uncertainty of intents (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#80874][#80874] [72a192c7f][72a192c7f] Add Andrew Baptist to AUTHORS (Andrew Baptist <baptist@cockroachlabs.com>)
- [#80443][#80443] [9c1d08409][9c1d08409] storage: fix accounting for orig LiveBytes in updateStatsOnResolve (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#80330][#80330] [16739391a][16739391a] docs: update GRANT stmt for WITH GRANT OPTION (Gemma Shay <75328174+gemma-shay@users.noreply.github.com>)
- [#79679][#79679] [2115a44e6][2115a44e6] sql/opt: split out row-level locking properties struct (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#80185][#80185] [562c7574a][562c7574a] backupccl: remove broken handling of inline values in `slurpSSTablesLatestKey` (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#80007][#80007] [679e5795e][679e5795e] kv/kvprober: use single batch in write probe (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79794][#79794] [913ce9dfd][913ce9dfd] kvserver: default allocator l0 action to rebalance (Austen McClernon <austen@cockroachlabs.com>)
- [#78044][#78044] [918b22bcf][918b22bcf] sql: introduce multi-region zone config extension descriptor changes (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78044][#78044] [c0b944fcd][c0b944fcd] sql: introduce multi-region zone config extension descriptor changes (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79581][#79581] [68819c520][68819c520] kv: fix logging of leaseholder's StoreID in ShouldTransferLease (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78255][#78255] [5ab7683da][5ab7683da] Log reference 6 (Ryan Kuo <8740013+taroface@users.noreply.github.com>)
- [#78255][#78255] [d0825de8c][d0825de8c] Log reference 6 (Ryan Kuo <8740013+taroface@users.noreply.github.com>)
- [#79554][#79554] [6bcf4c48e][6bcf4c48e] bulk: don't scatter after pre-splitting on table boundaries (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79522][#79522] [cacac45c7][cacac45c7] kv: remove raft leader progress override in newTruncateDecision (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79362][#79362] [af64a4a3d][af64a4a3d] kv: remove stale comment in processOneChange (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79444][#79444] [519266577][519266577] roachtest: warmup follower-reads for fixed duration, not fixed number of ops (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#79086][#79086] [ef293592e][ef293592e] backupccl: mark backup ExportRequests as Bulk priority (David Taylor <tinystatemachine@gmail.com>)
- [#78218][#78218] [1dd880897][1dd880897] kv: scan empty right-hand side of split for stats (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78585][#78585] [28d3c1a4e][28d3c1a4e] kv: ignore unevaluated Get requests after optimistic evaluation (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78584][#78584] [9a9c47963][9a9c47963] kv: don't update timestamp cache for unevaluated Get requests (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78418][#78418] [11d9b3d95][11d9b3d95] workload: support fixture import in multi-tenant mode (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78667][#78667] [2373a4c8f][2373a4c8f] sql/rowexec: deflake TestUncertaintyErrorIsReturned (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#77785][#77785] [4a696f2c9][4a696f2c9] util/admission: minor cleanups (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#77785][#77785] [091221e24][091221e24] util/admission: minor cleanups (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#77785][#77785] [2b2c43852][2b2c43852] util/admission: minor cleanups (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78103][#78103] [587efd688][587efd688] roachtest: increase sysbench workload concurrency (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#78102][#78102] [e6c2413a3][e6c2413a3] rpc: remove gRPC stats handlers (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#77854][#77854] [f7d183a11][f7d183a11] sql: break dependency from config/zonepb to sql/catalog/descpb (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#77857][#77857] [6b87aa6ad][6b87aa6ad] util/goschedstats: support go1.18 (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#77860][#77860] [1cf4a2766][1cf4a2766] *: remove redundant newlines at end of Fprintln (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74174][#74174] [05e903437][05e903437] logictest: randomly backup/restore in logic tests (Aditya Maru <adityamaru@gmail.com>, Paul Bardea <paul@pbardea.com>)
- [#76789][#76789] [f9d6bea00][f9d6bea00] backupccl: Moved checkpoint and latest files into new directories. (Darryl Wong <darryl.wong@cockroachlabs.com>)
- [#76888][#76888] [9cffb82d3][9cffb82d3] roachtest: fix gorm (Jane Xing <zhouxing@uchicago.edu>)
- [#76410][#76410] [c048446c9][c048446c9] kv: disallow GC requests that bump GC threshold and GC expired versions (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#76209][#76209] [2331ac119][2331ac119] kv: enforce minimum Raft snapshot rate limit (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#76095][#76095] [74e2070c0][74e2070c0] kv: don't pass clock information through Raft log (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#76095][#76095] [6ea73f4e1][6ea73f4e1] kv: don't pass clock information through Raft log (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#75843][#75843] [c517f764f][c517f764f] c-deps/krb5: fix build for more recent versions of autoconf (Nick Travers <travers@cockroachlabs.com>)
- [#75710][#75710] [38cba0df0][38cba0df0] vendor: bump cockroachdb/apd to v3.0.1 (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#75624][#75624] [4d041e27c][4d041e27c] kv: compare MVCC GC threshold against Refresh{Range}Request.RefreshFrom (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#75597][#75597] [d679b6de0][d679b6de0] Update 20180324_parallel_commit.md (llllash <33652948+llllash@users.noreply.github.com>)
- [#75231][#75231] [313d08532][313d08532] sql: support hash sharded index default bucket count (Chengxiong Ruan <chengxiongruan@gmail.com>)
- [#74082][#74082] [4bb7aef76][4bb7aef76] sql: schema changer not to validate shard column constraint (Chengxiong Ruan <chengxiongruan@gmail.com>)
- [#74560][#74560] [01cb84707][01cb84707] Revert "roachpb: change `Lease.String()`/`SafeFormat()` to support re… (Yahor Yuzefovich <yahor@cockroachlabs.com>)
- [#74341][#74341] [bb1bce264][bb1bce264] sql/catalog: restore fast-path in FullIndexColumnIDs (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74355][#74355] [410ef2994][410ef2994] kv: protect Replica's lastToReplica and lastFromReplica fields with raftMu (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74592][#74592] [8c5612909][8c5612909] coldata: operate on Nulls value, not reference (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74348][#74348] [deec9092f][deec9092f] sql: release BatchFlowCoordinator objects to pool (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74343][#74343] [fad1ef725][fad1ef725] sql: use FastIntMap for QueryState.RangesPerNode (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74354][#74354] [557fe5e7d][557fe5e7d] vendor: update petermattis/goid to support fast access on arm64 (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74345][#74345] [d54e0dda6][d54e0dda6] kv: return RangeIterator by value from constructor (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74351][#74351] [8d9427b58][8d9427b58] sql: don't formatStatementHideConstants when profiling prepared stmt (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74336][#74336] [79a52303d][79a52303d] kv: combine heap allocations for EndTxn requests (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74338][#74338] [47900ebb5][47900ebb5] sql: avoid string formatting in reportSessionDataChanges when not necessary (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74339][#74339] [840ac2191][840ac2191] sql: avoid net.Error allocation on each readTimeoutConn.Read call (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74340][#74340] [5ecb6e24c][5ecb6e24c] sql: don't construct empty SessionData.CustomOptions (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74340][#74340] [049721dba][049721dba] sql: don't construct empty SessionData.CustomOptions (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74344][#74344] [71cb6f5bc][71cb6f5bc] kv: move splitHealthy to method on grpcTransport (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74346][#74346] [03a4fad4a][03a4fad4a] kv: return pointers from TxnSender.GetLeafTxn{Input/Final}State (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74347][#74347] [d9e17f021][d9e17f021] kv: inline small condensableSpanSet slices (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74350][#74350] [1f021e405][1f021e405] kv: avoid retry error allocation on each Txn.exec call (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74353][#74353] [362242f1e][362242f1e] sql/schema: re-organize the UnleasableSystemDescriptors set (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74356][#74356] [36e31630d][36e31630d] kv: acquire Replica shared mutex in tryGetOrCreateReplica (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74358][#74358] [8fc9aa97e][8fc9aa97e] kv: combine heap allocations in maybeStripInFlightWrites (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74225][#74225] [c6dc23e9b][c6dc23e9b] kv: treat empty transaction deadlines identically to nil deadlines (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73924][#73924] [4c461b482][4c461b482] ui: update jobs page colors (Josephine Lee <josephine@cockroachlabs.com>)
- [#74076][#74076] [0b1171e8a][0b1171e8a] kv/kvclient: don't let request direction switch while splitting partial batches (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74136][#74136] [7613c1c71][7613c1c71] sql : allow computed column in pk for rand table tests (Chengxiong Ruan <chengxiongruan@gmail.com>)
- [#74108][#74108] [625ee8b39][625ee8b39] kv: remove dependency on ticks from maybeDropMsgApp (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74108][#74108] [63dfc1493][63dfc1493] kv: remove dependency on ticks from maybeDropMsgApp (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74109][#74109] [ebf99778e][ebf99778e] kv: rename gcQueue to mvccGCQueue (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74109][#74109] [58c5ea09c][58c5ea09c] kv: rename gcQueue to mvccGCQueue (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#74156][#74156] [509efb2e2][509efb2e2] docs: fix broken links in encoding.md (TennyZhuang <zty0826@gmail.com>)
- [#73928][#73928] [b61644c0a][b61644c0a] sql: primary key to allow virtual columns (Chengxiong Ruan <chengxiongruan@gmail.com>)
- [#74073][#74073] [f11f912cb][f11f912cb] kv: add to replicaGCQueue in replicaMsgAppDropper, not gcQueue (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73986][#73986] [48dd74ca4][48dd74ca4] Revert "colrpc: propagate the flow cancellation as ungraceful for FlowStream RPC" (Yahor Yuzefovich <yahor@cockroachlabs.com>)
- [#73943][#73943] [1190d4149][1190d4149] cli: support --locality and --max-offset flags with sql tenant pods (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73718][#73718] [3def4633e][3def4633e] kv: pass roachpb.Header by pointer to DeclareKeysFunc (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73725][#73725] [26eed0b33][26eed0b33] kv: add TestTxnReadWithinUncertaintyInterval (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73725][#73725] [8445150fc][8445150fc] kv: add TestTxnReadWithinUncertaintyInterval (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73557][#73557] [9c09473ec][9c09473ec] kv: unify client and server-side refresh code paths (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73578][#73578] [e05a787fb][e05a787fb] storage: remove leftover logic related to interleaved intents (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73591][#73591] [fda96e428][fda96e428] ui: show per-node series for "Read Amplification" and "SSTables" graphs (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73648][#73648] [7e81d81d3][7e81d81d3] ui: update cluster-ui version to v22.1.0-prerelease-3 (Marylia Gutierrez <marylia@cockroachlabs.com>)
- [#73528][#73528] [909e04f8b][909e04f8b] kv: don't set CanForwardReadTimestamp on implicit->explicit EndTxn transition (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73528][#73528] [cc674d8f8][cc674d8f8] kv: don't set CanForwardReadTimestamp on implicit->explicit EndTxn transition (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73494][#73494] [ed6d80372][ed6d80372] sql: actually deflake TestSavepoints (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73494][#73494] [7485ec19b][7485ec19b] sql: actually deflake TestSavepoints (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73392][#73392] [b5c75c7d0][b5c75c7d0] kv: stop consulting RaftHeartbeat.LaggingFollowersOnQuiesceAccurate (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73388][#73388] [c312eb044][c312eb044] sql: deflake TestSavepoints (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72908][#72908] [79650bd53][79650bd53] pkg/sql: move range unsplit logic to table gc jobs (Chengxiong Ruan <chengxiongruan@gmail.com>)
- [#73342][#73342] [547bfce23][547bfce23] kv/kvserver/uncertainty: remove observedts_test target from bazel build file (Chengxiong Ruan <chengxiongruan@gmail.com>)
- [#73244][#73244] [0ee3bbd66][0ee3bbd66] kv: combine local and global uncertainty limit into Interval struct (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73244][#73244] [534e4511f][534e4511f] kv: combine local and global uncertainty limit into Interval struct (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#73260][#73260] [5eca58c79][5eca58c79] ci: in bazel roachtest nightlies, symlink `lib` to `lib.docker_amd64` (Ricky Stewart <ricky@cockroachlabs.com>)
- [#72961][#72961] [019212fc8][019212fc8] col/coldata: batch allocate memColumn objects (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72962][#72962] [1b59a8c79][1b59a8c79] sql/catalog/descs: implement interfaces on *DistSQLTypeResolver (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72894][#72894] [eec9dc306][eec9dc306] kv: use version-less key in rditer.KeyRange (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72895][#72895] [39ef815ce][39ef815ce] storage: remove decodeMVCCKey (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72902][#72902] [f04e51a70][f04e51a70] storage: delete deprecated PutProto function (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72848][#72848] [315c3490d][315c3490d] server: only sleep to ensure clock monotonicity on server restart (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72014][#72014] [ca860749b][ca860749b] Roachprod: Add custom label to roachprod (Xun He <xun@cockroachlabs.com>)
- [#72679][#72679] [4ebde0858][4ebde0858] [Snyk] Security upgrade alpine from 3.9 to 3.14 (snyk-bot <snyk-bot@snyk.io>)
- [#72278][#72278] [3392a0b5f][3392a0b5f] hlc: document properties and uses of Hybrid Logical Clocks (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72584][#72584] [d0f72f975][d0f72f975] Revert "sql: add support for create index inside new schema changer" (Faizan Qazi <faizan@cockroachlabs.com>)
- [#72276][#72276] [7dd6acc58][7dd6acc58] server: actually ensure clock monotonicity on startup (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#72040][#72040] [805b6070e][805b6070e] kv: prevent intent timestamp regression during partial txn rollback (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#71871][#71871] [6a3b0d6ab][6a3b0d6ab] dev: add Lint/ prefix to lint test filter (Steven Danna <danna@cockroachlabs.com>)
- [#68705][#68705] [8abd5f02b][8abd5f02b] docs: fix broken links to the licenses (Paul Lin <paullin3280@gmail.com>)
- [#71330][#71330] [a4a9037d2][a4a9037d2] Use include_cached to speed up build time, adding comment tags. (Ian Evans <ian@cockroachlabs.com>)
- [#71259][#71259] [99a3a0ac4][99a3a0ac4] Bump Kubernetes YAML to CRDB version v21.1.10 (Juan Leon <juan.leon@gmail.com>)
- [#70972][#70972] [64f31f999][64f31f999] kv: don't require raftMu in cleanupFailedProposalLocked (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#70972][#70972] [ff7b7e7ab][ff7b7e7ab] kv: don't require raftMu in cleanupFailedProposalLocked (Nathan VanBenschoten <nvanbenschoten@gmail.com>)
- [#70513][#70513] [a9c31fc45][a9c31fc45] streamingccl: unskip TestStreamIngestionFrontierProcessor (Aditya Maru <adityamaru@gmail.com>)
- [#70693][#70693] [d963aa82b][d963aa82b] update instructions to publish cluster-ui to npm (Marylia Gutierrez <marylia@cockroachlabs.com>)
- [#70423][#70423] [24d711e96][24d711e96] Update CODEOWNERS (Tobias Grieger <tobias@tkschmidt.me>)
- [#70355][#70355] [d6b756777][d6b756777] roachtest: improve README re: roachstress (Tobias Grieger <tobias@tkschmidt.me>)
- [#69292][#69292] [d2ec82be1][d2ec82be1] importccl: delete redundant if condition from mysql import (Aditya Maru <adityamaru@gmail.com>)
- [#69215][#69215] [c744ad9ac][c744ad9ac] doc: fix typo in txn_coord_sender.md (Ikko Ashimine <eltociear@gmail.com>)

<h3 id="v22-2-0-alpha-2-doc-updates">Doc updates</h3>

{% comment %}Docs team: Please add these manually.{% endcomment %}

<h3 id="v22-2-0-alpha-2-contributors">Contributors</h3>

This release includes 5529 merged PRs by 201 authors.
We would like to thank the following contributors from the CockroachDB community:

- Abhinav Garg (first-time contributor, CockroachDB team member)
- Alex Santamaura (first-time contributor, CockroachDB team member)
- Alexander Shraer (first-time contributor, CockroachDB team member)
- Amy Gao (first-time contributor, CockroachDB team member)
- Andrew Baptist (first-time contributor, CockroachDB team member)
- Annie Pompa (first-time contributor, CockroachDB team member)
- Austen McClernon (first-time contributor, CockroachDB team member)
- Ben Bardin (first-time contributor, CockroachDB team member)
- Casper Liu (first-time contributor, CockroachDB team member)
- Catherine J (first-time contributor)
- Chen Chen (first-time contributor, CockroachDB team member)
- Chengxiong Ruan (first-time contributor, CockroachDB team member)
- Chinemerem (first-time contributor)
- Christopher Fitzner (first-time contributor, CockroachDB team member)
- Christopher Ye (first-time contributor, CockroachDB team member)
- Dan Sheldon (first-time contributor, CockroachDB team member)
- Darryl Wong (first-time contributor, CockroachDB team member)
- David Hartunian (first-time contributor, CockroachDB team member)
- Emnet Gossaye (first-time contributor, CockroachDB team member)
- Eng Zer Jun (first-time contributor)
- Eudald (first-time contributor)
- Evan Wall (first-time contributor, CockroachDB team member)
- Farye Nwede (first-time contributor)
- Fenil Patel (first-time contributor, CockroachDB team member)
- Frediano Ziglio (first-time contributor)
- Frédéric BIDON (first-time contributor)
- Ganeshprasad Biradar
- Gary Lau (first-time contributor, CockroachDB team member)
- Gemma Shay (first-time contributor)
- Gerardo Torres (first-time contributor, CockroachDB team member)
- Herko Lategan (first-time contributor, CockroachDB team member)
- Ian Evans (first-time contributor, CockroachDB team member)
- Ikko Ashimine (first-time contributor)
- Jack Wu (first-time contributor, CockroachDB team member)
- James Jung (first-time contributor, CockroachDB team member)
- Jason Chan (first-time contributor, CockroachDB team member)
- Jason Chen (first-time contributor, CockroachDB team member)
- Jeffrey White (first-time contributor, CockroachDB team member)
- Jeremy Yang (first-time contributor, CockroachDB team member)
- Joe Sankey (first-time contributor)
- Jon Tsiros (first-time contributor, CockroachDB team member)
- Josephine Lee (first-time contributor, CockroachDB team member)
- Josh Soref (first-time contributor)
- Juan Leon (first-time contributor, CockroachDB team member)
- Justin Beaver (first-time contributor, CockroachDB team member)
- Kathryn Hancox (first-time contributor, CockroachDB team member)
- Kevin Chen (first-time contributor, CockroachDB team member)
- Lasse Nordahl (first-time contributor, CockroachDB team member)
- Liam Gillies (first-time contributor, CockroachDB team member)
- Lidor Carmel (first-time contributor, CockroachDB team member)
- Mari Staib (first-time contributor, CockroachDB team member)
- Marjan Ansar (first-time contributor, CockroachDB team member)
- Mark Sirek (first-time contributor, CockroachDB team member)
- Matt Linville (first-time contributor, CockroachDB team member)
- Max Neverov
- Miguel Novelo (first-time contributor)
- Mike Bookham (first-time contributor, CockroachDB team member)
- Miral Gadani (first-time contributor, CockroachDB team member)
- Mufeez Amjad (first-time contributor, CockroachDB team member)
- Nate Long (first-time contributor, CockroachDB team member)
- Nathan Lowe (first-time contributor)
- Nick Vigilante (first-time contributor, CockroachDB team member)
- PJ Tatlow (first-time contributor, CockroachDB team member)
- Paul Lin (first-time contributor)
- Pavel Kalinnikov (first-time contributor, CockroachDB team member)
- Prashant Khoje (first-time contributor)
- Rachael Harding (first-time contributor, CockroachDB team member)
- Rajiv Sharma (first-time contributor)
- Remy Wang (first-time contributor)
- Renato Costa (first-time contributor, CockroachDB team member)
- Rima Deodhar (first-time contributor, CockroachDB team member)
- Ron Nollen (first-time contributor, CockroachDB team member)
- Rupesh Harode
- Ryan Zhao (first-time contributor, CockroachDB team member)
- Saad Ur Rahman (first-time contributor)
- Sean Barag (first-time contributor, CockroachDB team member)
- Sean Chittenden (first-time contributor, CockroachDB team member)
- Sherman Grewal (first-time contributor, CockroachDB team member)
- Sideny (first-time contributor, CockroachDB team member)
- Stan Rosenberg (first-time contributor, CockroachDB team member)
- Steve Kuznetsov (first-time contributor)
- Suraj Rao (first-time contributor, CockroachDB team member)
- TennyZhuang (first-time contributor)
- Tharun
- Tim Graham
- Tom Schmidt (first-time contributor, CockroachDB team member)
- Ulf Adams
- Wenyi Hu (first-time contributor, CockroachDB team member)
- Xiang Gu (first-time contributor, CockroachDB team member)
- Xun He (first-time contributor, CockroachDB team member)
- Zach Lite (first-time contributor, CockroachDB team member)
- Zane Teh (first-time contributor, CockroachDB team member)
- Zhou Fang (first-time contributor)
- adityamaru (first-time contributor, CockroachDB team member)
- changhan (first-time contributor)
- craig[bot] (first-time contributor, CockroachDB team member)
- dandotimujahid (first-time contributor)
- e-mbrown
- fabio (first-time contributor, CockroachDB team member)
- healthy-pod (first-time contributor, CockroachDB team member)
- j82w (first-time contributor, CockroachDB team member)
- likzn (first-time contributor)
- linaqiu22 (first-time contributor)
- llllash (first-time contributor)
- lpessoa (first-time contributor)
- lyubomirkyuchukov (first-time contributor)
- mnovelodou (first-time contributor)
- mosquito2333
- neeral
- nnaka2992 (first-time contributor)
- rharding6373
- shralex (first-time contributor)
- snyk-bot
- tukeJonny (first-time contributor)

[#57339]: https://github.com/cockroachdb/cockroach/pull/57339
[#58261]: https://github.com/cockroachdb/cockroach/pull/58261
[#60719]: https://github.com/cockroachdb/cockroach/pull/60719
[#61531]: https://github.com/cockroachdb/cockroach/pull/61531
[#63416]: https://github.com/cockroachdb/cockroach/pull/63416
[#63996]: https://github.com/cockroachdb/cockroach/pull/63996
[#64503]: https://github.com/cockroachdb/cockroach/pull/64503
[#65599]: https://github.com/cockroachdb/cockroach/pull/65599
[#66903]: https://github.com/cockroachdb/cockroach/pull/66903
[#67106]: https://github.com/cockroachdb/cockroach/pull/67106
[#67501]: https://github.com/cockroachdb/cockroach/pull/67501
[#67737]: https://github.com/cockroachdb/cockroach/pull/67737
[#68019]: https://github.com/cockroachdb/cockroach/pull/68019
[#68140]: https://github.com/cockroachdb/cockroach/pull/68140
[#68255]: https://github.com/cockroachdb/cockroach/pull/68255
[#68282]: https://github.com/cockroachdb/cockroach/pull/68282
[#68488]: https://github.com/cockroachdb/cockroach/pull/68488
[#68535]: https://github.com/cockroachdb/cockroach/pull/68535
[#68705]: https://github.com/cockroachdb/cockroach/pull/68705
[#68740]: https://github.com/cockroachdb/cockroach/pull/68740
[#68964]: https://github.com/cockroachdb/cockroach/pull/68964
[#69215]: https://github.com/cockroachdb/cockroach/pull/69215
[#69292]: https://github.com/cockroachdb/cockroach/pull/69292
[#69293]: https://github.com/cockroachdb/cockroach/pull/69293
[#69300]: https://github.com/cockroachdb/cockroach/pull/69300
[#69314]: https://github.com/cockroachdb/cockroach/pull/69314
[#69443]: https://github.com/cockroachdb/cockroach/pull/69443
[#69486]: https://github.com/cockroachdb/cockroach/pull/69486
[#69603]: https://github.com/cockroachdb/cockroach/pull/69603
[#69609]: https://github.com/cockroachdb/cockroach/pull/69609
[#69655]: https://github.com/cockroachdb/cockroach/pull/69655
[#69715]: https://github.com/cockroachdb/cockroach/pull/69715
[#69723]: https://github.com/cockroachdb/cockroach/pull/69723
[#69779]: https://github.com/cockroachdb/cockroach/pull/69779
[#69783]: https://github.com/cockroachdb/cockroach/pull/69783
[#69789]: https://github.com/cockroachdb/cockroach/pull/69789
[#69816]: https://github.com/cockroachdb/cockroach/pull/69816
[#69824]: https://github.com/cockroachdb/cockroach/pull/69824
[#69903]: https://github.com/cockroachdb/cockroach/pull/69903
[#69909]: https://github.com/cockroachdb/cockroach/pull/69909
[#69911]: https://github.com/cockroachdb/cockroach/pull/69911
[#69913]: https://github.com/cockroachdb/cockroach/pull/69913
[#69933]: https://github.com/cockroachdb/cockroach/pull/69933
[#69936]: https://github.com/cockroachdb/cockroach/pull/69936
[#69939]: https://github.com/cockroachdb/cockroach/pull/69939
[#69945]: https://github.com/cockroachdb/cockroach/pull/69945
[#69955]: https://github.com/cockroachdb/cockroach/pull/69955
[#69958]: https://github.com/cockroachdb/cockroach/pull/69958
[#69975]: https://github.com/cockroachdb/cockroach/pull/69975
[#69976]: https://github.com/cockroachdb/cockroach/pull/69976
[#69981]: https://github.com/cockroachdb/cockroach/pull/69981
[#69983]: https://github.com/cockroachdb/cockroach/pull/69983
[#70017]: https://github.com/cockroachdb/cockroach/pull/70017
[#70034]: https://github.com/cockroachdb/cockroach/pull/70034
[#70038]: https://github.com/cockroachdb/cockroach/pull/70038
[#70039]: https://github.com/cockroachdb/cockroach/pull/70039
[#70041]: https://github.com/cockroachdb/cockroach/pull/70041
[#70043]: https://github.com/cockroachdb/cockroach/pull/70043
[#70047]: https://github.com/cockroachdb/cockroach/pull/70047
[#70051]: https://github.com/cockroachdb/cockroach/pull/70051
[#70052]: https://github.com/cockroachdb/cockroach/pull/70052
[#70053]: https://github.com/cockroachdb/cockroach/pull/70053
[#70065]: https://github.com/cockroachdb/cockroach/pull/70065
[#70066]: https://github.com/cockroachdb/cockroach/pull/70066
[#70096]: https://github.com/cockroachdb/cockroach/pull/70096
[#70100]: https://github.com/cockroachdb/cockroach/pull/70100
[#70115]: https://github.com/cockroachdb/cockroach/pull/70115
[#70120]: https://github.com/cockroachdb/cockroach/pull/70120
[#70121]: https://github.com/cockroachdb/cockroach/pull/70121
[#70162]: https://github.com/cockroachdb/cockroach/pull/70162
[#70200]: https://github.com/cockroachdb/cockroach/pull/70200
[#70207]: https://github.com/cockroachdb/cockroach/pull/70207
[#70218]: https://github.com/cockroachdb/cockroach/pull/70218
[#70222]: https://github.com/cockroachdb/cockroach/pull/70222
[#70226]: https://github.com/cockroachdb/cockroach/pull/70226
[#70229]: https://github.com/cockroachdb/cockroach/pull/70229
[#70238]: https://github.com/cockroachdb/cockroach/pull/70238
[#70242]: https://github.com/cockroachdb/cockroach/pull/70242
[#70251]: https://github.com/cockroachdb/cockroach/pull/70251
[#70261]: https://github.com/cockroachdb/cockroach/pull/70261
[#70262]: https://github.com/cockroachdb/cockroach/pull/70262
[#70269]: https://github.com/cockroachdb/cockroach/pull/70269
[#70281]: https://github.com/cockroachdb/cockroach/pull/70281
[#70282]: https://github.com/cockroachdb/cockroach/pull/70282
[#70285]: https://github.com/cockroachdb/cockroach/pull/70285
[#70323]: https://github.com/cockroachdb/cockroach/pull/70323
[#70326]: https://github.com/cockroachdb/cockroach/pull/70326
[#70330]: https://github.com/cockroachdb/cockroach/pull/70330
[#70332]: https://github.com/cockroachdb/cockroach/pull/70332
[#70334]: https://github.com/cockroachdb/cockroach/pull/70334
[#70338]: https://github.com/cockroachdb/cockroach/pull/70338
[#70346]: https://github.com/cockroachdb/cockroach/pull/70346
[#70347]: https://github.com/cockroachdb/cockroach/pull/70347
[#70355]: https://github.com/cockroachdb/cockroach/pull/70355
[#70363]: https://github.com/cockroachdb/cockroach/pull/70363
[#70369]: https://github.com/cockroachdb/cockroach/pull/70369
[#70374]: https://github.com/cockroachdb/cockroach/pull/70374
[#70375]: https://github.com/cockroachdb/cockroach/pull/70375
[#70377]: https://github.com/cockroachdb/cockroach/pull/70377
[#70382]: https://github.com/cockroachdb/cockroach/pull/70382
[#70388]: https://github.com/cockroachdb/cockroach/pull/70388
[#70423]: https://github.com/cockroachdb/cockroach/pull/70423
[#70439]: https://github.com/cockroachdb/cockroach/pull/70439
[#70444]: https://github.com/cockroachdb/cockroach/pull/70444
[#70454]: https://github.com/cockroachdb/cockroach/pull/70454
[#70466]: https://github.com/cockroachdb/cockroach/pull/70466
[#70472]: https://github.com/cockroachdb/cockroach/pull/70472
[#70496]: https://github.com/cockroachdb/cockroach/pull/70496
[#70498]: https://github.com/cockroachdb/cockroach/pull/70498
[#70513]: https://github.com/cockroachdb/cockroach/pull/70513
[#70522]: https://github.com/cockroachdb/cockroach/pull/70522
[#70528]: https://github.com/cockroachdb/cockroach/pull/70528
[#70533]: https://github.com/cockroachdb/cockroach/pull/70533
[#70534]: https://github.com/cockroachdb/cockroach/pull/70534
[#70568]: https://github.com/cockroachdb/cockroach/pull/70568
[#70581]: https://github.com/cockroachdb/cockroach/pull/70581
[#70586]: https://github.com/cockroachdb/cockroach/pull/70586
[#70590]: https://github.com/cockroachdb/cockroach/pull/70590
[#70591]: https://github.com/cockroachdb/cockroach/pull/70591
[#70593]: https://github.com/cockroachdb/cockroach/pull/70593
[#70594]: https://github.com/cockroachdb/cockroach/pull/70594
[#70600]: https://github.com/cockroachdb/cockroach/pull/70600
[#70601]: https://github.com/cockroachdb/cockroach/pull/70601
[#70604]: https://github.com/cockroachdb/cockroach/pull/70604
[#70609]: https://github.com/cockroachdb/cockroach/pull/70609
[#70612]: https://github.com/cockroachdb/cockroach/pull/70612
[#70618]: https://github.com/cockroachdb/cockroach/pull/70618
[#70630]: https://github.com/cockroachdb/cockroach/pull/70630
[#70639]: https://github.com/cockroachdb/cockroach/pull/70639
[#70642]: https://github.com/cockroachdb/cockroach/pull/70642
[#70648]: https://github.com/cockroachdb/cockroach/pull/70648
[#70654]: https://github.com/cockroachdb/cockroach/pull/70654
[#70656]: https://github.com/cockroachdb/cockroach/pull/70656
[#70658]: https://github.com/cockroachdb/cockroach/pull/70658
[#70671]: https://github.com/cockroachdb/cockroach/pull/70671
[#70673]: https://github.com/cockroachdb/cockroach/pull/70673
[#70693]: https://github.com/cockroachdb/cockroach/pull/70693
[#70716]: https://github.com/cockroachdb/cockroach/pull/70716
[#70721]: https://github.com/cockroachdb/cockroach/pull/70721
[#70722]: https://github.com/cockroachdb/cockroach/pull/70722
[#70726]: https://github.com/cockroachdb/cockroach/pull/70726
[#70729]: https://github.com/cockroachdb/cockroach/pull/70729
[#70766]: https://github.com/cockroachdb/cockroach/pull/70766
[#70785]: https://github.com/cockroachdb/cockroach/pull/70785
[#70786]: https://github.com/cockroachdb/cockroach/pull/70786
[#70788]: https://github.com/cockroachdb/cockroach/pull/70788
[#70792]: https://github.com/cockroachdb/cockroach/pull/70792
[#70799]: https://github.com/cockroachdb/cockroach/pull/70799
[#70808]: https://github.com/cockroachdb/cockroach/pull/70808
[#70838]: https://github.com/cockroachdb/cockroach/pull/70838
[#70842]: https://github.com/cockroachdb/cockroach/pull/70842
[#70854]: https://github.com/cockroachdb/cockroach/pull/70854
[#70856]: https://github.com/cockroachdb/cockroach/pull/70856
[#70865]: https://github.com/cockroachdb/cockroach/pull/70865
[#70881]: https://github.com/cockroachdb/cockroach/pull/70881
[#70932]: https://github.com/cockroachdb/cockroach/pull/70932
[#70942]: https://github.com/cockroachdb/cockroach/pull/70942
[#70948]: https://github.com/cockroachdb/cockroach/pull/70948
[#70955]: https://github.com/cockroachdb/cockroach/pull/70955
[#70959]: https://github.com/cockroachdb/cockroach/pull/70959
[#70966]: https://github.com/cockroachdb/cockroach/pull/70966
[#70972]: https://github.com/cockroachdb/cockroach/pull/70972
[#70976]: https://github.com/cockroachdb/cockroach/pull/70976
[#70994]: https://github.com/cockroachdb/cockroach/pull/70994
[#70999]: https://github.com/cockroachdb/cockroach/pull/70999
[#71003]: https://github.com/cockroachdb/cockroach/pull/71003
[#71011]: https://github.com/cockroachdb/cockroach/pull/71011
[#71012]: https://github.com/cockroachdb/cockroach/pull/71012
[#71013]: https://github.com/cockroachdb/cockroach/pull/71013
[#71016]: https://github.com/cockroachdb/cockroach/pull/71016
[#71026]: https://github.com/cockroachdb/cockroach/pull/71026
[#71027]: https://github.com/cockroachdb/cockroach/pull/71027
[#71035]: https://github.com/cockroachdb/cockroach/pull/71035
[#71040]: https://github.com/cockroachdb/cockroach/pull/71040
[#71055]: https://github.com/cockroachdb/cockroach/pull/71055
[#71058]: https://github.com/cockroachdb/cockroach/pull/71058
[#71062]: https://github.com/cockroachdb/cockroach/pull/71062
[#71069]: https://github.com/cockroachdb/cockroach/pull/71069
[#71083]: https://github.com/cockroachdb/cockroach/pull/71083
[#71097]: https://github.com/cockroachdb/cockroach/pull/71097
[#71105]: https://github.com/cockroachdb/cockroach/pull/71105
[#71110]: https://github.com/cockroachdb/cockroach/pull/71110
[#71134]: https://github.com/cockroachdb/cockroach/pull/71134
[#71138]: https://github.com/cockroachdb/cockroach/pull/71138
[#71174]: https://github.com/cockroachdb/cockroach/pull/71174
[#71178]: https://github.com/cockroachdb/cockroach/pull/71178
[#71181]: https://github.com/cockroachdb/cockroach/pull/71181
[#71183]: https://github.com/cockroachdb/cockroach/pull/71183
[#71186]: https://github.com/cockroachdb/cockroach/pull/71186
[#71222]: https://github.com/cockroachdb/cockroach/pull/71222
[#71226]: https://github.com/cockroachdb/cockroach/pull/71226
[#71239]: https://github.com/cockroachdb/cockroach/pull/71239
[#71247]: https://github.com/cockroachdb/cockroach/pull/71247
[#71248]: https://github.com/cockroachdb/cockroach/pull/71248
[#71254]: https://github.com/cockroachdb/cockroach/pull/71254
[#71257]: https://github.com/cockroachdb/cockroach/pull/71257
[#71259]: https://github.com/cockroachdb/cockroach/pull/71259
[#71288]: https://github.com/cockroachdb/cockroach/pull/71288
[#71299]: https://github.com/cockroachdb/cockroach/pull/71299
[#71317]: https://github.com/cockroachdb/cockroach/pull/71317
[#71325]: https://github.com/cockroachdb/cockroach/pull/71325
[#71326]: https://github.com/cockroachdb/cockroach/pull/71326
[#71330]: https://github.com/cockroachdb/cockroach/pull/71330
[#71339]: https://github.com/cockroachdb/cockroach/pull/71339
[#71357]: https://github.com/cockroachdb/cockroach/pull/71357
[#71360]: https://github.com/cockroachdb/cockroach/pull/71360
[#71396]: https://github.com/cockroachdb/cockroach/pull/71396
[#71406]: https://github.com/cockroachdb/cockroach/pull/71406
[#71417]: https://github.com/cockroachdb/cockroach/pull/71417
[#71423]: https://github.com/cockroachdb/cockroach/pull/71423
[#71427]: https://github.com/cockroachdb/cockroach/pull/71427
[#71429]: https://github.com/cockroachdb/cockroach/pull/71429
[#71432]: https://github.com/cockroachdb/cockroach/pull/71432
[#71439]: https://github.com/cockroachdb/cockroach/pull/71439
[#71440]: https://github.com/cockroachdb/cockroach/pull/71440
[#71482]: https://github.com/cockroachdb/cockroach/pull/71482
[#71492]: https://github.com/cockroachdb/cockroach/pull/71492
[#71498]: https://github.com/cockroachdb/cockroach/pull/71498
[#71501]: https://github.com/cockroachdb/cockroach/pull/71501
[#71503]: https://github.com/cockroachdb/cockroach/pull/71503
[#71534]: https://github.com/cockroachdb/cockroach/pull/71534
[#71537]: https://github.com/cockroachdb/cockroach/pull/71537
[#71538]: https://github.com/cockroachdb/cockroach/pull/71538
[#71542]: https://github.com/cockroachdb/cockroach/pull/71542
[#71545]: https://github.com/cockroachdb/cockroach/pull/71545
[#71546]: https://github.com/cockroachdb/cockroach/pull/71546
[#71547]: https://github.com/cockroachdb/cockroach/pull/71547
[#71548]: https://github.com/cockroachdb/cockroach/pull/71548
[#71567]: https://github.com/cockroachdb/cockroach/pull/71567
[#71581]: https://github.com/cockroachdb/cockroach/pull/71581
[#71594]: https://github.com/cockroachdb/cockroach/pull/71594
[#71596]: https://github.com/cockroachdb/cockroach/pull/71596
[#71597]: https://github.com/cockroachdb/cockroach/pull/71597
[#71632]: https://github.com/cockroachdb/cockroach/pull/71632
[#71643]: https://github.com/cockroachdb/cockroach/pull/71643
[#71653]: https://github.com/cockroachdb/cockroach/pull/71653
[#71676]: https://github.com/cockroachdb/cockroach/pull/71676
[#71680]: https://github.com/cockroachdb/cockroach/pull/71680
[#71685]: https://github.com/cockroachdb/cockroach/pull/71685
[#71688]: https://github.com/cockroachdb/cockroach/pull/71688
[#71690]: https://github.com/cockroachdb/cockroach/pull/71690
[#71740]: https://github.com/cockroachdb/cockroach/pull/71740
[#71749]: https://github.com/cockroachdb/cockroach/pull/71749
[#71758]: https://github.com/cockroachdb/cockroach/pull/71758
[#71772]: https://github.com/cockroachdb/cockroach/pull/71772
[#71780]: https://github.com/cockroachdb/cockroach/pull/71780
[#71787]: https://github.com/cockroachdb/cockroach/pull/71787
[#71810]: https://github.com/cockroachdb/cockroach/pull/71810
[#71814]: https://github.com/cockroachdb/cockroach/pull/71814
[#71817]: https://github.com/cockroachdb/cockroach/pull/71817
[#71823]: https://github.com/cockroachdb/cockroach/pull/71823
[#71846]: https://github.com/cockroachdb/cockroach/pull/71846
[#71848]: https://github.com/cockroachdb/cockroach/pull/71848
[#71868]: https://github.com/cockroachdb/cockroach/pull/71868
[#71871]: https://github.com/cockroachdb/cockroach/pull/71871
[#71873]: https://github.com/cockroachdb/cockroach/pull/71873
[#71882]: https://github.com/cockroachdb/cockroach/pull/71882
[#71890]: https://github.com/cockroachdb/cockroach/pull/71890
[#71896]: https://github.com/cockroachdb/cockroach/pull/71896
[#71897]: https://github.com/cockroachdb/cockroach/pull/71897
[#71909]: https://github.com/cockroachdb/cockroach/pull/71909
[#71915]: https://github.com/cockroachdb/cockroach/pull/71915
[#71916]: https://github.com/cockroachdb/cockroach/pull/71916
[#71940]: https://github.com/cockroachdb/cockroach/pull/71940
[#71943]: https://github.com/cockroachdb/cockroach/pull/71943
[#71950]: https://github.com/cockroachdb/cockroach/pull/71950
[#71960]: https://github.com/cockroachdb/cockroach/pull/71960
[#71962]: https://github.com/cockroachdb/cockroach/pull/71962
[#71966]: https://github.com/cockroachdb/cockroach/pull/71966
[#71967]: https://github.com/cockroachdb/cockroach/pull/71967
[#71971]: https://github.com/cockroachdb/cockroach/pull/71971
[#71985]: https://github.com/cockroachdb/cockroach/pull/71985
[#71988]: https://github.com/cockroachdb/cockroach/pull/71988
[#72000]: https://github.com/cockroachdb/cockroach/pull/72000
[#72010]: https://github.com/cockroachdb/cockroach/pull/72010
[#72014]: https://github.com/cockroachdb/cockroach/pull/72014
[#72015]: https://github.com/cockroachdb/cockroach/pull/72015
[#72016]: https://github.com/cockroachdb/cockroach/pull/72016
[#72040]: https://github.com/cockroachdb/cockroach/pull/72040
[#72042]: https://github.com/cockroachdb/cockroach/pull/72042
[#72055]: https://github.com/cockroachdb/cockroach/pull/72055
[#72056]: https://github.com/cockroachdb/cockroach/pull/72056
[#72057]: https://github.com/cockroachdb/cockroach/pull/72057
[#72071]: https://github.com/cockroachdb/cockroach/pull/72071
[#72109]: https://github.com/cockroachdb/cockroach/pull/72109
[#72111]: https://github.com/cockroachdb/cockroach/pull/72111
[#72113]: https://github.com/cockroachdb/cockroach/pull/72113
[#72123]: https://github.com/cockroachdb/cockroach/pull/72123
[#72136]: https://github.com/cockroachdb/cockroach/pull/72136
[#72161]: https://github.com/cockroachdb/cockroach/pull/72161
[#72238]: https://github.com/cockroachdb/cockroach/pull/72238
[#72276]: https://github.com/cockroachdb/cockroach/pull/72276
[#72278]: https://github.com/cockroachdb/cockroach/pull/72278
[#72291]: https://github.com/cockroachdb/cockroach/pull/72291
[#72293]: https://github.com/cockroachdb/cockroach/pull/72293
[#72296]: https://github.com/cockroachdb/cockroach/pull/72296
[#72297]: https://github.com/cockroachdb/cockroach/pull/72297
[#72305]: https://github.com/cockroachdb/cockroach/pull/72305
[#72323]: https://github.com/cockroachdb/cockroach/pull/72323
[#72327]: https://github.com/cockroachdb/cockroach/pull/72327
[#72330]: https://github.com/cockroachdb/cockroach/pull/72330
[#72365]: https://github.com/cockroachdb/cockroach/pull/72365
[#72395]: https://github.com/cockroachdb/cockroach/pull/72395
[#72406]: https://github.com/cockroachdb/cockroach/pull/72406
[#72409]: https://github.com/cockroachdb/cockroach/pull/72409
[#72416]: https://github.com/cockroachdb/cockroach/pull/72416
[#72431]: https://github.com/cockroachdb/cockroach/pull/72431
[#72435]: https://github.com/cockroachdb/cockroach/pull/72435
[#72443]: https://github.com/cockroachdb/cockroach/pull/72443
[#72490]: https://github.com/cockroachdb/cockroach/pull/72490
[#72502]: https://github.com/cockroachdb/cockroach/pull/72502
[#72516]: https://github.com/cockroachdb/cockroach/pull/72516
[#72530]: https://github.com/cockroachdb/cockroach/pull/72530
[#72534]: https://github.com/cockroachdb/cockroach/pull/72534
[#72545]: https://github.com/cockroachdb/cockroach/pull/72545
[#72579]: https://github.com/cockroachdb/cockroach/pull/72579
[#72584]: https://github.com/cockroachdb/cockroach/pull/72584
[#72587]: https://github.com/cockroachdb/cockroach/pull/72587
[#72595]: https://github.com/cockroachdb/cockroach/pull/72595
[#72659]: https://github.com/cockroachdb/cockroach/pull/72659
[#72660]: https://github.com/cockroachdb/cockroach/pull/72660
[#72665]: https://github.com/cockroachdb/cockroach/pull/72665
[#72667]: https://github.com/cockroachdb/cockroach/pull/72667
[#72670]: https://github.com/cockroachdb/cockroach/pull/72670
[#72677]: https://github.com/cockroachdb/cockroach/pull/72677
[#72679]: https://github.com/cockroachdb/cockroach/pull/72679
[#72689]: https://github.com/cockroachdb/cockroach/pull/72689
[#72713]: https://github.com/cockroachdb/cockroach/pull/72713
[#72734]: https://github.com/cockroachdb/cockroach/pull/72734
[#72738]: https://github.com/cockroachdb/cockroach/pull/72738
[#72750]: https://github.com/cockroachdb/cockroach/pull/72750
[#72767]: https://github.com/cockroachdb/cockroach/pull/72767
[#72770]: https://github.com/cockroachdb/cockroach/pull/72770
[#72777]: https://github.com/cockroachdb/cockroach/pull/72777
[#72780]: https://github.com/cockroachdb/cockroach/pull/72780
[#72837]: https://github.com/cockroachdb/cockroach/pull/72837
[#72848]: https://github.com/cockroachdb/cockroach/pull/72848
[#72871]: https://github.com/cockroachdb/cockroach/pull/72871
[#72892]: https://github.com/cockroachdb/cockroach/pull/72892
[#72894]: https://github.com/cockroachdb/cockroach/pull/72894
[#72895]: https://github.com/cockroachdb/cockroach/pull/72895
[#72902]: https://github.com/cockroachdb/cockroach/pull/72902
[#72908]: https://github.com/cockroachdb/cockroach/pull/72908
[#72925]: https://github.com/cockroachdb/cockroach/pull/72925
[#72948]: https://github.com/cockroachdb/cockroach/pull/72948
[#72961]: https://github.com/cockroachdb/cockroach/pull/72961
[#72962]: https://github.com/cockroachdb/cockroach/pull/72962
[#72966]: https://github.com/cockroachdb/cockroach/pull/72966
[#72987]: https://github.com/cockroachdb/cockroach/pull/72987
[#72991]: https://github.com/cockroachdb/cockroach/pull/72991
[#72992]: https://github.com/cockroachdb/cockroach/pull/72992
[#73023]: https://github.com/cockroachdb/cockroach/pull/73023
[#73040]: https://github.com/cockroachdb/cockroach/pull/73040
[#73055]: https://github.com/cockroachdb/cockroach/pull/73055
[#73062]: https://github.com/cockroachdb/cockroach/pull/73062
[#73064]: https://github.com/cockroachdb/cockroach/pull/73064
[#73090]: https://github.com/cockroachdb/cockroach/pull/73090
[#73095]: https://github.com/cockroachdb/cockroach/pull/73095
[#73114]: https://github.com/cockroachdb/cockroach/pull/73114
[#73125]: https://github.com/cockroachdb/cockroach/pull/73125
[#73139]: https://github.com/cockroachdb/cockroach/pull/73139
[#73178]: https://github.com/cockroachdb/cockroach/pull/73178
[#73244]: https://github.com/cockroachdb/cockroach/pull/73244
[#73253]: https://github.com/cockroachdb/cockroach/pull/73253
[#73260]: https://github.com/cockroachdb/cockroach/pull/73260
[#73272]: https://github.com/cockroachdb/cockroach/pull/73272
[#73278]: https://github.com/cockroachdb/cockroach/pull/73278
[#73279]: https://github.com/cockroachdb/cockroach/pull/73279
[#73286]: https://github.com/cockroachdb/cockroach/pull/73286
[#73288]: https://github.com/cockroachdb/cockroach/pull/73288
[#73302]: https://github.com/cockroachdb/cockroach/pull/73302
[#73303]: https://github.com/cockroachdb/cockroach/pull/73303
[#73306]: https://github.com/cockroachdb/cockroach/pull/73306
[#73319]: https://github.com/cockroachdb/cockroach/pull/73319
[#73321]: https://github.com/cockroachdb/cockroach/pull/73321
[#73340]: https://github.com/cockroachdb/cockroach/pull/73340
[#73342]: https://github.com/cockroachdb/cockroach/pull/73342
[#73344]: https://github.com/cockroachdb/cockroach/pull/73344
[#73346]: https://github.com/cockroachdb/cockroach/pull/73346
[#73357]: https://github.com/cockroachdb/cockroach/pull/73357
[#73362]: https://github.com/cockroachdb/cockroach/pull/73362
[#73367]: https://github.com/cockroachdb/cockroach/pull/73367
[#73380]: https://github.com/cockroachdb/cockroach/pull/73380
[#73382]: https://github.com/cockroachdb/cockroach/pull/73382
[#73388]: https://github.com/cockroachdb/cockroach/pull/73388
[#73392]: https://github.com/cockroachdb/cockroach/pull/73392
[#73447]: https://github.com/cockroachdb/cockroach/pull/73447
[#73455]: https://github.com/cockroachdb/cockroach/pull/73455
[#73459]: https://github.com/cockroachdb/cockroach/pull/73459
[#73460]: https://github.com/cockroachdb/cockroach/pull/73460
[#73461]: https://github.com/cockroachdb/cockroach/pull/73461
[#73473]: https://github.com/cockroachdb/cockroach/pull/73473
[#73488]: https://github.com/cockroachdb/cockroach/pull/73488
[#73489]: https://github.com/cockroachdb/cockroach/pull/73489
[#73491]: https://github.com/cockroachdb/cockroach/pull/73491
[#73494]: https://github.com/cockroachdb/cockroach/pull/73494
[#73522]: https://github.com/cockroachdb/cockroach/pull/73522
[#73528]: https://github.com/cockroachdb/cockroach/pull/73528
[#73532]: https://github.com/cockroachdb/cockroach/pull/73532
[#73557]: https://github.com/cockroachdb/cockroach/pull/73557
[#73576]: https://github.com/cockroachdb/cockroach/pull/73576
[#73577]: https://github.com/cockroachdb/cockroach/pull/73577
[#73578]: https://github.com/cockroachdb/cockroach/pull/73578
[#73591]: https://github.com/cockroachdb/cockroach/pull/73591
[#73608]: https://github.com/cockroachdb/cockroach/pull/73608
[#73630]: https://github.com/cockroachdb/cockroach/pull/73630
[#73635]: https://github.com/cockroachdb/cockroach/pull/73635
[#73642]: https://github.com/cockroachdb/cockroach/pull/73642
[#73647]: https://github.com/cockroachdb/cockroach/pull/73647
[#73648]: https://github.com/cockroachdb/cockroach/pull/73648
[#73697]: https://github.com/cockroachdb/cockroach/pull/73697
[#73700]: https://github.com/cockroachdb/cockroach/pull/73700
[#73702]: https://github.com/cockroachdb/cockroach/pull/73702
[#73703]: https://github.com/cockroachdb/cockroach/pull/73703
[#73705]: https://github.com/cockroachdb/cockroach/pull/73705
[#73712]: https://github.com/cockroachdb/cockroach/pull/73712
[#73718]: https://github.com/cockroachdb/cockroach/pull/73718
[#73725]: https://github.com/cockroachdb/cockroach/pull/73725
[#73734]: https://github.com/cockroachdb/cockroach/pull/73734
[#73735]: https://github.com/cockroachdb/cockroach/pull/73735
[#73744]: https://github.com/cockroachdb/cockroach/pull/73744
[#73762]: https://github.com/cockroachdb/cockroach/pull/73762
[#73776]: https://github.com/cockroachdb/cockroach/pull/73776
[#73802]: https://github.com/cockroachdb/cockroach/pull/73802
[#73803]: https://github.com/cockroachdb/cockroach/pull/73803
[#73807]: https://github.com/cockroachdb/cockroach/pull/73807
[#73832]: https://github.com/cockroachdb/cockroach/pull/73832
[#73853]: https://github.com/cockroachdb/cockroach/pull/73853
[#73875]: https://github.com/cockroachdb/cockroach/pull/73875
[#73877]: https://github.com/cockroachdb/cockroach/pull/73877
[#73886]: https://github.com/cockroachdb/cockroach/pull/73886
[#73887]: https://github.com/cockroachdb/cockroach/pull/73887
[#73904]: https://github.com/cockroachdb/cockroach/pull/73904
[#73910]: https://github.com/cockroachdb/cockroach/pull/73910
[#73917]: https://github.com/cockroachdb/cockroach/pull/73917
[#73922]: https://github.com/cockroachdb/cockroach/pull/73922
[#73924]: https://github.com/cockroachdb/cockroach/pull/73924
[#73928]: https://github.com/cockroachdb/cockroach/pull/73928
[#73935]: https://github.com/cockroachdb/cockroach/pull/73935
[#73943]: https://github.com/cockroachdb/cockroach/pull/73943
[#73960]: https://github.com/cockroachdb/cockroach/pull/73960
[#73975]: https://github.com/cockroachdb/cockroach/pull/73975
[#73978]: https://github.com/cockroachdb/cockroach/pull/73978
[#73986]: https://github.com/cockroachdb/cockroach/pull/73986
[#73991]: https://github.com/cockroachdb/cockroach/pull/73991
[#73995]: https://github.com/cockroachdb/cockroach/pull/73995
[#74005]: https://github.com/cockroachdb/cockroach/pull/74005
[#74006]: https://github.com/cockroachdb/cockroach/pull/74006
[#74073]: https://github.com/cockroachdb/cockroach/pull/74073
[#74076]: https://github.com/cockroachdb/cockroach/pull/74076
[#74077]: https://github.com/cockroachdb/cockroach/pull/74077
[#74082]: https://github.com/cockroachdb/cockroach/pull/74082
[#74102]: https://github.com/cockroachdb/cockroach/pull/74102
[#74108]: https://github.com/cockroachdb/cockroach/pull/74108
[#74109]: https://github.com/cockroachdb/cockroach/pull/74109
[#74112]: https://github.com/cockroachdb/cockroach/pull/74112
[#74115]: https://github.com/cockroachdb/cockroach/pull/74115
[#74136]: https://github.com/cockroachdb/cockroach/pull/74136
[#74138]: https://github.com/cockroachdb/cockroach/pull/74138
[#74140]: https://github.com/cockroachdb/cockroach/pull/74140
[#74156]: https://github.com/cockroachdb/cockroach/pull/74156
[#74157]: https://github.com/cockroachdb/cockroach/pull/74157
[#74163]: https://github.com/cockroachdb/cockroach/pull/74163
[#74174]: https://github.com/cockroachdb/cockroach/pull/74174
[#74179]: https://github.com/cockroachdb/cockroach/pull/74179
[#74189]: https://github.com/cockroachdb/cockroach/pull/74189
[#74210]: https://github.com/cockroachdb/cockroach/pull/74210
[#74222]: https://github.com/cockroachdb/cockroach/pull/74222
[#74225]: https://github.com/cockroachdb/cockroach/pull/74225
[#74236]: https://github.com/cockroachdb/cockroach/pull/74236
[#74242]: https://github.com/cockroachdb/cockroach/pull/74242
[#74245]: https://github.com/cockroachdb/cockroach/pull/74245
[#74253]: https://github.com/cockroachdb/cockroach/pull/74253
[#74281]: https://github.com/cockroachdb/cockroach/pull/74281
[#74286]: https://github.com/cockroachdb/cockroach/pull/74286
[#74288]: https://github.com/cockroachdb/cockroach/pull/74288
[#74301]: https://github.com/cockroachdb/cockroach/pull/74301
[#74303]: https://github.com/cockroachdb/cockroach/pull/74303
[#74319]: https://github.com/cockroachdb/cockroach/pull/74319
[#74336]: https://github.com/cockroachdb/cockroach/pull/74336
[#74337]: https://github.com/cockroachdb/cockroach/pull/74337
[#74338]: https://github.com/cockroachdb/cockroach/pull/74338
[#74339]: https://github.com/cockroachdb/cockroach/pull/74339
[#74340]: https://github.com/cockroachdb/cockroach/pull/74340
[#74341]: https://github.com/cockroachdb/cockroach/pull/74341
[#74342]: https://github.com/cockroachdb/cockroach/pull/74342
[#74343]: https://github.com/cockroachdb/cockroach/pull/74343
[#74344]: https://github.com/cockroachdb/cockroach/pull/74344
[#74345]: https://github.com/cockroachdb/cockroach/pull/74345
[#74346]: https://github.com/cockroachdb/cockroach/pull/74346
[#74347]: https://github.com/cockroachdb/cockroach/pull/74347
[#74348]: https://github.com/cockroachdb/cockroach/pull/74348
[#74350]: https://github.com/cockroachdb/cockroach/pull/74350
[#74351]: https://github.com/cockroachdb/cockroach/pull/74351
[#74353]: https://github.com/cockroachdb/cockroach/pull/74353
[#74354]: https://github.com/cockroachdb/cockroach/pull/74354
[#74355]: https://github.com/cockroachdb/cockroach/pull/74355
[#74356]: https://github.com/cockroachdb/cockroach/pull/74356
[#74358]: https://github.com/cockroachdb/cockroach/pull/74358
[#74365]: https://github.com/cockroachdb/cockroach/pull/74365
[#74393]: https://github.com/cockroachdb/cockroach/pull/74393
[#74394]: https://github.com/cockroachdb/cockroach/pull/74394
[#74408]: https://github.com/cockroachdb/cockroach/pull/74408
[#74411]: https://github.com/cockroachdb/cockroach/pull/74411
[#74425]: https://github.com/cockroachdb/cockroach/pull/74425
[#74431]: https://github.com/cockroachdb/cockroach/pull/74431
[#74491]: https://github.com/cockroachdb/cockroach/pull/74491
[#74499]: https://github.com/cockroachdb/cockroach/pull/74499
[#74507]: https://github.com/cockroachdb/cockroach/pull/74507
[#74551]: https://github.com/cockroachdb/cockroach/pull/74551
[#74560]: https://github.com/cockroachdb/cockroach/pull/74560
[#74582]: https://github.com/cockroachdb/cockroach/pull/74582
[#74590]: https://github.com/cockroachdb/cockroach/pull/74590
[#74592]: https://github.com/cockroachdb/cockroach/pull/74592
[#74601]: https://github.com/cockroachdb/cockroach/pull/74601
[#74628]: https://github.com/cockroachdb/cockroach/pull/74628
[#74645]: https://github.com/cockroachdb/cockroach/pull/74645
[#74655]: https://github.com/cockroachdb/cockroach/pull/74655
[#74659]: https://github.com/cockroachdb/cockroach/pull/74659
[#74661]: https://github.com/cockroachdb/cockroach/pull/74661
[#74662]: https://github.com/cockroachdb/cockroach/pull/74662
[#74664]: https://github.com/cockroachdb/cockroach/pull/74664
[#74674]: https://github.com/cockroachdb/cockroach/pull/74674
[#74706]: https://github.com/cockroachdb/cockroach/pull/74706
[#74715]: https://github.com/cockroachdb/cockroach/pull/74715
[#74726]: https://github.com/cockroachdb/cockroach/pull/74726
[#74761]: https://github.com/cockroachdb/cockroach/pull/74761
[#74774]: https://github.com/cockroachdb/cockroach/pull/74774
[#74821]: https://github.com/cockroachdb/cockroach/pull/74821
[#74825]: https://github.com/cockroachdb/cockroach/pull/74825
[#74828]: https://github.com/cockroachdb/cockroach/pull/74828
[#74831]: https://github.com/cockroachdb/cockroach/pull/74831
[#74840]: https://github.com/cockroachdb/cockroach/pull/74840
[#74863]: https://github.com/cockroachdb/cockroach/pull/74863
[#74867]: https://github.com/cockroachdb/cockroach/pull/74867
[#74869]: https://github.com/cockroachdb/cockroach/pull/74869
[#74877]: https://github.com/cockroachdb/cockroach/pull/74877
[#74881]: https://github.com/cockroachdb/cockroach/pull/74881
[#74882]: https://github.com/cockroachdb/cockroach/pull/74882
[#74905]: https://github.com/cockroachdb/cockroach/pull/74905
[#74914]: https://github.com/cockroachdb/cockroach/pull/74914
[#74916]: https://github.com/cockroachdb/cockroach/pull/74916
[#74920]: https://github.com/cockroachdb/cockroach/pull/74920
[#74923]: https://github.com/cockroachdb/cockroach/pull/74923
[#74929]: https://github.com/cockroachdb/cockroach/pull/74929
[#75056]: https://github.com/cockroachdb/cockroach/pull/75056
[#75058]: https://github.com/cockroachdb/cockroach/pull/75058
[#75076]: https://github.com/cockroachdb/cockroach/pull/75076
[#75097]: https://github.com/cockroachdb/cockroach/pull/75097
[#75105]: https://github.com/cockroachdb/cockroach/pull/75105
[#75114]: https://github.com/cockroachdb/cockroach/pull/75114
[#75155]: https://github.com/cockroachdb/cockroach/pull/75155
[#75174]: https://github.com/cockroachdb/cockroach/pull/75174
[#75175]: https://github.com/cockroachdb/cockroach/pull/75175
[#75194]: https://github.com/cockroachdb/cockroach/pull/75194
[#75219]: https://github.com/cockroachdb/cockroach/pull/75219
[#75223]: https://github.com/cockroachdb/cockroach/pull/75223
[#75226]: https://github.com/cockroachdb/cockroach/pull/75226
[#75231]: https://github.com/cockroachdb/cockroach/pull/75231
[#75239]: https://github.com/cockroachdb/cockroach/pull/75239
[#75262]: https://github.com/cockroachdb/cockroach/pull/75262
[#75271]: https://github.com/cockroachdb/cockroach/pull/75271
[#75274]: https://github.com/cockroachdb/cockroach/pull/75274
[#75429]: https://github.com/cockroachdb/cockroach/pull/75429
[#75431]: https://github.com/cockroachdb/cockroach/pull/75431
[#75443]: https://github.com/cockroachdb/cockroach/pull/75443
[#75446]: https://github.com/cockroachdb/cockroach/pull/75446
[#75451]: https://github.com/cockroachdb/cockroach/pull/75451
[#75458]: https://github.com/cockroachdb/cockroach/pull/75458
[#75461]: https://github.com/cockroachdb/cockroach/pull/75461
[#75470]: https://github.com/cockroachdb/cockroach/pull/75470
[#75473]: https://github.com/cockroachdb/cockroach/pull/75473
[#75475]: https://github.com/cockroachdb/cockroach/pull/75475
[#75490]: https://github.com/cockroachdb/cockroach/pull/75490
[#75517]: https://github.com/cockroachdb/cockroach/pull/75517
[#75548]: https://github.com/cockroachdb/cockroach/pull/75548
[#75551]: https://github.com/cockroachdb/cockroach/pull/75551
[#75556]: https://github.com/cockroachdb/cockroach/pull/75556
[#75562]: https://github.com/cockroachdb/cockroach/pull/75562
[#75572]: https://github.com/cockroachdb/cockroach/pull/75572
[#75575]: https://github.com/cockroachdb/cockroach/pull/75575
[#75581]: https://github.com/cockroachdb/cockroach/pull/75581
[#75582]: https://github.com/cockroachdb/cockroach/pull/75582
[#75588]: https://github.com/cockroachdb/cockroach/pull/75588
[#75597]: https://github.com/cockroachdb/cockroach/pull/75597
[#75601]: https://github.com/cockroachdb/cockroach/pull/75601
[#75613]: https://github.com/cockroachdb/cockroach/pull/75613
[#75619]: https://github.com/cockroachdb/cockroach/pull/75619
[#75624]: https://github.com/cockroachdb/cockroach/pull/75624
[#75628]: https://github.com/cockroachdb/cockroach/pull/75628
[#75660]: https://github.com/cockroachdb/cockroach/pull/75660
[#75673]: https://github.com/cockroachdb/cockroach/pull/75673
[#75678]: https://github.com/cockroachdb/cockroach/pull/75678
[#75710]: https://github.com/cockroachdb/cockroach/pull/75710
[#75722]: https://github.com/cockroachdb/cockroach/pull/75722
[#75727]: https://github.com/cockroachdb/cockroach/pull/75727
[#75733]: https://github.com/cockroachdb/cockroach/pull/75733
[#75737]: https://github.com/cockroachdb/cockroach/pull/75737
[#75750]: https://github.com/cockroachdb/cockroach/pull/75750
[#75753]: https://github.com/cockroachdb/cockroach/pull/75753
[#75762]: https://github.com/cockroachdb/cockroach/pull/75762
[#75770]: https://github.com/cockroachdb/cockroach/pull/75770
[#75793]: https://github.com/cockroachdb/cockroach/pull/75793
[#75804]: https://github.com/cockroachdb/cockroach/pull/75804
[#75809]: https://github.com/cockroachdb/cockroach/pull/75809
[#75814]: https://github.com/cockroachdb/cockroach/pull/75814
[#75815]: https://github.com/cockroachdb/cockroach/pull/75815
[#75816]: https://github.com/cockroachdb/cockroach/pull/75816
[#75820]: https://github.com/cockroachdb/cockroach/pull/75820
[#75822]: https://github.com/cockroachdb/cockroach/pull/75822
[#75843]: https://github.com/cockroachdb/cockroach/pull/75843
[#75851]: https://github.com/cockroachdb/cockroach/pull/75851
[#75852]: https://github.com/cockroachdb/cockroach/pull/75852
[#75854]: https://github.com/cockroachdb/cockroach/pull/75854
[#75880]: https://github.com/cockroachdb/cockroach/pull/75880
[#75890]: https://github.com/cockroachdb/cockroach/pull/75890
[#75894]: https://github.com/cockroachdb/cockroach/pull/75894
[#75898]: https://github.com/cockroachdb/cockroach/pull/75898
[#75900]: https://github.com/cockroachdb/cockroach/pull/75900
[#75905]: https://github.com/cockroachdb/cockroach/pull/75905
[#75914]: https://github.com/cockroachdb/cockroach/pull/75914
[#75957]: https://github.com/cockroachdb/cockroach/pull/75957
[#75965]: https://github.com/cockroachdb/cockroach/pull/75965
[#75970]: https://github.com/cockroachdb/cockroach/pull/75970
[#75971]: https://github.com/cockroachdb/cockroach/pull/75971
[#75988]: https://github.com/cockroachdb/cockroach/pull/75988
[#75990]: https://github.com/cockroachdb/cockroach/pull/75990
[#76002]: https://github.com/cockroachdb/cockroach/pull/76002
[#76007]: https://github.com/cockroachdb/cockroach/pull/76007
[#76012]: https://github.com/cockroachdb/cockroach/pull/76012
[#76068]: https://github.com/cockroachdb/cockroach/pull/76068
[#76078]: https://github.com/cockroachdb/cockroach/pull/76078
[#76095]: https://github.com/cockroachdb/cockroach/pull/76095
[#76112]: https://github.com/cockroachdb/cockroach/pull/76112
[#76115]: https://github.com/cockroachdb/cockroach/pull/76115
[#76129]: https://github.com/cockroachdb/cockroach/pull/76129
[#76154]: https://github.com/cockroachdb/cockroach/pull/76154
[#76166]: https://github.com/cockroachdb/cockroach/pull/76166
[#76168]: https://github.com/cockroachdb/cockroach/pull/76168
[#76193]: https://github.com/cockroachdb/cockroach/pull/76193
[#76209]: https://github.com/cockroachdb/cockroach/pull/76209
[#76213]: https://github.com/cockroachdb/cockroach/pull/76213
[#76215]: https://github.com/cockroachdb/cockroach/pull/76215
[#76233]: https://github.com/cockroachdb/cockroach/pull/76233
[#76252]: https://github.com/cockroachdb/cockroach/pull/76252
[#76254]: https://github.com/cockroachdb/cockroach/pull/76254
[#76265]: https://github.com/cockroachdb/cockroach/pull/76265
[#76266]: https://github.com/cockroachdb/cockroach/pull/76266
[#76271]: https://github.com/cockroachdb/cockroach/pull/76271
[#76277]: https://github.com/cockroachdb/cockroach/pull/76277
[#76285]: https://github.com/cockroachdb/cockroach/pull/76285
[#76301]: https://github.com/cockroachdb/cockroach/pull/76301
[#76315]: https://github.com/cockroachdb/cockroach/pull/76315
[#76334]: https://github.com/cockroachdb/cockroach/pull/76334
[#76346]: https://github.com/cockroachdb/cockroach/pull/76346
[#76348]: https://github.com/cockroachdb/cockroach/pull/76348
[#76358]: https://github.com/cockroachdb/cockroach/pull/76358
[#76397]: https://github.com/cockroachdb/cockroach/pull/76397
[#76399]: https://github.com/cockroachdb/cockroach/pull/76399
[#76401]: https://github.com/cockroachdb/cockroach/pull/76401
[#76403]: https://github.com/cockroachdb/cockroach/pull/76403
[#76410]: https://github.com/cockroachdb/cockroach/pull/76410
[#76416]: https://github.com/cockroachdb/cockroach/pull/76416
[#76427]: https://github.com/cockroachdb/cockroach/pull/76427
[#76430]: https://github.com/cockroachdb/cockroach/pull/76430
[#76437]: https://github.com/cockroachdb/cockroach/pull/76437
[#76457]: https://github.com/cockroachdb/cockroach/pull/76457
[#76458]: https://github.com/cockroachdb/cockroach/pull/76458
[#76486]: https://github.com/cockroachdb/cockroach/pull/76486
[#76495]: https://github.com/cockroachdb/cockroach/pull/76495
[#76510]: https://github.com/cockroachdb/cockroach/pull/76510
[#76512]: https://github.com/cockroachdb/cockroach/pull/76512
[#76516]: https://github.com/cockroachdb/cockroach/pull/76516
[#76518]: https://github.com/cockroachdb/cockroach/pull/76518
[#76523]: https://github.com/cockroachdb/cockroach/pull/76523
[#76532]: https://github.com/cockroachdb/cockroach/pull/76532
[#76538]: https://github.com/cockroachdb/cockroach/pull/76538
[#76563]: https://github.com/cockroachdb/cockroach/pull/76563
[#76566]: https://github.com/cockroachdb/cockroach/pull/76566
[#76583]: https://github.com/cockroachdb/cockroach/pull/76583
[#76589]: https://github.com/cockroachdb/cockroach/pull/76589
[#76592]: https://github.com/cockroachdb/cockroach/pull/76592
[#76605]: https://github.com/cockroachdb/cockroach/pull/76605
[#76609]: https://github.com/cockroachdb/cockroach/pull/76609
[#76620]: https://github.com/cockroachdb/cockroach/pull/76620
[#76635]: https://github.com/cockroachdb/cockroach/pull/76635
[#76639]: https://github.com/cockroachdb/cockroach/pull/76639
[#76670]: https://github.com/cockroachdb/cockroach/pull/76670
[#76675]: https://github.com/cockroachdb/cockroach/pull/76675
[#76676]: https://github.com/cockroachdb/cockroach/pull/76676
[#76687]: https://github.com/cockroachdb/cockroach/pull/76687
[#76691]: https://github.com/cockroachdb/cockroach/pull/76691
[#76719]: https://github.com/cockroachdb/cockroach/pull/76719
[#76739]: https://github.com/cockroachdb/cockroach/pull/76739
[#76743]: https://github.com/cockroachdb/cockroach/pull/76743
[#76753]: https://github.com/cockroachdb/cockroach/pull/76753
[#76754]: https://github.com/cockroachdb/cockroach/pull/76754
[#76757]: https://github.com/cockroachdb/cockroach/pull/76757
[#76786]: https://github.com/cockroachdb/cockroach/pull/76786
[#76789]: https://github.com/cockroachdb/cockroach/pull/76789
[#76792]: https://github.com/cockroachdb/cockroach/pull/76792
[#76817]: https://github.com/cockroachdb/cockroach/pull/76817
[#76825]: https://github.com/cockroachdb/cockroach/pull/76825
[#76834]: https://github.com/cockroachdb/cockroach/pull/76834
[#76837]: https://github.com/cockroachdb/cockroach/pull/76837
[#76853]: https://github.com/cockroachdb/cockroach/pull/76853
[#76863]: https://github.com/cockroachdb/cockroach/pull/76863
[#76869]: https://github.com/cockroachdb/cockroach/pull/76869
[#76886]: https://github.com/cockroachdb/cockroach/pull/76886
[#76888]: https://github.com/cockroachdb/cockroach/pull/76888
[#76892]: https://github.com/cockroachdb/cockroach/pull/76892
[#76893]: https://github.com/cockroachdb/cockroach/pull/76893
[#76897]: https://github.com/cockroachdb/cockroach/pull/76897
[#76907]: https://github.com/cockroachdb/cockroach/pull/76907
[#76917]: https://github.com/cockroachdb/cockroach/pull/76917
[#76918]: https://github.com/cockroachdb/cockroach/pull/76918
[#76929]: https://github.com/cockroachdb/cockroach/pull/76929
[#76930]: https://github.com/cockroachdb/cockroach/pull/76930
[#76932]: https://github.com/cockroachdb/cockroach/pull/76932
[#76937]: https://github.com/cockroachdb/cockroach/pull/76937
[#76943]: https://github.com/cockroachdb/cockroach/pull/76943
[#76951]: https://github.com/cockroachdb/cockroach/pull/76951
[#76961]: https://github.com/cockroachdb/cockroach/pull/76961
[#76989]: https://github.com/cockroachdb/cockroach/pull/76989
[#76990]: https://github.com/cockroachdb/cockroach/pull/76990
[#76995]: https://github.com/cockroachdb/cockroach/pull/76995
[#77004]: https://github.com/cockroachdb/cockroach/pull/77004
[#77014]: https://github.com/cockroachdb/cockroach/pull/77014
[#77015]: https://github.com/cockroachdb/cockroach/pull/77015
[#77016]: https://github.com/cockroachdb/cockroach/pull/77016
[#77023]: https://github.com/cockroachdb/cockroach/pull/77023
[#77043]: https://github.com/cockroachdb/cockroach/pull/77043
[#77052]: https://github.com/cockroachdb/cockroach/pull/77052
[#77063]: https://github.com/cockroachdb/cockroach/pull/77063
[#77070]: https://github.com/cockroachdb/cockroach/pull/77070
[#77084]: https://github.com/cockroachdb/cockroach/pull/77084
[#77152]: https://github.com/cockroachdb/cockroach/pull/77152
[#77233]: https://github.com/cockroachdb/cockroach/pull/77233
[#77237]: https://github.com/cockroachdb/cockroach/pull/77237
[#77240]: https://github.com/cockroachdb/cockroach/pull/77240
[#77244]: https://github.com/cockroachdb/cockroach/pull/77244
[#77246]: https://github.com/cockroachdb/cockroach/pull/77246
[#77247]: https://github.com/cockroachdb/cockroach/pull/77247
[#77255]: https://github.com/cockroachdb/cockroach/pull/77255
[#77263]: https://github.com/cockroachdb/cockroach/pull/77263
[#77284]: https://github.com/cockroachdb/cockroach/pull/77284
[#77306]: https://github.com/cockroachdb/cockroach/pull/77306
[#77308]: https://github.com/cockroachdb/cockroach/pull/77308
[#77316]: https://github.com/cockroachdb/cockroach/pull/77316
[#77330]: https://github.com/cockroachdb/cockroach/pull/77330
[#77331]: https://github.com/cockroachdb/cockroach/pull/77331
[#77359]: https://github.com/cockroachdb/cockroach/pull/77359
[#77372]: https://github.com/cockroachdb/cockroach/pull/77372
[#77418]: https://github.com/cockroachdb/cockroach/pull/77418
[#77433]: https://github.com/cockroachdb/cockroach/pull/77433
[#77438]: https://github.com/cockroachdb/cockroach/pull/77438
[#77506]: https://github.com/cockroachdb/cockroach/pull/77506
[#77507]: https://github.com/cockroachdb/cockroach/pull/77507
[#77508]: https://github.com/cockroachdb/cockroach/pull/77508
[#77514]: https://github.com/cockroachdb/cockroach/pull/77514
[#77521]: https://github.com/cockroachdb/cockroach/pull/77521
[#77558]: https://github.com/cockroachdb/cockroach/pull/77558
[#77561]: https://github.com/cockroachdb/cockroach/pull/77561
[#77567]: https://github.com/cockroachdb/cockroach/pull/77567
[#77571]: https://github.com/cockroachdb/cockroach/pull/77571
[#77575]: https://github.com/cockroachdb/cockroach/pull/77575
[#77588]: https://github.com/cockroachdb/cockroach/pull/77588
[#77597]: https://github.com/cockroachdb/cockroach/pull/77597
[#77606]: https://github.com/cockroachdb/cockroach/pull/77606
[#77608]: https://github.com/cockroachdb/cockroach/pull/77608
[#77623]: https://github.com/cockroachdb/cockroach/pull/77623
[#77632]: https://github.com/cockroachdb/cockroach/pull/77632
[#77640]: https://github.com/cockroachdb/cockroach/pull/77640
[#77642]: https://github.com/cockroachdb/cockroach/pull/77642
[#77649]: https://github.com/cockroachdb/cockroach/pull/77649
[#77711]: https://github.com/cockroachdb/cockroach/pull/77711
[#77712]: https://github.com/cockroachdb/cockroach/pull/77712
[#77725]: https://github.com/cockroachdb/cockroach/pull/77725
[#77726]: https://github.com/cockroachdb/cockroach/pull/77726
[#77732]: https://github.com/cockroachdb/cockroach/pull/77732
[#77741]: https://github.com/cockroachdb/cockroach/pull/77741
[#77763]: https://github.com/cockroachdb/cockroach/pull/77763
[#77773]: https://github.com/cockroachdb/cockroach/pull/77773
[#77785]: https://github.com/cockroachdb/cockroach/pull/77785
[#77797]: https://github.com/cockroachdb/cockroach/pull/77797
[#77837]: https://github.com/cockroachdb/cockroach/pull/77837
[#77854]: https://github.com/cockroachdb/cockroach/pull/77854
[#77857]: https://github.com/cockroachdb/cockroach/pull/77857
[#77860]: https://github.com/cockroachdb/cockroach/pull/77860
[#77861]: https://github.com/cockroachdb/cockroach/pull/77861
[#77876]: https://github.com/cockroachdb/cockroach/pull/77876
[#77883]: https://github.com/cockroachdb/cockroach/pull/77883
[#77936]: https://github.com/cockroachdb/cockroach/pull/77936
[#77938]: https://github.com/cockroachdb/cockroach/pull/77938
[#77943]: https://github.com/cockroachdb/cockroach/pull/77943
[#77949]: https://github.com/cockroachdb/cockroach/pull/77949
[#77952]: https://github.com/cockroachdb/cockroach/pull/77952
[#77955]: https://github.com/cockroachdb/cockroach/pull/77955
[#77968]: https://github.com/cockroachdb/cockroach/pull/77968
[#77975]: https://github.com/cockroachdb/cockroach/pull/77975
[#77995]: https://github.com/cockroachdb/cockroach/pull/77995
[#78032]: https://github.com/cockroachdb/cockroach/pull/78032
[#78044]: https://github.com/cockroachdb/cockroach/pull/78044
[#78045]: https://github.com/cockroachdb/cockroach/pull/78045
[#78046]: https://github.com/cockroachdb/cockroach/pull/78046
[#78050]: https://github.com/cockroachdb/cockroach/pull/78050
[#78095]: https://github.com/cockroachdb/cockroach/pull/78095
[#78102]: https://github.com/cockroachdb/cockroach/pull/78102
[#78103]: https://github.com/cockroachdb/cockroach/pull/78103
[#78108]: https://github.com/cockroachdb/cockroach/pull/78108
[#78110]: https://github.com/cockroachdb/cockroach/pull/78110
[#78142]: https://github.com/cockroachdb/cockroach/pull/78142
[#78165]: https://github.com/cockroachdb/cockroach/pull/78165
[#78166]: https://github.com/cockroachdb/cockroach/pull/78166
[#78186]: https://github.com/cockroachdb/cockroach/pull/78186
[#78199]: https://github.com/cockroachdb/cockroach/pull/78199
[#78218]: https://github.com/cockroachdb/cockroach/pull/78218
[#78224]: https://github.com/cockroachdb/cockroach/pull/78224
[#78243]: https://github.com/cockroachdb/cockroach/pull/78243
[#78255]: https://github.com/cockroachdb/cockroach/pull/78255
[#78278]: https://github.com/cockroachdb/cockroach/pull/78278
[#78283]: https://github.com/cockroachdb/cockroach/pull/78283
[#78287]: https://github.com/cockroachdb/cockroach/pull/78287
[#78292]: https://github.com/cockroachdb/cockroach/pull/78292
[#78297]: https://github.com/cockroachdb/cockroach/pull/78297
[#78303]: https://github.com/cockroachdb/cockroach/pull/78303
[#78317]: https://github.com/cockroachdb/cockroach/pull/78317
[#78333]: https://github.com/cockroachdb/cockroach/pull/78333
[#78357]: https://github.com/cockroachdb/cockroach/pull/78357
[#78367]: https://github.com/cockroachdb/cockroach/pull/78367
[#78398]: https://github.com/cockroachdb/cockroach/pull/78398
[#78410]: https://github.com/cockroachdb/cockroach/pull/78410
[#78418]: https://github.com/cockroachdb/cockroach/pull/78418
[#78423]: https://github.com/cockroachdb/cockroach/pull/78423
[#78427]: https://github.com/cockroachdb/cockroach/pull/78427
[#78459]: https://github.com/cockroachdb/cockroach/pull/78459
[#78460]: https://github.com/cockroachdb/cockroach/pull/78460
[#78467]: https://github.com/cockroachdb/cockroach/pull/78467
[#78501]: https://github.com/cockroachdb/cockroach/pull/78501
[#78520]: https://github.com/cockroachdb/cockroach/pull/78520
[#78529]: https://github.com/cockroachdb/cockroach/pull/78529
[#78533]: https://github.com/cockroachdb/cockroach/pull/78533
[#78541]: https://github.com/cockroachdb/cockroach/pull/78541
[#78546]: https://github.com/cockroachdb/cockroach/pull/78546
[#78549]: https://github.com/cockroachdb/cockroach/pull/78549
[#78562]: https://github.com/cockroachdb/cockroach/pull/78562
[#78564]: https://github.com/cockroachdb/cockroach/pull/78564
[#78584]: https://github.com/cockroachdb/cockroach/pull/78584
[#78585]: https://github.com/cockroachdb/cockroach/pull/78585
[#78595]: https://github.com/cockroachdb/cockroach/pull/78595
[#78600]: https://github.com/cockroachdb/cockroach/pull/78600
[#78608]: https://github.com/cockroachdb/cockroach/pull/78608
[#78616]: https://github.com/cockroachdb/cockroach/pull/78616
[#78626]: https://github.com/cockroachdb/cockroach/pull/78626
[#78637]: https://github.com/cockroachdb/cockroach/pull/78637
[#78649]: https://github.com/cockroachdb/cockroach/pull/78649
[#78650]: https://github.com/cockroachdb/cockroach/pull/78650
[#78652]: https://github.com/cockroachdb/cockroach/pull/78652
[#78667]: https://github.com/cockroachdb/cockroach/pull/78667
[#78685]: https://github.com/cockroachdb/cockroach/pull/78685
[#78705]: https://github.com/cockroachdb/cockroach/pull/78705
[#78940]: https://github.com/cockroachdb/cockroach/pull/78940
[#78959]: https://github.com/cockroachdb/cockroach/pull/78959
[#78960]: https://github.com/cockroachdb/cockroach/pull/78960
[#78961]: https://github.com/cockroachdb/cockroach/pull/78961
[#78962]: https://github.com/cockroachdb/cockroach/pull/78962
[#78965]: https://github.com/cockroachdb/cockroach/pull/78965
[#78969]: https://github.com/cockroachdb/cockroach/pull/78969
[#78978]: https://github.com/cockroachdb/cockroach/pull/78978
[#78985]: https://github.com/cockroachdb/cockroach/pull/78985
[#78987]: https://github.com/cockroachdb/cockroach/pull/78987
[#78997]: https://github.com/cockroachdb/cockroach/pull/78997
[#79011]: https://github.com/cockroachdb/cockroach/pull/79011
[#79016]: https://github.com/cockroachdb/cockroach/pull/79016
[#79038]: https://github.com/cockroachdb/cockroach/pull/79038
[#79045]: https://github.com/cockroachdb/cockroach/pull/79045
[#79049]: https://github.com/cockroachdb/cockroach/pull/79049
[#79055]: https://github.com/cockroachdb/cockroach/pull/79055
[#79064]: https://github.com/cockroachdb/cockroach/pull/79064
[#79065]: https://github.com/cockroachdb/cockroach/pull/79065
[#79084]: https://github.com/cockroachdb/cockroach/pull/79084
[#79085]: https://github.com/cockroachdb/cockroach/pull/79085
[#79086]: https://github.com/cockroachdb/cockroach/pull/79086
[#79097]: https://github.com/cockroachdb/cockroach/pull/79097
[#79100]: https://github.com/cockroachdb/cockroach/pull/79100
[#79115]: https://github.com/cockroachdb/cockroach/pull/79115
[#79121]: https://github.com/cockroachdb/cockroach/pull/79121
[#79126]: https://github.com/cockroachdb/cockroach/pull/79126
[#79133]: https://github.com/cockroachdb/cockroach/pull/79133
[#79134]: https://github.com/cockroachdb/cockroach/pull/79134
[#79135]: https://github.com/cockroachdb/cockroach/pull/79135
[#79175]: https://github.com/cockroachdb/cockroach/pull/79175
[#79176]: https://github.com/cockroachdb/cockroach/pull/79176
[#79186]: https://github.com/cockroachdb/cockroach/pull/79186
[#79250]: https://github.com/cockroachdb/cockroach/pull/79250
[#79252]: https://github.com/cockroachdb/cockroach/pull/79252
[#79257]: https://github.com/cockroachdb/cockroach/pull/79257
[#79293]: https://github.com/cockroachdb/cockroach/pull/79293
[#79295]: https://github.com/cockroachdb/cockroach/pull/79295
[#79301]: https://github.com/cockroachdb/cockroach/pull/79301
[#79302]: https://github.com/cockroachdb/cockroach/pull/79302
[#79313]: https://github.com/cockroachdb/cockroach/pull/79313
[#79324]: https://github.com/cockroachdb/cockroach/pull/79324
[#79325]: https://github.com/cockroachdb/cockroach/pull/79325
[#79356]: https://github.com/cockroachdb/cockroach/pull/79356
[#79362]: https://github.com/cockroachdb/cockroach/pull/79362
[#79365]: https://github.com/cockroachdb/cockroach/pull/79365
[#79389]: https://github.com/cockroachdb/cockroach/pull/79389
[#79444]: https://github.com/cockroachdb/cockroach/pull/79444
[#79447]: https://github.com/cockroachdb/cockroach/pull/79447
[#79465]: https://github.com/cockroachdb/cockroach/pull/79465
[#79473]: https://github.com/cockroachdb/cockroach/pull/79473
[#79513]: https://github.com/cockroachdb/cockroach/pull/79513
[#79522]: https://github.com/cockroachdb/cockroach/pull/79522
[#79523]: https://github.com/cockroachdb/cockroach/pull/79523
[#79536]: https://github.com/cockroachdb/cockroach/pull/79536
[#79537]: https://github.com/cockroachdb/cockroach/pull/79537
[#79542]: https://github.com/cockroachdb/cockroach/pull/79542
[#79543]: https://github.com/cockroachdb/cockroach/pull/79543
[#79554]: https://github.com/cockroachdb/cockroach/pull/79554
[#79581]: https://github.com/cockroachdb/cockroach/pull/79581
[#79606]: https://github.com/cockroachdb/cockroach/pull/79606
[#79623]: https://github.com/cockroachdb/cockroach/pull/79623
[#79629]: https://github.com/cockroachdb/cockroach/pull/79629
[#79652]: https://github.com/cockroachdb/cockroach/pull/79652
[#79663]: https://github.com/cockroachdb/cockroach/pull/79663
[#79673]: https://github.com/cockroachdb/cockroach/pull/79673
[#79677]: https://github.com/cockroachdb/cockroach/pull/79677
[#79679]: https://github.com/cockroachdb/cockroach/pull/79679
[#79690]: https://github.com/cockroachdb/cockroach/pull/79690
[#79691]: https://github.com/cockroachdb/cockroach/pull/79691
[#79693]: https://github.com/cockroachdb/cockroach/pull/79693
[#79705]: https://github.com/cockroachdb/cockroach/pull/79705
[#79714]: https://github.com/cockroachdb/cockroach/pull/79714
[#79739]: https://github.com/cockroachdb/cockroach/pull/79739
[#79748]: https://github.com/cockroachdb/cockroach/pull/79748
[#79761]: https://github.com/cockroachdb/cockroach/pull/79761
[#79772]: https://github.com/cockroachdb/cockroach/pull/79772
[#79794]: https://github.com/cockroachdb/cockroach/pull/79794
[#79799]: https://github.com/cockroachdb/cockroach/pull/79799
[#79810]: https://github.com/cockroachdb/cockroach/pull/79810
[#79811]: https://github.com/cockroachdb/cockroach/pull/79811
[#79818]: https://github.com/cockroachdb/cockroach/pull/79818
[#79853]: https://github.com/cockroachdb/cockroach/pull/79853
[#79862]: https://github.com/cockroachdb/cockroach/pull/79862
[#79865]: https://github.com/cockroachdb/cockroach/pull/79865
[#79897]: https://github.com/cockroachdb/cockroach/pull/79897
[#79900]: https://github.com/cockroachdb/cockroach/pull/79900
[#79906]: https://github.com/cockroachdb/cockroach/pull/79906
[#79936]: https://github.com/cockroachdb/cockroach/pull/79936
[#79966]: https://github.com/cockroachdb/cockroach/pull/79966
[#79967]: https://github.com/cockroachdb/cockroach/pull/79967
[#79968]: https://github.com/cockroachdb/cockroach/pull/79968
[#79998]: https://github.com/cockroachdb/cockroach/pull/79998
[#80007]: https://github.com/cockroachdb/cockroach/pull/80007
[#80036]: https://github.com/cockroachdb/cockroach/pull/80036
[#80114]: https://github.com/cockroachdb/cockroach/pull/80114
[#80115]: https://github.com/cockroachdb/cockroach/pull/80115
[#80116]: https://github.com/cockroachdb/cockroach/pull/80116
[#80132]: https://github.com/cockroachdb/cockroach/pull/80132
[#80133]: https://github.com/cockroachdb/cockroach/pull/80133
[#80136]: https://github.com/cockroachdb/cockroach/pull/80136
[#80142]: https://github.com/cockroachdb/cockroach/pull/80142
[#80154]: https://github.com/cockroachdb/cockroach/pull/80154
[#80182]: https://github.com/cockroachdb/cockroach/pull/80182
[#80185]: https://github.com/cockroachdb/cockroach/pull/80185
[#80200]: https://github.com/cockroachdb/cockroach/pull/80200
[#80204]: https://github.com/cockroachdb/cockroach/pull/80204
[#80207]: https://github.com/cockroachdb/cockroach/pull/80207
[#80211]: https://github.com/cockroachdb/cockroach/pull/80211
[#80212]: https://github.com/cockroachdb/cockroach/pull/80212
[#80221]: https://github.com/cockroachdb/cockroach/pull/80221
[#80245]: https://github.com/cockroachdb/cockroach/pull/80245
[#80261]: https://github.com/cockroachdb/cockroach/pull/80261
[#80274]: https://github.com/cockroachdb/cockroach/pull/80274
[#80300]: https://github.com/cockroachdb/cockroach/pull/80300
[#80307]: https://github.com/cockroachdb/cockroach/pull/80307
[#80318]: https://github.com/cockroachdb/cockroach/pull/80318
[#80330]: https://github.com/cockroachdb/cockroach/pull/80330
[#80363]: https://github.com/cockroachdb/cockroach/pull/80363
[#80403]: https://github.com/cockroachdb/cockroach/pull/80403
[#80408]: https://github.com/cockroachdb/cockroach/pull/80408
[#80410]: https://github.com/cockroachdb/cockroach/pull/80410
[#80414]: https://github.com/cockroachdb/cockroach/pull/80414
[#80417]: https://github.com/cockroachdb/cockroach/pull/80417
[#80430]: https://github.com/cockroachdb/cockroach/pull/80430
[#80443]: https://github.com/cockroachdb/cockroach/pull/80443
[#80447]: https://github.com/cockroachdb/cockroach/pull/80447
[#80481]: https://github.com/cockroachdb/cockroach/pull/80481
[#80491]: https://github.com/cockroachdb/cockroach/pull/80491
[#80494]: https://github.com/cockroachdb/cockroach/pull/80494
[#80499]: https://github.com/cockroachdb/cockroach/pull/80499
[#80511]: https://github.com/cockroachdb/cockroach/pull/80511
[#80539]: https://github.com/cockroachdb/cockroach/pull/80539
[#80548]: https://github.com/cockroachdb/cockroach/pull/80548
[#80551]: https://github.com/cockroachdb/cockroach/pull/80551
[#80587]: https://github.com/cockroachdb/cockroach/pull/80587
[#80590]: https://github.com/cockroachdb/cockroach/pull/80590
[#80592]: https://github.com/cockroachdb/cockroach/pull/80592
[#80651]: https://github.com/cockroachdb/cockroach/pull/80651
[#80660]: https://github.com/cockroachdb/cockroach/pull/80660
[#80679]: https://github.com/cockroachdb/cockroach/pull/80679
[#80705]: https://github.com/cockroachdb/cockroach/pull/80705
[#80706]: https://github.com/cockroachdb/cockroach/pull/80706
[#80707]: https://github.com/cockroachdb/cockroach/pull/80707
[#80726]: https://github.com/cockroachdb/cockroach/pull/80726
[#80743]: https://github.com/cockroachdb/cockroach/pull/80743
[#80806]: https://github.com/cockroachdb/cockroach/pull/80806
[#80809]: https://github.com/cockroachdb/cockroach/pull/80809
[#80833]: https://github.com/cockroachdb/cockroach/pull/80833
[#80861]: https://github.com/cockroachdb/cockroach/pull/80861
[#80874]: https://github.com/cockroachdb/cockroach/pull/80874
[#80878]: https://github.com/cockroachdb/cockroach/pull/80878
[#80923]: https://github.com/cockroachdb/cockroach/pull/80923
[#80993]: https://github.com/cockroachdb/cockroach/pull/80993
[#81042]: https://github.com/cockroachdb/cockroach/pull/81042
[#81049]: https://github.com/cockroachdb/cockroach/pull/81049
[#81062]: https://github.com/cockroachdb/cockroach/pull/81062
[#81071]: https://github.com/cockroachdb/cockroach/pull/81071
[#81075]: https://github.com/cockroachdb/cockroach/pull/81075
[#81077]: https://github.com/cockroachdb/cockroach/pull/81077
[#81104]: https://github.com/cockroachdb/cockroach/pull/81104
[#81107]: https://github.com/cockroachdb/cockroach/pull/81107
[#81120]: https://github.com/cockroachdb/cockroach/pull/81120
[#81123]: https://github.com/cockroachdb/cockroach/pull/81123
[#81125]: https://github.com/cockroachdb/cockroach/pull/81125
[#81133]: https://github.com/cockroachdb/cockroach/pull/81133
[#81136]: https://github.com/cockroachdb/cockroach/pull/81136
[#81148]: https://github.com/cockroachdb/cockroach/pull/81148
[#81200]: https://github.com/cockroachdb/cockroach/pull/81200
[#81207]: https://github.com/cockroachdb/cockroach/pull/81207
[#81213]: https://github.com/cockroachdb/cockroach/pull/81213
[#81253]: https://github.com/cockroachdb/cockroach/pull/81253
[#81266]: https://github.com/cockroachdb/cockroach/pull/81266
[#81268]: https://github.com/cockroachdb/cockroach/pull/81268
[#81298]: https://github.com/cockroachdb/cockroach/pull/81298
[#81304]: https://github.com/cockroachdb/cockroach/pull/81304
[#81306]: https://github.com/cockroachdb/cockroach/pull/81306
[#81310]: https://github.com/cockroachdb/cockroach/pull/81310
[#81331]: https://github.com/cockroachdb/cockroach/pull/81331
[#81373]: https://github.com/cockroachdb/cockroach/pull/81373
[#81377]: https://github.com/cockroachdb/cockroach/pull/81377
[#81382]: https://github.com/cockroachdb/cockroach/pull/81382
[#81389]: https://github.com/cockroachdb/cockroach/pull/81389
[#81406]: https://github.com/cockroachdb/cockroach/pull/81406
[#81418]: https://github.com/cockroachdb/cockroach/pull/81418
[#81420]: https://github.com/cockroachdb/cockroach/pull/81420
[#81438]: https://github.com/cockroachdb/cockroach/pull/81438
[#81480]: https://github.com/cockroachdb/cockroach/pull/81480
[#81486]: https://github.com/cockroachdb/cockroach/pull/81486
[#81523]: https://github.com/cockroachdb/cockroach/pull/81523
[#81530]: https://github.com/cockroachdb/cockroach/pull/81530
[#81531]: https://github.com/cockroachdb/cockroach/pull/81531
[#81564]: https://github.com/cockroachdb/cockroach/pull/81564
[#81582]: https://github.com/cockroachdb/cockroach/pull/81582
[#81597]: https://github.com/cockroachdb/cockroach/pull/81597
[#81648]: https://github.com/cockroachdb/cockroach/pull/81648
[#81679]: https://github.com/cockroachdb/cockroach/pull/81679
[#81681]: https://github.com/cockroachdb/cockroach/pull/81681
[#81693]: https://github.com/cockroachdb/cockroach/pull/81693
[#81708]: https://github.com/cockroachdb/cockroach/pull/81708
[#81734]: https://github.com/cockroachdb/cockroach/pull/81734
[#81767]: https://github.com/cockroachdb/cockroach/pull/81767
[#81811]: https://github.com/cockroachdb/cockroach/pull/81811
[#81844]: https://github.com/cockroachdb/cockroach/pull/81844
[#81855]: https://github.com/cockroachdb/cockroach/pull/81855
[#81860]: https://github.com/cockroachdb/cockroach/pull/81860
[#81879]: https://github.com/cockroachdb/cockroach/pull/81879
[#81917]: https://github.com/cockroachdb/cockroach/pull/81917
[#81924]: https://github.com/cockroachdb/cockroach/pull/81924
[#81933]: https://github.com/cockroachdb/cockroach/pull/81933
[#81943]: https://github.com/cockroachdb/cockroach/pull/81943
[#81988]: https://github.com/cockroachdb/cockroach/pull/81988
[#82020]: https://github.com/cockroachdb/cockroach/pull/82020
[#82022]: https://github.com/cockroachdb/cockroach/pull/82022
[#82026]: https://github.com/cockroachdb/cockroach/pull/82026
[#82032]: https://github.com/cockroachdb/cockroach/pull/82032
[#82054]: https://github.com/cockroachdb/cockroach/pull/82054
[#82081]: https://github.com/cockroachdb/cockroach/pull/82081
[#82087]: https://github.com/cockroachdb/cockroach/pull/82087
[#82094]: https://github.com/cockroachdb/cockroach/pull/82094
[#82101]: https://github.com/cockroachdb/cockroach/pull/82101
[#82118]: https://github.com/cockroachdb/cockroach/pull/82118
[#82147]: https://github.com/cockroachdb/cockroach/pull/82147
[#82151]: https://github.com/cockroachdb/cockroach/pull/82151
[#82166]: https://github.com/cockroachdb/cockroach/pull/82166
[#82171]: https://github.com/cockroachdb/cockroach/pull/82171
[#82187]: https://github.com/cockroachdb/cockroach/pull/82187
[#82190]: https://github.com/cockroachdb/cockroach/pull/82190
[#82193]: https://github.com/cockroachdb/cockroach/pull/82193
[#82274]: https://github.com/cockroachdb/cockroach/pull/82274
[#82276]: https://github.com/cockroachdb/cockroach/pull/82276
[#82293]: https://github.com/cockroachdb/cockroach/pull/82293
[#82304]: https://github.com/cockroachdb/cockroach/pull/82304
[#82352]: https://github.com/cockroachdb/cockroach/pull/82352
[#82354]: https://github.com/cockroachdb/cockroach/pull/82354
[#82362]: https://github.com/cockroachdb/cockroach/pull/82362
[#82371]: https://github.com/cockroachdb/cockroach/pull/82371
[#82389]: https://github.com/cockroachdb/cockroach/pull/82389
[#82390]: https://github.com/cockroachdb/cockroach/pull/82390
[#82426]: https://github.com/cockroachdb/cockroach/pull/82426
[#82430]: https://github.com/cockroachdb/cockroach/pull/82430
[#82435]: https://github.com/cockroachdb/cockroach/pull/82435
[#82440]: https://github.com/cockroachdb/cockroach/pull/82440
[#82450]: https://github.com/cockroachdb/cockroach/pull/82450
[#82457]: https://github.com/cockroachdb/cockroach/pull/82457
[#82458]: https://github.com/cockroachdb/cockroach/pull/82458
[#82463]: https://github.com/cockroachdb/cockroach/pull/82463
[#82476]: https://github.com/cockroachdb/cockroach/pull/82476
[#82477]: https://github.com/cockroachdb/cockroach/pull/82477
[#82479]: https://github.com/cockroachdb/cockroach/pull/82479
[#82504]: https://github.com/cockroachdb/cockroach/pull/82504
[#82523]: https://github.com/cockroachdb/cockroach/pull/82523
[#82560]: https://github.com/cockroachdb/cockroach/pull/82560
[#82562]: https://github.com/cockroachdb/cockroach/pull/82562
[#82567]: https://github.com/cockroachdb/cockroach/pull/82567
[#82616]: https://github.com/cockroachdb/cockroach/pull/82616
[#82622]: https://github.com/cockroachdb/cockroach/pull/82622
[#82626]: https://github.com/cockroachdb/cockroach/pull/82626
[#82633]: https://github.com/cockroachdb/cockroach/pull/82633
[#82641]: https://github.com/cockroachdb/cockroach/pull/82641
[#82677]: https://github.com/cockroachdb/cockroach/pull/82677
[#82686]: https://github.com/cockroachdb/cockroach/pull/82686
[#82724]: https://github.com/cockroachdb/cockroach/pull/82724
[#82742]: https://github.com/cockroachdb/cockroach/pull/82742
[#82744]: https://github.com/cockroachdb/cockroach/pull/82744
[#82752]: https://github.com/cockroachdb/cockroach/pull/82752
[#82754]: https://github.com/cockroachdb/cockroach/pull/82754
[#82758]: https://github.com/cockroachdb/cockroach/pull/82758
[#82761]: https://github.com/cockroachdb/cockroach/pull/82761
[#82763]: https://github.com/cockroachdb/cockroach/pull/82763
[#82768]: https://github.com/cockroachdb/cockroach/pull/82768
[#82797]: https://github.com/cockroachdb/cockroach/pull/82797
[#82798]: https://github.com/cockroachdb/cockroach/pull/82798
[#82833]: https://github.com/cockroachdb/cockroach/pull/82833
[#82838]: https://github.com/cockroachdb/cockroach/pull/82838
[#82846]: https://github.com/cockroachdb/cockroach/pull/82846
[#82861]: https://github.com/cockroachdb/cockroach/pull/82861
[#82877]: https://github.com/cockroachdb/cockroach/pull/82877
[#82893]: https://github.com/cockroachdb/cockroach/pull/82893
[#82911]: https://github.com/cockroachdb/cockroach/pull/82911
[#82915]: https://github.com/cockroachdb/cockroach/pull/82915
[#82936]: https://github.com/cockroachdb/cockroach/pull/82936
[#82945]: https://github.com/cockroachdb/cockroach/pull/82945
[#82951]: https://github.com/cockroachdb/cockroach/pull/82951
[#82952]: https://github.com/cockroachdb/cockroach/pull/82952
[#82956]: https://github.com/cockroachdb/cockroach/pull/82956
[#82988]: https://github.com/cockroachdb/cockroach/pull/82988
[#82999]: https://github.com/cockroachdb/cockroach/pull/82999
[#83008]: https://github.com/cockroachdb/cockroach/pull/83008
[#83014]: https://github.com/cockroachdb/cockroach/pull/83014
[#83027]: https://github.com/cockroachdb/cockroach/pull/83027
[#83043]: https://github.com/cockroachdb/cockroach/pull/83043
[#83066]: https://github.com/cockroachdb/cockroach/pull/83066
[#83102]: https://github.com/cockroachdb/cockroach/pull/83102
[#83103]: https://github.com/cockroachdb/cockroach/pull/83103
[#83107]: https://github.com/cockroachdb/cockroach/pull/83107
[#83108]: https://github.com/cockroachdb/cockroach/pull/83108
[#83110]: https://github.com/cockroachdb/cockroach/pull/83110
[#83118]: https://github.com/cockroachdb/cockroach/pull/83118
[#83122]: https://github.com/cockroachdb/cockroach/pull/83122
[#83125]: https://github.com/cockroachdb/cockroach/pull/83125
[#83134]: https://github.com/cockroachdb/cockroach/pull/83134
[#83136]: https://github.com/cockroachdb/cockroach/pull/83136
[#83143]: https://github.com/cockroachdb/cockroach/pull/83143
[#83150]: https://github.com/cockroachdb/cockroach/pull/83150
[#83151]: https://github.com/cockroachdb/cockroach/pull/83151
[#83152]: https://github.com/cockroachdb/cockroach/pull/83152
[#83191]: https://github.com/cockroachdb/cockroach/pull/83191
[#83194]: https://github.com/cockroachdb/cockroach/pull/83194
[#83213]: https://github.com/cockroachdb/cockroach/pull/83213
[#83229]: https://github.com/cockroachdb/cockroach/pull/83229
[#83257]: https://github.com/cockroachdb/cockroach/pull/83257
[#83280]: https://github.com/cockroachdb/cockroach/pull/83280
[#83282]: https://github.com/cockroachdb/cockroach/pull/83282
[#83310]: https://github.com/cockroachdb/cockroach/pull/83310
[#83335]: https://github.com/cockroachdb/cockroach/pull/83335
[#83339]: https://github.com/cockroachdb/cockroach/pull/83339
[#83345]: https://github.com/cockroachdb/cockroach/pull/83345
[#83347]: https://github.com/cockroachdb/cockroach/pull/83347
[#83365]: https://github.com/cockroachdb/cockroach/pull/83365
[#83366]: https://github.com/cockroachdb/cockroach/pull/83366
[#83375]: https://github.com/cockroachdb/cockroach/pull/83375
[#83377]: https://github.com/cockroachdb/cockroach/pull/83377
[#83409]: https://github.com/cockroachdb/cockroach/pull/83409
[#83417]: https://github.com/cockroachdb/cockroach/pull/83417
[#83420]: https://github.com/cockroachdb/cockroach/pull/83420
[#83423]: https://github.com/cockroachdb/cockroach/pull/83423
[#83443]: https://github.com/cockroachdb/cockroach/pull/83443
[#83451]: https://github.com/cockroachdb/cockroach/pull/83451
[#83491]: https://github.com/cockroachdb/cockroach/pull/83491
[#83510]: https://github.com/cockroachdb/cockroach/pull/83510
[#83520]: https://github.com/cockroachdb/cockroach/pull/83520
[#83530]: https://github.com/cockroachdb/cockroach/pull/83530
[#83533]: https://github.com/cockroachdb/cockroach/pull/83533
[#83541]: https://github.com/cockroachdb/cockroach/pull/83541
[#83544]: https://github.com/cockroachdb/cockroach/pull/83544
[#83590]: https://github.com/cockroachdb/cockroach/pull/83590
[#83597]: https://github.com/cockroachdb/cockroach/pull/83597
[#83604]: https://github.com/cockroachdb/cockroach/pull/83604
[#83605]: https://github.com/cockroachdb/cockroach/pull/83605
[#83614]: https://github.com/cockroachdb/cockroach/pull/83614
[#83616]: https://github.com/cockroachdb/cockroach/pull/83616
[#83619]: https://github.com/cockroachdb/cockroach/pull/83619
[#83668]: https://github.com/cockroachdb/cockroach/pull/83668
[#83673]: https://github.com/cockroachdb/cockroach/pull/83673
[#83675]: https://github.com/cockroachdb/cockroach/pull/83675
[#83677]: https://github.com/cockroachdb/cockroach/pull/83677
[#83686]: https://github.com/cockroachdb/cockroach/pull/83686
[#83704]: https://github.com/cockroachdb/cockroach/pull/83704
[#83712]: https://github.com/cockroachdb/cockroach/pull/83712
[#83717]: https://github.com/cockroachdb/cockroach/pull/83717
[#83800]: https://github.com/cockroachdb/cockroach/pull/83800
[#83807]: https://github.com/cockroachdb/cockroach/pull/83807
[#83813]: https://github.com/cockroachdb/cockroach/pull/83813
[#83824]: https://github.com/cockroachdb/cockroach/pull/83824
[#83840]: https://github.com/cockroachdb/cockroach/pull/83840
[#83851]: https://github.com/cockroachdb/cockroach/pull/83851
[#83868]: https://github.com/cockroachdb/cockroach/pull/83868
[#83870]: https://github.com/cockroachdb/cockroach/pull/83870
[#83875]: https://github.com/cockroachdb/cockroach/pull/83875
[#83876]: https://github.com/cockroachdb/cockroach/pull/83876
[#83891]: https://github.com/cockroachdb/cockroach/pull/83891
[#83896]: https://github.com/cockroachdb/cockroach/pull/83896
[#83903]: https://github.com/cockroachdb/cockroach/pull/83903
[#83915]: https://github.com/cockroachdb/cockroach/pull/83915
[#83918]: https://github.com/cockroachdb/cockroach/pull/83918
[#83924]: https://github.com/cockroachdb/cockroach/pull/83924
[#83938]: https://github.com/cockroachdb/cockroach/pull/83938
[#83944]: https://github.com/cockroachdb/cockroach/pull/83944
[#83952]: https://github.com/cockroachdb/cockroach/pull/83952
[#83959]: https://github.com/cockroachdb/cockroach/pull/83959
[#84031]: https://github.com/cockroachdb/cockroach/pull/84031
[#84034]: https://github.com/cockroachdb/cockroach/pull/84034
[#84036]: https://github.com/cockroachdb/cockroach/pull/84036
[#84037]: https://github.com/cockroachdb/cockroach/pull/84037
[#84044]: https://github.com/cockroachdb/cockroach/pull/84044
[#84045]: https://github.com/cockroachdb/cockroach/pull/84045
[#84088]: https://github.com/cockroachdb/cockroach/pull/84088
[#84092]: https://github.com/cockroachdb/cockroach/pull/84092
[#84100]: https://github.com/cockroachdb/cockroach/pull/84100
[#84106]: https://github.com/cockroachdb/cockroach/pull/84106
[#84107]: https://github.com/cockroachdb/cockroach/pull/84107
[#84108]: https://github.com/cockroachdb/cockroach/pull/84108
[#84110]: https://github.com/cockroachdb/cockroach/pull/84110
[#84159]: https://github.com/cockroachdb/cockroach/pull/84159
[#84169]: https://github.com/cockroachdb/cockroach/pull/84169
[#84170]: https://github.com/cockroachdb/cockroach/pull/84170
[#84173]: https://github.com/cockroachdb/cockroach/pull/84173
[#84177]: https://github.com/cockroachdb/cockroach/pull/84177
[#84182]: https://github.com/cockroachdb/cockroach/pull/84182
[#84189]: https://github.com/cockroachdb/cockroach/pull/84189
[#84195]: https://github.com/cockroachdb/cockroach/pull/84195
[#84198]: https://github.com/cockroachdb/cockroach/pull/84198
[#84205]: https://github.com/cockroachdb/cockroach/pull/84205
[#84208]: https://github.com/cockroachdb/cockroach/pull/84208
[#84219]: https://github.com/cockroachdb/cockroach/pull/84219
[#84230]: https://github.com/cockroachdb/cockroach/pull/84230
[#84282]: https://github.com/cockroachdb/cockroach/pull/84282
[#84283]: https://github.com/cockroachdb/cockroach/pull/84283
[#84286]: https://github.com/cockroachdb/cockroach/pull/84286
[#84303]: https://github.com/cockroachdb/cockroach/pull/84303
[#84310]: https://github.com/cockroachdb/cockroach/pull/84310
[#84366]: https://github.com/cockroachdb/cockroach/pull/84366
[#84386]: https://github.com/cockroachdb/cockroach/pull/84386
[#84398]: https://github.com/cockroachdb/cockroach/pull/84398
[#84400]: https://github.com/cockroachdb/cockroach/pull/84400
[#84445]: https://github.com/cockroachdb/cockroach/pull/84445
[#84449]: https://github.com/cockroachdb/cockroach/pull/84449
[#84450]: https://github.com/cockroachdb/cockroach/pull/84450
[#84452]: https://github.com/cockroachdb/cockroach/pull/84452
[#84471]: https://github.com/cockroachdb/cockroach/pull/84471
[#84485]: https://github.com/cockroachdb/cockroach/pull/84485
[#84486]: https://github.com/cockroachdb/cockroach/pull/84486
[#84487]: https://github.com/cockroachdb/cockroach/pull/84487
[#84494]: https://github.com/cockroachdb/cockroach/pull/84494
[#84495]: https://github.com/cockroachdb/cockroach/pull/84495
[#84498]: https://github.com/cockroachdb/cockroach/pull/84498
[#84500]: https://github.com/cockroachdb/cockroach/pull/84500
[#84501]: https://github.com/cockroachdb/cockroach/pull/84501
[#84510]: https://github.com/cockroachdb/cockroach/pull/84510
[#84515]: https://github.com/cockroachdb/cockroach/pull/84515
[#84516]: https://github.com/cockroachdb/cockroach/pull/84516
[#84524]: https://github.com/cockroachdb/cockroach/pull/84524
[#84532]: https://github.com/cockroachdb/cockroach/pull/84532
[#84555]: https://github.com/cockroachdb/cockroach/pull/84555
[#84590]: https://github.com/cockroachdb/cockroach/pull/84590
[#84612]: https://github.com/cockroachdb/cockroach/pull/84612
[#84613]: https://github.com/cockroachdb/cockroach/pull/84613
[#84617]: https://github.com/cockroachdb/cockroach/pull/84617
[#84618]: https://github.com/cockroachdb/cockroach/pull/84618
[#84619]: https://github.com/cockroachdb/cockroach/pull/84619
[#84649]: https://github.com/cockroachdb/cockroach/pull/84649
[#84670]: https://github.com/cockroachdb/cockroach/pull/84670
[#84674]: https://github.com/cockroachdb/cockroach/pull/84674
[#84682]: https://github.com/cockroachdb/cockroach/pull/84682
[#84686]: https://github.com/cockroachdb/cockroach/pull/84686
[#84689]: https://github.com/cockroachdb/cockroach/pull/84689
[#84718]: https://github.com/cockroachdb/cockroach/pull/84718
[#84728]: https://github.com/cockroachdb/cockroach/pull/84728
[#84744]: https://github.com/cockroachdb/cockroach/pull/84744
[#84749]: https://github.com/cockroachdb/cockroach/pull/84749
[#84751]: https://github.com/cockroachdb/cockroach/pull/84751
[#84761]: https://github.com/cockroachdb/cockroach/pull/84761
[#84764]: https://github.com/cockroachdb/cockroach/pull/84764
[#84776]: https://github.com/cockroachdb/cockroach/pull/84776
[#84783]: https://github.com/cockroachdb/cockroach/pull/84783
[#84865]: https://github.com/cockroachdb/cockroach/pull/84865
[#84879]: https://github.com/cockroachdb/cockroach/pull/84879
[#84886]: https://github.com/cockroachdb/cockroach/pull/84886
[#84887]: https://github.com/cockroachdb/cockroach/pull/84887
[#84910]: https://github.com/cockroachdb/cockroach/pull/84910
[#84931]: https://github.com/cockroachdb/cockroach/pull/84931
[#84945]: https://github.com/cockroachdb/cockroach/pull/84945
[#84947]: https://github.com/cockroachdb/cockroach/pull/84947
[#84999]: https://github.com/cockroachdb/cockroach/pull/84999
[#85007]: https://github.com/cockroachdb/cockroach/pull/85007
[#85017]: https://github.com/cockroachdb/cockroach/pull/85017
[#85027]: https://github.com/cockroachdb/cockroach/pull/85027
[#85069]: https://github.com/cockroachdb/cockroach/pull/85069
[#85072]: https://github.com/cockroachdb/cockroach/pull/85072
[#85075]: https://github.com/cockroachdb/cockroach/pull/85075
[#85081]: https://github.com/cockroachdb/cockroach/pull/85081
[#85086]: https://github.com/cockroachdb/cockroach/pull/85086
[#85100]: https://github.com/cockroachdb/cockroach/pull/85100
[#85131]: https://github.com/cockroachdb/cockroach/pull/85131
[#85134]: https://github.com/cockroachdb/cockroach/pull/85134
[#85140]: https://github.com/cockroachdb/cockroach/pull/85140
[#85146]: https://github.com/cockroachdb/cockroach/pull/85146
[#85150]: https://github.com/cockroachdb/cockroach/pull/85150
[#85158]: https://github.com/cockroachdb/cockroach/pull/85158
[#85159]: https://github.com/cockroachdb/cockroach/pull/85159
[#85169]: https://github.com/cockroachdb/cockroach/pull/85169
[#85174]: https://github.com/cockroachdb/cockroach/pull/85174
[#85231]: https://github.com/cockroachdb/cockroach/pull/85231
[#85244]: https://github.com/cockroachdb/cockroach/pull/85244
[#85280]: https://github.com/cockroachdb/cockroach/pull/85280
[#85326]: https://github.com/cockroachdb/cockroach/pull/85326
[#85339]: https://github.com/cockroachdb/cockroach/pull/85339
[#85343]: https://github.com/cockroachdb/cockroach/pull/85343
[#85344]: https://github.com/cockroachdb/cockroach/pull/85344
[#85351]: https://github.com/cockroachdb/cockroach/pull/85351
[#85392]: https://github.com/cockroachdb/cockroach/pull/85392
[#85407]: https://github.com/cockroachdb/cockroach/pull/85407
[#85410]: https://github.com/cockroachdb/cockroach/pull/85410
[#85421]: https://github.com/cockroachdb/cockroach/pull/85421
[#85423]: https://github.com/cockroachdb/cockroach/pull/85423
[#85440]: https://github.com/cockroachdb/cockroach/pull/85440
[#85442]: https://github.com/cockroachdb/cockroach/pull/85442
[#85453]: https://github.com/cockroachdb/cockroach/pull/85453
[#85458]: https://github.com/cockroachdb/cockroach/pull/85458
[#85464]: https://github.com/cockroachdb/cockroach/pull/85464
[#85473]: https://github.com/cockroachdb/cockroach/pull/85473
[#85489]: https://github.com/cockroachdb/cockroach/pull/85489
[#85524]: https://github.com/cockroachdb/cockroach/pull/85524
[#85544]: https://github.com/cockroachdb/cockroach/pull/85544
[#85556]: https://github.com/cockroachdb/cockroach/pull/85556
[#85586]: https://github.com/cockroachdb/cockroach/pull/85586
[#85593]: https://github.com/cockroachdb/cockroach/pull/85593
[#85594]: https://github.com/cockroachdb/cockroach/pull/85594
[#85597]: https://github.com/cockroachdb/cockroach/pull/85597
[#85599]: https://github.com/cockroachdb/cockroach/pull/85599
[#85634]: https://github.com/cockroachdb/cockroach/pull/85634
[#85649]: https://github.com/cockroachdb/cockroach/pull/85649
[#85656]: https://github.com/cockroachdb/cockroach/pull/85656
[#85671]: https://github.com/cockroachdb/cockroach/pull/85671
[#85676]: https://github.com/cockroachdb/cockroach/pull/85676
[#85680]: https://github.com/cockroachdb/cockroach/pull/85680
[#85695]: https://github.com/cockroachdb/cockroach/pull/85695
[#85704]: https://github.com/cockroachdb/cockroach/pull/85704
[#85718]: https://github.com/cockroachdb/cockroach/pull/85718
[#85720]: https://github.com/cockroachdb/cockroach/pull/85720
[#85731]: https://github.com/cockroachdb/cockroach/pull/85731
[#85756]: https://github.com/cockroachdb/cockroach/pull/85756
[#85757]: https://github.com/cockroachdb/cockroach/pull/85757
[#85764]: https://github.com/cockroachdb/cockroach/pull/85764
[#85769]: https://github.com/cockroachdb/cockroach/pull/85769
[#85770]: https://github.com/cockroachdb/cockroach/pull/85770
[#85772]: https://github.com/cockroachdb/cockroach/pull/85772
[#85773]: https://github.com/cockroachdb/cockroach/pull/85773
[#85778]: https://github.com/cockroachdb/cockroach/pull/85778
[#85781]: https://github.com/cockroachdb/cockroach/pull/85781
[#85794]: https://github.com/cockroachdb/cockroach/pull/85794
[#85809]: https://github.com/cockroachdb/cockroach/pull/85809
[#85819]: https://github.com/cockroachdb/cockroach/pull/85819
[#85823]: https://github.com/cockroachdb/cockroach/pull/85823
[#85843]: https://github.com/cockroachdb/cockroach/pull/85843
[#85844]: https://github.com/cockroachdb/cockroach/pull/85844
[#85847]: https://github.com/cockroachdb/cockroach/pull/85847
[#85850]: https://github.com/cockroachdb/cockroach/pull/85850
[#85853]: https://github.com/cockroachdb/cockroach/pull/85853
[#85861]: https://github.com/cockroachdb/cockroach/pull/85861
[#85863]: https://github.com/cockroachdb/cockroach/pull/85863
[#85878]: https://github.com/cockroachdb/cockroach/pull/85878
[#85889]: https://github.com/cockroachdb/cockroach/pull/85889
[#85890]: https://github.com/cockroachdb/cockroach/pull/85890
[#85896]: https://github.com/cockroachdb/cockroach/pull/85896
[#85940]: https://github.com/cockroachdb/cockroach/pull/85940
[#85949]: https://github.com/cockroachdb/cockroach/pull/85949
[#85957]: https://github.com/cockroachdb/cockroach/pull/85957
[#85959]: https://github.com/cockroachdb/cockroach/pull/85959
[#85964]: https://github.com/cockroachdb/cockroach/pull/85964
[#85974]: https://github.com/cockroachdb/cockroach/pull/85974
[#85981]: https://github.com/cockroachdb/cockroach/pull/85981
[#85983]: https://github.com/cockroachdb/cockroach/pull/85983
[#85986]: https://github.com/cockroachdb/cockroach/pull/85986
[#86006]: https://github.com/cockroachdb/cockroach/pull/86006
[#86007]: https://github.com/cockroachdb/cockroach/pull/86007
[#86032]: https://github.com/cockroachdb/cockroach/pull/86032
[#86033]: https://github.com/cockroachdb/cockroach/pull/86033
[#86043]: https://github.com/cockroachdb/cockroach/pull/86043
[#86050]: https://github.com/cockroachdb/cockroach/pull/86050
[#86055]: https://github.com/cockroachdb/cockroach/pull/86055
[#86063]: https://github.com/cockroachdb/cockroach/pull/86063
[#86071]: https://github.com/cockroachdb/cockroach/pull/86071
[#86078]: https://github.com/cockroachdb/cockroach/pull/86078
[#86126]: https://github.com/cockroachdb/cockroach/pull/86126
[#86136]: https://github.com/cockroachdb/cockroach/pull/86136
[#86138]: https://github.com/cockroachdb/cockroach/pull/86138
[#86139]: https://github.com/cockroachdb/cockroach/pull/86139
[#86147]: https://github.com/cockroachdb/cockroach/pull/86147
[#86152]: https://github.com/cockroachdb/cockroach/pull/86152
[#86161]: https://github.com/cockroachdb/cockroach/pull/86161
[#86169]: https://github.com/cockroachdb/cockroach/pull/86169
[#86173]: https://github.com/cockroachdb/cockroach/pull/86173
[#86174]: https://github.com/cockroachdb/cockroach/pull/86174
[#86190]: https://github.com/cockroachdb/cockroach/pull/86190
[#86193]: https://github.com/cockroachdb/cockroach/pull/86193
[#86195]: https://github.com/cockroachdb/cockroach/pull/86195
[#86216]: https://github.com/cockroachdb/cockroach/pull/86216
[#86230]: https://github.com/cockroachdb/cockroach/pull/86230
[#86236]: https://github.com/cockroachdb/cockroach/pull/86236
[#86252]: https://github.com/cockroachdb/cockroach/pull/86252
[#86253]: https://github.com/cockroachdb/cockroach/pull/86253
[#86255]: https://github.com/cockroachdb/cockroach/pull/86255
[#86257]: https://github.com/cockroachdb/cockroach/pull/86257
[#86264]: https://github.com/cockroachdb/cockroach/pull/86264
[#86272]: https://github.com/cockroachdb/cockroach/pull/86272
[#86317]: https://github.com/cockroachdb/cockroach/pull/86317
[#86319]: https://github.com/cockroachdb/cockroach/pull/86319
[#86325]: https://github.com/cockroachdb/cockroach/pull/86325
[#86329]: https://github.com/cockroachdb/cockroach/pull/86329
[#86336]: https://github.com/cockroachdb/cockroach/pull/86336
[#86345]: https://github.com/cockroachdb/cockroach/pull/86345
[#86382]: https://github.com/cockroachdb/cockroach/pull/86382
[#86402]: https://github.com/cockroachdb/cockroach/pull/86402
[#86407]: https://github.com/cockroachdb/cockroach/pull/86407
[#86409]: https://github.com/cockroachdb/cockroach/pull/86409
[#86415]: https://github.com/cockroachdb/cockroach/pull/86415
[#86417]: https://github.com/cockroachdb/cockroach/pull/86417
[#86448]: https://github.com/cockroachdb/cockroach/pull/86448
[#86485]: https://github.com/cockroachdb/cockroach/pull/86485
[#86486]: https://github.com/cockroachdb/cockroach/pull/86486
[#86495]: https://github.com/cockroachdb/cockroach/pull/86495
[#86566]: https://github.com/cockroachdb/cockroach/pull/86566
[#86570]: https://github.com/cockroachdb/cockroach/pull/86570
[#86572]: https://github.com/cockroachdb/cockroach/pull/86572
[#86581]: https://github.com/cockroachdb/cockroach/pull/86581
[#86605]: https://github.com/cockroachdb/cockroach/pull/86605
[#86606]: https://github.com/cockroachdb/cockroach/pull/86606
[#86607]: https://github.com/cockroachdb/cockroach/pull/86607
[#86619]: https://github.com/cockroachdb/cockroach/pull/86619
[#86653]: https://github.com/cockroachdb/cockroach/pull/86653
[#86673]: https://github.com/cockroachdb/cockroach/pull/86673
[#86675]: https://github.com/cockroachdb/cockroach/pull/86675
[#86677]: https://github.com/cockroachdb/cockroach/pull/86677
[#86679]: https://github.com/cockroachdb/cockroach/pull/86679
[#86688]: https://github.com/cockroachdb/cockroach/pull/86688
[#86700]: https://github.com/cockroachdb/cockroach/pull/86700
[#86712]: https://github.com/cockroachdb/cockroach/pull/86712
[#86722]: https://github.com/cockroachdb/cockroach/pull/86722
[#86738]: https://github.com/cockroachdb/cockroach/pull/86738
[#86764]: https://github.com/cockroachdb/cockroach/pull/86764
[#86776]: https://github.com/cockroachdb/cockroach/pull/86776
[#86779]: https://github.com/cockroachdb/cockroach/pull/86779
[#86794]: https://github.com/cockroachdb/cockroach/pull/86794
[#86812]: https://github.com/cockroachdb/cockroach/pull/86812
[#86819]: https://github.com/cockroachdb/cockroach/pull/86819
[#86821]: https://github.com/cockroachdb/cockroach/pull/86821
[#86829]: https://github.com/cockroachdb/cockroach/pull/86829
[#86834]: https://github.com/cockroachdb/cockroach/pull/86834
[#86841]: https://github.com/cockroachdb/cockroach/pull/86841
[#86848]: https://github.com/cockroachdb/cockroach/pull/86848
[#86901]: https://github.com/cockroachdb/cockroach/pull/86901
[#86906]: https://github.com/cockroachdb/cockroach/pull/86906
[#86909]: https://github.com/cockroachdb/cockroach/pull/86909
[#86918]: https://github.com/cockroachdb/cockroach/pull/86918
[#86924]: https://github.com/cockroachdb/cockroach/pull/86924
[#86929]: https://github.com/cockroachdb/cockroach/pull/86929
[#86932]: https://github.com/cockroachdb/cockroach/pull/86932
[#86957]: https://github.com/cockroachdb/cockroach/pull/86957
[#86986]: https://github.com/cockroachdb/cockroach/pull/86986
[#86990]: https://github.com/cockroachdb/cockroach/pull/86990
[#86991]: https://github.com/cockroachdb/cockroach/pull/86991
[#87068]: https://github.com/cockroachdb/cockroach/pull/87068
[019212fc8]: https://github.com/cockroachdb/cockroach/commit/019212fc8
[01cb84707]: https://github.com/cockroachdb/cockroach/commit/01cb84707
[03a4fad4a]: https://github.com/cockroachdb/cockroach/commit/03a4fad4a
[049721dba]: https://github.com/cockroachdb/cockroach/commit/049721dba
[05e903437]: https://github.com/cockroachdb/cockroach/commit/05e903437
[06cc64493]: https://github.com/cockroachdb/cockroach/commit/06cc64493
[091221e24]: https://github.com/cockroachdb/cockroach/commit/091221e24
[09e60c061]: https://github.com/cockroachdb/cockroach/commit/09e60c061
[0b1171e8a]: https://github.com/cockroachdb/cockroach/commit/0b1171e8a
[0ca54c768]: https://github.com/cockroachdb/cockroach/commit/0ca54c768
[0cb3190ea]: https://github.com/cockroachdb/cockroach/commit/0cb3190ea
[0ee3bbd66]: https://github.com/cockroachdb/cockroach/commit/0ee3bbd66
[1190d4149]: https://github.com/cockroachdb/cockroach/commit/1190d4149
[11d9b3d95]: https://github.com/cockroachdb/cockroach/commit/11d9b3d95
[16739391a]: https://github.com/cockroachdb/cockroach/commit/16739391a
[1b59a8c79]: https://github.com/cockroachdb/cockroach/commit/1b59a8c79
[1cc5b550c]: https://github.com/cockroachdb/cockroach/commit/1cc5b550c
[1cf4a2766]: https://github.com/cockroachdb/cockroach/commit/1cf4a2766
[1dd880897]: https://github.com/cockroachdb/cockroach/commit/1dd880897
[1f021e405]: https://github.com/cockroachdb/cockroach/commit/1f021e405
[2115a44e6]: https://github.com/cockroachdb/cockroach/commit/2115a44e6
[2331ac119]: https://github.com/cockroachdb/cockroach/commit/2331ac119
[2373a4c8f]: https://github.com/cockroachdb/cockroach/commit/2373a4c8f
[24d711e96]: https://github.com/cockroachdb/cockroach/commit/24d711e96
[26eed0b33]: https://github.com/cockroachdb/cockroach/commit/26eed0b33
[27772d931]: https://github.com/cockroachdb/cockroach/commit/27772d931
[28d3c1a4e]: https://github.com/cockroachdb/cockroach/commit/28d3c1a4e
[2904f8937]: https://github.com/cockroachdb/cockroach/commit/2904f8937
[2b2c43852]: https://github.com/cockroachdb/cockroach/commit/2b2c43852
[313d08532]: https://github.com/cockroachdb/cockroach/commit/313d08532
[315c3490d]: https://github.com/cockroachdb/cockroach/commit/315c3490d
[3392a0b5f]: https://github.com/cockroachdb/cockroach/commit/3392a0b5f
[35151c9c6]: https://github.com/cockroachdb/cockroach/commit/35151c9c6
[35e0f4a6a]: https://github.com/cockroachdb/cockroach/commit/35e0f4a6a
[362242f1e]: https://github.com/cockroachdb/cockroach/commit/362242f1e
[36e31630d]: https://github.com/cockroachdb/cockroach/commit/36e31630d
[38cba0df0]: https://github.com/cockroachdb/cockroach/commit/38cba0df0
[39ef815ce]: https://github.com/cockroachdb/cockroach/commit/39ef815ce
[3def4633e]: https://github.com/cockroachdb/cockroach/commit/3def4633e
[410ef2994]: https://github.com/cockroachdb/cockroach/commit/410ef2994
[454826e72]: https://github.com/cockroachdb/cockroach/commit/454826e72
[47900ebb5]: https://github.com/cockroachdb/cockroach/commit/47900ebb5
[4844cfce0]: https://github.com/cockroachdb/cockroach/commit/4844cfce0
[486dcc307]: https://github.com/cockroachdb/cockroach/commit/486dcc307
[48dd74ca4]: https://github.com/cockroachdb/cockroach/commit/48dd74ca4
[4a696f2c9]: https://github.com/cockroachdb/cockroach/commit/4a696f2c9
[4a9816b59]: https://github.com/cockroachdb/cockroach/commit/4a9816b59
[4bb7aef76]: https://github.com/cockroachdb/cockroach/commit/4bb7aef76
[4c461b482]: https://github.com/cockroachdb/cockroach/commit/4c461b482
[4d041e27c]: https://github.com/cockroachdb/cockroach/commit/4d041e27c
[4ebde0858]: https://github.com/cockroachdb/cockroach/commit/4ebde0858
[4fafba71b]: https://github.com/cockroachdb/cockroach/commit/4fafba71b
[509efb2e2]: https://github.com/cockroachdb/cockroach/commit/509efb2e2
[51709f3b1]: https://github.com/cockroachdb/cockroach/commit/51709f3b1
[519266577]: https://github.com/cockroachdb/cockroach/commit/519266577
[51c5a382c]: https://github.com/cockroachdb/cockroach/commit/51c5a382c
[534e4511f]: https://github.com/cockroachdb/cockroach/commit/534e4511f
[547bfce23]: https://github.com/cockroachdb/cockroach/commit/547bfce23
[557fe5e7d]: https://github.com/cockroachdb/cockroach/commit/557fe5e7d
[562c7574a]: https://github.com/cockroachdb/cockroach/commit/562c7574a
[566bb1651]: https://github.com/cockroachdb/cockroach/commit/566bb1651
[575215b93]: https://github.com/cockroachdb/cockroach/commit/575215b93
[587efd688]: https://github.com/cockroachdb/cockroach/commit/587efd688
[58c5ea09c]: https://github.com/cockroachdb/cockroach/commit/58c5ea09c
[5ab7683da]: https://github.com/cockroachdb/cockroach/commit/5ab7683da
[5b7a1335a]: https://github.com/cockroachdb/cockroach/commit/5b7a1335a
[5d4c0d71b]: https://github.com/cockroachdb/cockroach/commit/5d4c0d71b
[5eca58c79]: https://github.com/cockroachdb/cockroach/commit/5eca58c79
[5ecb6e24c]: https://github.com/cockroachdb/cockroach/commit/5ecb6e24c
[613ef47b8]: https://github.com/cockroachdb/cockroach/commit/613ef47b8
[625ee8b39]: https://github.com/cockroachdb/cockroach/commit/625ee8b39
[63dfc1493]: https://github.com/cockroachdb/cockroach/commit/63dfc1493
[64f31f999]: https://github.com/cockroachdb/cockroach/commit/64f31f999
[6590b9f4f]: https://github.com/cockroachdb/cockroach/commit/6590b9f4f
[667b46adb]: https://github.com/cockroachdb/cockroach/commit/667b46adb
[679e5795e]: https://github.com/cockroachdb/cockroach/commit/679e5795e
[68819c520]: https://github.com/cockroachdb/cockroach/commit/68819c520
[6a3b0d6ab]: https://github.com/cockroachdb/cockroach/commit/6a3b0d6ab
[6b87aa6ad]: https://github.com/cockroachdb/cockroach/commit/6b87aa6ad
[6bcf4c48e]: https://github.com/cockroachdb/cockroach/commit/6bcf4c48e
[6ea73f4e1]: https://github.com/cockroachdb/cockroach/commit/6ea73f4e1
[718fe9f53]: https://github.com/cockroachdb/cockroach/commit/718fe9f53
[71cb6f5bc]: https://github.com/cockroachdb/cockroach/commit/71cb6f5bc
[72a192c7f]: https://github.com/cockroachdb/cockroach/commit/72a192c7f
[745208894]: https://github.com/cockroachdb/cockroach/commit/745208894
[7485ec19b]: https://github.com/cockroachdb/cockroach/commit/7485ec19b
[74d1fb9b7]: https://github.com/cockroachdb/cockroach/commit/74d1fb9b7
[74e2070c0]: https://github.com/cockroachdb/cockroach/commit/74e2070c0
[7613c1c71]: https://github.com/cockroachdb/cockroach/commit/7613c1c71
[78dd74f0a]: https://github.com/cockroachdb/cockroach/commit/78dd74f0a
[79650bd53]: https://github.com/cockroachdb/cockroach/commit/79650bd53
[79a52303d]: https://github.com/cockroachdb/cockroach/commit/79a52303d
[7a8f50124]: https://github.com/cockroachdb/cockroach/commit/7a8f50124
[7dd6acc58]: https://github.com/cockroachdb/cockroach/commit/7dd6acc58
[7e81d81d3]: https://github.com/cockroachdb/cockroach/commit/7e81d81d3
[7f713fb31]: https://github.com/cockroachdb/cockroach/commit/7f713fb31
[8012d6a92]: https://github.com/cockroachdb/cockroach/commit/8012d6a92
[805b6070e]: https://github.com/cockroachdb/cockroach/commit/805b6070e
[82e4af40f]: https://github.com/cockroachdb/cockroach/commit/82e4af40f
[82ea33c88]: https://github.com/cockroachdb/cockroach/commit/82ea33c88
[831bfe703]: https://github.com/cockroachdb/cockroach/commit/831bfe703
[840ac2191]: https://github.com/cockroachdb/cockroach/commit/840ac2191
[8445150fc]: https://github.com/cockroachdb/cockroach/commit/8445150fc
[8891fd39d]: https://github.com/cockroachdb/cockroach/commit/8891fd39d
[88b2b015d]: https://github.com/cockroachdb/cockroach/commit/88b2b015d
[8abd5f02b]: https://github.com/cockroachdb/cockroach/commit/8abd5f02b
[8c5612909]: https://github.com/cockroachdb/cockroach/commit/8c5612909
[8d9427b58]: https://github.com/cockroachdb/cockroach/commit/8d9427b58
[8e6b85b53]: https://github.com/cockroachdb/cockroach/commit/8e6b85b53
[8fc9aa97e]: https://github.com/cockroachdb/cockroach/commit/8fc9aa97e
[909e04f8b]: https://github.com/cockroachdb/cockroach/commit/909e04f8b
[913ce9dfd]: https://github.com/cockroachdb/cockroach/commit/913ce9dfd
[918b22bcf]: https://github.com/cockroachdb/cockroach/commit/918b22bcf
[99a3a0ac4]: https://github.com/cockroachdb/cockroach/commit/99a3a0ac4
[9a9c47963]: https://github.com/cockroachdb/cockroach/commit/9a9c47963
[9c09473ec]: https://github.com/cockroachdb/cockroach/commit/9c09473ec
[9c1d08409]: https://github.com/cockroachdb/cockroach/commit/9c1d08409
[9cffb82d3]: https://github.com/cockroachdb/cockroach/commit/9cffb82d3
[9ec6d411f]: https://github.com/cockroachdb/cockroach/commit/9ec6d411f
[a345d4612]: https://github.com/cockroachdb/cockroach/commit/a345d4612
[a4a9037d2]: https://github.com/cockroachdb/cockroach/commit/a4a9037d2
[a9c31fc45]: https://github.com/cockroachdb/cockroach/commit/a9c31fc45
[ac2185f82]: https://github.com/cockroachdb/cockroach/commit/ac2185f82
[af64a4a3d]: https://github.com/cockroachdb/cockroach/commit/af64a4a3d
[b5c75c7d0]: https://github.com/cockroachdb/cockroach/commit/b5c75c7d0
[b61644c0a]: https://github.com/cockroachdb/cockroach/commit/b61644c0a
[b6e0a6f85]: https://github.com/cockroachdb/cockroach/commit/b6e0a6f85
[b7be578e9]: https://github.com/cockroachdb/cockroach/commit/b7be578e9
[bb1bce264]: https://github.com/cockroachdb/cockroach/commit/bb1bce264
[bb750c965]: https://github.com/cockroachdb/cockroach/commit/bb750c965
[bfcdb544e]: https://github.com/cockroachdb/cockroach/commit/bfcdb544e
[c048446c9]: https://github.com/cockroachdb/cockroach/commit/c048446c9
[c0b944fcd]: https://github.com/cockroachdb/cockroach/commit/c0b944fcd
[c312eb044]: https://github.com/cockroachdb/cockroach/commit/c312eb044
[c517f764f]: https://github.com/cockroachdb/cockroach/commit/c517f764f
[c5497ba47]: https://github.com/cockroachdb/cockroach/commit/c5497ba47
[c5bc00186]: https://github.com/cockroachdb/cockroach/commit/c5bc00186
[c6dc23e9b]: https://github.com/cockroachdb/cockroach/commit/c6dc23e9b
[c744ad9ac]: https://github.com/cockroachdb/cockroach/commit/c744ad9ac
[c7c154af8]: https://github.com/cockroachdb/cockroach/commit/c7c154af8
[c869c9ab9]: https://github.com/cockroachdb/cockroach/commit/c869c9ab9
[ca860749b]: https://github.com/cockroachdb/cockroach/commit/ca860749b
[cacac45c7]: https://github.com/cockroachdb/cockroach/commit/cacac45c7
[cc674d8f8]: https://github.com/cockroachdb/cockroach/commit/cc674d8f8
[d0825de8c]: https://github.com/cockroachdb/cockroach/commit/d0825de8c
[d0f72f975]: https://github.com/cockroachdb/cockroach/commit/d0f72f975
[d270fa08c]: https://github.com/cockroachdb/cockroach/commit/d270fa08c
[d2ec82be1]: https://github.com/cockroachdb/cockroach/commit/d2ec82be1
[d32226b97]: https://github.com/cockroachdb/cockroach/commit/d32226b97
[d54e0dda6]: https://github.com/cockroachdb/cockroach/commit/d54e0dda6
[d679b6de0]: https://github.com/cockroachdb/cockroach/commit/d679b6de0
[d6b756777]: https://github.com/cockroachdb/cockroach/commit/d6b756777
[d7d313b73]: https://github.com/cockroachdb/cockroach/commit/d7d313b73
[d963aa82b]: https://github.com/cockroachdb/cockroach/commit/d963aa82b
[d9e17f021]: https://github.com/cockroachdb/cockroach/commit/d9e17f021
[dd4049bd5]: https://github.com/cockroachdb/cockroach/commit/dd4049bd5
[deec9092f]: https://github.com/cockroachdb/cockroach/commit/deec9092f
[e05a787fb]: https://github.com/cockroachdb/cockroach/commit/e05a787fb
[e6c2413a3]: https://github.com/cockroachdb/cockroach/commit/e6c2413a3
[ea7d6fbd2]: https://github.com/cockroachdb/cockroach/commit/ea7d6fbd2
[ebf99778e]: https://github.com/cockroachdb/cockroach/commit/ebf99778e
[ed6d80372]: https://github.com/cockroachdb/cockroach/commit/ed6d80372
[eec9dc306]: https://github.com/cockroachdb/cockroach/commit/eec9dc306
[ef293592e]: https://github.com/cockroachdb/cockroach/commit/ef293592e
[f04e51a70]: https://github.com/cockroachdb/cockroach/commit/f04e51a70
[f11f912cb]: https://github.com/cockroachdb/cockroach/commit/f11f912cb
[f1f0697bf]: https://github.com/cockroachdb/cockroach/commit/f1f0697bf
[f20ff698f]: https://github.com/cockroachdb/cockroach/commit/f20ff698f
[f3f8c79ed]: https://github.com/cockroachdb/cockroach/commit/f3f8c79ed
[f7407c71a]: https://github.com/cockroachdb/cockroach/commit/f7407c71a
[f7d183a11]: https://github.com/cockroachdb/cockroach/commit/f7d183a11
[f9d6bea00]: https://github.com/cockroachdb/cockroach/commit/f9d6bea00
[fa0e39a3f]: https://github.com/cockroachdb/cockroach/commit/fa0e39a3f
[fad1ef725]: https://github.com/cockroachdb/cockroach/commit/fad1ef725
[fb5ec492b]: https://github.com/cockroachdb/cockroach/commit/fb5ec492b
[fda96e428]: https://github.com/cockroachdb/cockroach/commit/fda96e428
[fec45b870]: https://github.com/cockroachdb/cockroach/commit/fec45b870
[ff7b7e7ab]: https://github.com/cockroachdb/cockroach/commit/ff7b7e7ab
